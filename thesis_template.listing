public void here() {
    goes().the().code()
}
\end{sexylisting







\begin{table}[h!]
\centering
\caption{Analiza sentimenta}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}

\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje}                              \\ \hline     \hline
\textbf{Hugging Face Transformers}   & Priklic  & 0.937              & 0.912                 & 0.930              & 0.926 (±0.013)                                     \\
				    &  Natančnost  & 0.938              & 0.987                  & 0.860               & \textbf{0.928} (±0.064)                                     \\
                                     & F1 ocena    & 0.937                 & 0.952                  & 0.893             & 0.929 (±0.031)                    \\
\hline
\textbf{Google Vertex AI}         & Priklic  & 0.921              & 0.948              & 0.938              & 0.936 (±0.014)                                           \\
                                   &  Natančnost & 0.942             & 0.888              & 0.943              & 0.924 (±0.031)                                         \\
                                   & F1 ocena   & 0.931            & 0.917            & 0.940              & \textbf{0.930}  (±0.012)                                        \\
\hline
\textbf{AWS SageMaker}   & Priklic  & 0.901              & 0.882              & 0.891              & 0.891 (±0.010)                                           \\
                                   &  Natančnost & 0.821              & 0.853              & 0.912              & 0.862 (±0.046 )                                           \\
                                   & F1 ocena   & 0.859              & 0.867              & 0.901              & 0.876 (±0.022)                                                  \\
  \hline
\textbf{Azure Cognitive Services}   & Priklic  & 0.881              & 0.905              & 0.887              & \textbf{0.981} (±0.012)                                            \\
                       &  Natančnost & 0.852              & 0.884              & 0.851              & 0.862 (±0.019)                                          \\
                        & F1 ocena   & 0.866              & 0.894              & 0.869              & 0.876  (±0.015)                                          \\
  \hline
   \hline
  \textbf{Najboljši rezultat z članka}   & Priklic    &               &             &               & 0.980                                           \\
                       &  Natančnost &               &               &             & 0.650                                          \\
                        & F1 ocena   &              &             &               & 0.782                                         \\

\hline
\hline
\end{tabular}}
\end{table}

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{KP.png}
\end{center}
\caption{Analiza sentimenta Ocena F1}
\label{pic2}
\end{figure}

Pri analizi sentimenta je bil uporabljen  IMDb Reviews korpus (glej poglavje~\ref{sec:ch9}).
Za analizo sentimenta  je bila najboljša Vertex AI storitev.

\newpage

\subsection{Analiza napak pri analizi sentimenta}
\begin{table}[h!]
\begin{center}
\caption {Primeri napak pri analizi sentimenta} \label{tab:title}
\begin{tabularx}{1.1\textwidth} {
  | >{\centering\arraybackslash}X
  | >{\centering\arraybackslash}X
  | >{\centering\arraybackslash}X
    | >{\centering\arraybackslash}X
        | >{\centering\arraybackslash}X
    | >{\centering\arraybackslash}X |}
 \hline
  \textbf{Besedilo}  & \textbf{ Imenske entitete}   & \textbf{Google Vertex AI  } &  \textbf{Hugging Face Transformers}    \\
 \hline
Ta knjiga je zelo zanimiva.   &Pozitivno    & Pozitivno   &Negativno   \\
\hline
  To je zelo dolgočasno.  &Negativno  &Nevtralno    &Nevtralno  \\
    \hline
  Ta igra je bila zelo napeta. &Pozitivno    & Pozitivno & Nevtralno \\
      \hline
  Ta politični govor je bil zelo kontroverzen.  &Negativno    & Negativno & Pozitivno \\
    \hline
\end{tabularx}
\end{center}
\end{table}

Opazimo da sta obe storitvi naredili isto napako pri istem primeru, saj sta zaznali dolgočasno kot nevtralno in ne negativno.

Najpogosteje opažene napake pri analizi sentimenta:
\begin{enumerate}
 \item Nepravilna identifikacija sentimenta: je ena izmed najpogosteje opaženih napak, ki se je pojavila pri analizi sentimenta, kar je lahko ko je beseda ali besedna zveza dvoumna in lahko pomeni tako pozitiven kot negativen sentiment. Lahko je tudi napaka v zapisu same besede ali besedne zveze, kot tudi da je model premalo naučen za določeno področje.
 \item Nepravilna kategorizacija sentimenta: se pojavi, ko analiza sentimenta pravilno identificira sentiment, vendar ga napačno kategorizira. To lahko povzroči, da analiza sentimenta ne bo uporabna za namen, za katerega je bila namenjena.
 \item Napaka v kontekstu: se zgodi ko analiza sentimenta pravilno identificira sentiment in ga pravilno kategorizira, vendar ga napačno razvrsti v kontekstu. To lahko povzroči, da analiza sentimenta ne bo uporabna za namen, za katerega je bila namenjena.
 \item Napaka v viru: zaznamo jo, ko analiza sentimenta pravilno identificira sentiment, ga pravilno kategorizira in ga pravilno razvrsti v kontekstu, vendar ga napačno dobi iz vira. To lahko povzroči, da analiza sentimenta ne bo uporabna za namen, za katerega je bila namenjena.
 \end{enumerate}

\newpage
\section{Povzemanje besedila}
\begin{table}[h!]
\centering
\caption{Povzemanje besedila}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}
\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje}                          \\ \hline   \hline
\textbf{Hugging Face Transformers}   & ROUGE-L   & 0.178              & 0.187                 & 0.212              & 0.192 (±0.018)                                    \\
\hline
\textbf{Vertex AI}         & ROUGE-L   & 0.312              & 0.291              & 0.315              & 0.306 (±0.013)                                          \\
\hline
\textbf{AWS SageMaker}.   & ROUGE-L   & 0.203             & 0.184              & 0.216             & 0.201 (±0.016)                                           \\
\hline
\textbf{Azure Cognitive Services}   & ROUGE-L   & 0.387              & 0.318             & 0.284             & \textbf{0.330} (±0.052)                  \\
\hline
 \hline
\textbf{Rezultati članka}   & ROUGE-L   &               &              &             & 0.392                   \\
\hline
\hline
\end{tabular}}
\end{table}

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{SUMM.png}
\end{center}
\caption{Povzemanje Ocena F1}
\label{pic2}
\end{figure}

Pri povzemanju je bil uporabljen korpus CNN/Daily Mail (glej poglavje~\ref{sec:cnn}).

Kot najboljša izbira za ustvarjanje povzetkov se je izkazala storitev Azure Cognitive Services.
\newpage

\subsection{Analiza napak pri povzemanju besedila}
\begin{table}[h!]
\begin{center}
\caption {Primeri napak pri povzemanju besedila} \label{tab:title}
\begin{tabularx}{0.9\textwidth} {
  | >{\centering\arraybackslash}X
  | >{\centering\arraybackslash}X
  | >{\centering\arraybackslash}X
    | >{\centering\arraybackslash}X
    | >{\centering\arraybackslash}X |}
 \hline
  \textbf{Besedilo}  & \textbf{ Imenske entitete}   & \textbf{Azure Cognitive Services} &  \textbf{Hugging Face Transformers}    \\
 \hline
John Doe je živel v San Franciscu. Bil je uspešen poslovnež.   &John Doe, uspešen poslovnež iz San Francisca.    &John Doe je živel v San Franciscu in bil poslovnež. & John Doe, poslovnež, živel v San Franciscu.       \\
\hline
Apple je bila ustanovljena leta 1976. Je ena največjih tehnoloških podjetij na svetu.  &Apple, ustanovljeno leta 1976, je eno največjih tehnoloških podjetij na svetu.  &Apple, ustanovljeno leta 1976, je največje tehnološko podjetje na svetu. &Apple, tehnološko podjetje, ustanovljeno leta 1976.        \\
    \hline
     To je velikanski robot.  &Robot je velikanski.    & To je velikanski robot, ki je zelo močan.  & Velikanski, robot.   \\
    \hline
\end{tabularx}
\end{center}
\end{table}

Kot je razvidno iz tabele je Hugging Face Transformers vse stavke zelo slabo oblikoval in so zelo nepovezani.

\vspace{\baselineskip}



Najpogosteje opažene napake pri povzemanju besedila:
\begin{enumerate}
 \item Izpuščanje pomembnih informacij: kar pomeni, da je povzetek netočen ali nepopoln. To se lahko zgodi iz več razlogov, na primer zaradi tega, da model ne prepozna pomembnih informacij ali pa ne more pravilno razumeti pomena besedila. 
  \item Dodajanje napačnih informacij: povzroča, da je povzetek netočen ali zavajajoč. To se lahko zgodi iz več razlogov, na primer zaradi tega, da model napačno intrepterira besedilo ali pa uporablja napačne podatke pri treniranju modela.
 \item Slab slog in gramatika: ustvarjeni povzetki, ki so slabo napisani ali vsebujejo napake v slogu in gramatiki, kar je lahko posledica napačnega algoritma.
  \end{enumerate}

%----------------------------------------------------------------
%Izvleček besedne zveze

%----------------------------------------------------------------

\section{Prepoznavanje besednih zvez}

\begin{table}[h!]
\centering
\caption{Prepoznavanje besednih zvez}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}

\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje}                        \\ \hline \hline
\textbf{Hugging Face Transformers}   & Priklic  & 0.523              & 0.640                  & 0.556              & 0.573 (±0.060)                                        \\
				    &  Natančnost  & 0.398               & 0.499                 & 0.528               & 0.475 (±0.068 )  	          	   \\
                                     & F1 ocena    & 0.452                  & 0.561                  & 0.542              & 0.519 (±0.058)  			   \\
                                     \hline
\textbf{Google Vertex AI}         & Priklic  & 0.499              & 0.541              & 0.589              & 0.543 (±0.045)                                            \\
                                   &  Natančnost & 0.688             & 0.635              & 0.589              & \textbf{0.637} (±0.050 )                                          \\
                                   & F1 ocena   & 0.578             & 0.584              & 0.589              & 0.586 (±0.005)                                          \\
                                   \hline
\textbf{AWS SageMaker}   & Priklic  & 0.675              & 0.605              & 0.587              &\textbf{0.622}  (±0.046)                                         \\
                                   &  Natančnost & 0.520              & 0.492             & 0.526             & 0.513 (±0.018)                                            \\
                                   & F1 ocena   & 0.587             & 0.543             & 0.555              & 0.562 (±0.023)   					  \\
                                   \hline
\textbf{Azure Cognitive Services}   & Priklic  & 0.532              & 0.559             & 0.500              & 0.530 (±0.030 )                                        \\
                       &  Natančnost & 0.674              & 0.648             & 0.689              & 0.670 (±0.021)                                         	  \\
                        & F1 ocena   & 0.595              & 0.600              & 0.579              & \textbf{0.592}  (±0.011)                                                   \\
                                   \hline
                                    \hline
\textbf{Rezultati članka}   & Priklic  &              &              &               &0.543                                            \\
                       &  Natančnost &             &             &               &0.637                                        	  \\
                        & F1 ocena   &               &              &               &0.519                                                     \\
                        \hline
                        \hline
\end{tabular}}
\end{table}

  \newpage
 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{KEY.png}
\end{center}
\caption{Prepoznavanje besednih zvez Ocena F1}
\label{pic2}
\end{figure}


Pri izvajanju naloge zvlečka besedne zveze je bil uporabljen korpus SemEval 2017(glej poglavje~\ref{sec:semeval}).

Kot najboljša rešitev za izvleček besedne zveze pa se je izkazala storitev Azure Cognitive Services.


  \newpage
\subsection{Analiza napak pri izvlečeku besedne zveze}

\begin{table}[h!]
\begin{center}
\caption {Primeri napak pri izvlečeku besedne zveze} \label{tab:title}
\begin{tabularx}{0.9\textwidth} {
  | >{\centering\arraybackslash}X
  | >{\centering\arraybackslash}X
  | >{\centering\arraybackslash}X
    | >{\centering\arraybackslash}X
    | >{\centering\arraybackslash}X |}
 \hline
  \textbf{Besedilo}  & \textbf{ Imenske entitete}   & \textbf{Azure Cognitive Services} &  \textbf{Hugging Face Transformers}    \\
 \hline
John Doe je živel v San Franciscu. Bil je uspešen poslovnež.    &John Doe, uspešen poslovnež, San Francisco    &John Doe, San Francisco  & John Doe, Francisco        \\
\hline
Apple je bila ustanovljena leta 1976. Je ena največjih tehnoloških podjetij na svetu.   &Apple, podjetje, tehnološko, ustanovljeno leta 1976  &Apple, tehnološko podjetje, ustanovljeno  1976  &Apple, podjetje, ustanovljeno leta 1976, tehnološko        \\
    \hline
     To je velikanski robot.     & velikanski robot &velikanski, robot  &velikanski, robot, ki je zelo močan  \\
    \hline
\end{tabularx}
\end{center}
\end{table}

Iz tabele lahko razberemo, da je do napak prišlo pri uporabi obeh storitev, kot pri Hugging Face Transformers kakor tudi pri Azure Cognitive Services. Opazimo lahko makajoči  del ključne besede kateri je zelo pomemben, napačno povezovanje besed ter dodajanje neresničnih podatkov.

Najpogosteje opažene napake pri izvlečeku besedne zveze:
\begin{enumerate}
 \item Napačne oznake: napake v oznaki besednih zvez, na primer napačno označitev besedne zveze kot pomembne, čeprav ni pomembna ali obratno.
  \item Izpuščanje: napake, pri katerih se besedna zveza izpusti iz izvlečka, na primer zaradi napake pri prepoznavanju besednih zvez ali zaradi napake pri razdelitvi besedila na stavke.
  \item   Ponavljanje: To so napake, pri katerih se besedna zveza ponovi v izvlečku, na primer zaradi napake pri razdelitvi besedila na stavke ali zaradi napake pri ohranitvi besedne zveze.
 \end{enumerate}




%----------------------------------------------------------------
% Klasifikacija besedila
%----------------------------------------------------------------

\section{Uvrščanje besedil}

\begin{table}[h!]
\centering
\caption{Uvrščanje besedil}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}
\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje}
                 \\ \hline      \hline
\textbf{Hugging Face Transformers}   & Priklic  & 0.933             & 0.948                  &  0.896             &  0.926 (±0.027)                                         \\
				    &  Natančnost  &  0.898               & 0.935                 & 0.958               &  0.930 (±0.030)   		      \\
                                     & F1 ocena    &  0.915                  &  0.941                  &  0.926              &  \textbf{0.928} (±0.013) 		     \\
                                     \hline
\textbf{Google Vertex AI}         & Priklic  &  0.842              &  0.901              &  0.844             & \textbf{ 0.962} (±0.034)                                             \\
                                   &  Natančnost &  0.989              &  0.924              &  0.959              &  \textbf{0.957} (±0.033)                                             \\
                                   & F1 ocena   &  0.910              &  0.912              &  0.989              &  0.907 (± 0.008)                                            \\
                                   \hline
\textbf{AWS SageMaker}   & Priklic  &  0.789              &  0.802             &  0.697              &  0.763 (±0.057)                                            \\
                                   &  Natančnost &  0.879              &  0.799              &  0.895              &  0.858  (±0.051)                                           \\
                                   & F1 ocena   &  0.832              &  0.800              &  0.784              &  0.808 (±0.024)   			    \\
                                   \hline
\textbf{Azure Cognitive Services}   & Priklic  &  0.935              &  0.925             &  0.900              &  0.920  (±0.018)                                           \\
                       &  Natančnost &  0.827              &  0.888              &  0.925             &  0.880 (±0.049)                                            \\
                        & F1 ocena   &  0.878              &  0.906              &  0.912              &  0.900(±0.018)                                           \\
                                   \hline
                                    \hline
\textbf{Rezultati članka}   & Priklic  &                &               &              &  0.757                                            \\
                       &  Natančnost &                &               &             &  0.707                                            \\
                        & F1 ocena   &                &                &                &  0.735                                        \\
                        \hline
                        \hline
\end{tabular}}
\end{table}

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{CLASSIFICATION.png}
\end{center}
\caption{Uvrščanje besedil  Ocena F1}
\label{pic2}
\end{figure}

  \newpage
Pri izvajanju naloge uvrščanja besedila je bil uporabljen korpus IMDb Reviews (glej poglavje~\ref{sec:ch9}).

Kot najboljša rešitev za naloge uvrščanje besedila pa se je izkazala storitev Hugging Face Transformers.


\subsection{Analiza napak pri uvrščanje besedila}

\begin{table}[h!]
\begin{center}
\caption {Primeri napak pri uvrščanje besedila} \label{tab:title}
\begin{tabularx}{1.1\textwidth} {
  | >{\centering\arraybackslash}X
  | >{\centering\arraybackslash}X
  | >{\centering\arraybackslash}X
    | >{\centering\arraybackslash}X
    | >{\centering\arraybackslash}X |}
 \hline
  \textbf{Besedilo}  & \textbf{ Imenske entitete}   & \textbf{Google Vertex AI } &  \textbf{Hugging Face Transformers}    \\
 \hline
John Doe je živel v San Franciscu.     &Novice     &Novice  & Novice        \\
\hline
Apple je bila ustanovljena leta 1976.    &Novice  &Tehnologija   &Novice        \\
    \hline
     Ta koncert je bil zelo ganljiv.      & Umetnost  &Glasba  &Glasba  \\
    \hline
\end{tabularx}
\end{center}
\end{table}

Iz tabele lahko razberemo da so bile narejene napake pri obeh ponudnikih, vendar je Hugging Face Transformers imel manj napak.

Najpogosteje opažene napake pri uvrščanju besedila:

\begin{enumerate}
  \item Napačno uvrščanje razredov: zaradi pomanjkanja jasnih ločnic med razredi ali zaradi podobnosti med besedili različnih razredov.
    \item Nezaznavanje: kadar se izpustijo pomembne informacije iz besedila, kar la povzroči, da je uvrščanje netočno ali nepopolno.


 \end{enumerate}
%----------------------------------------------------------------
% Zaznava objektov
%---------------------------------------------------------------

\section{Zaznava objektov}
\begin{table}[h!]
\centering
\caption{Zaznava objektov }
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}
\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje }                            \\ \hline    \hline
\textbf{Hugging Face Transformers}   & Točnost  & 0.900             & 0.970                  & 0.940              & 0.940 (±0.018 )                                    \\
\hline
\textbf{Google Vertex AI}         & Točnost  & 0.963              & 0.991              & 0.977             & 0.977 (±0.014)                                           \\
\hline
\textbf{AWS SageMaker}  & Točnost  & 0.995              & 0.963              & 0.982              & \textbf{0.980} (±0.016)                                    \\
\hline
\textbf{Azure Cognitive Services}   & Točnost  & 0.960             & 0.950              & 0.985             & 0.965 (±0.017)               \\
\hline
 \hline
\textbf{Rezultati članka}   & Točnost  &             &               &              & 0.780               \\
\hline\hline
\end{tabular}}
\end{table}


 \begin{figure}[h!]
\begin{center}
\includegraphics[width=9cm]{OBJECT.png}
\end{center}
\caption{ Zaznava objektov Ocena F1}
\label{pic2}
\end{figure}


Pri zaznavi objektov je bil uporabljen  COCO korpus (glej poglavje~\ref{sec:coco}).

Kot najboljša izbira za zaznavanje objektov pa se je izkazala storitev AWS SageMaker.

\subsection{Analiza napak pri zaznavi objektov}
\begin{table}[h!]
\begin{center}
\caption {Primeri napak pri zaznavi objektov} \label{tab:title}
\begin{tabularx}{1.0\textwidth} {
  | >{\centering\arraybackslash}X
  | >{\centering\arraybackslash}X
  | >{\centering\arraybackslash}X
    | >{\centering\arraybackslash}X
      | >{\centering\arraybackslash}X
  | >{\centering\arraybackslash}X
    | >{\centering\arraybackslash}X
    | >{\centering\arraybackslash}X |}
 \hline
  \textbf{Slika}  & \textbf{ Pravilni objekti}   & \textbf{AWS SageMaker } &  \textbf{Hugging Face Transformers}    \\
 \hline
Psa     &Pes     &Pes  & Mačka        \\
\hline
Avtomobila    &Avtomobil  &Avtomobil, cesta   &Avtomobil        \\
    \hline
     Slika mize z rožami      & Miza, roža   &Miza  &Miza, roža   \\
         \hline
    Avtomobil, ki vozi po cesti      & Avtomobil, cesta   &Avtomobil, cesta   &Avtomobil, oseba, cesta   \\
             \hline
    Oseba, ki hodi po ulici       & Oseba, ulica,cesta   &Oseba, ulica,cesta   &Oseba, ulica   \\
    \hline
\end{tabularx}
\end{center}
\end{table}

Tudi pri tej tabeli lahko vidimo da sta obe storitvi naredili napake. Opazimo da je Hugging Face Transformers večkrat napačno kategoriziral.

Do napak pri zazvanju objektov prihaja zaradi različnih razlogov, na primer zaradi napak v algoritmu za zaznavanje objektov, zaradi slabe kakovosti slik ali zaradi prisotnosti motenj v okolju.

Najpogosteje opažene napake pri zaznavi objektov:
\begin{enumerate}
 \item  Nenamerna zaznava: zaznava objektov, ki v dejanskem okolju niso prisotni.
  \item Nezaznavanje: izpuščanje objektov, ki so dejansko pristotni v okolju.
   \item Napačna zaznava: AI modeli lahko nepravilno zaznajo objekte.
 \end{enumerate}


\section{Diskusija}
\begin{table}[h!]
\centering
\caption{Tabela analize}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}

\multicolumn{1}{r}{} &                                                & \textbf{Hugging Face Transformers}             & \textbf{Google Vertex AI}                & \textbf{AWS SageMaker}               & \textbf{Azure Cognitive Services}                             \\ \hline
\hline
\textbf{Prepoznavanje imenskih entitet}                         &  Priklic  & 0.919               & 0.919                           & 0.961               & 0.824 \\
										   & Natančnost  & 0.923                & 0.920                  &0.954              & 0.858                                         \\
                                                                                       & F1 ocena    & 0.921                & 0.919                  & \textbf{0.958}               & 0.841    \\
\hline
\textbf{Analiza sentimenta}                         		 &  Priklic  & 0.926              & 0.936                  & 0.891               & 0.981       \\
										   & Natančnost  & 0.928               & 0.924                  & 0.862               & 0.862    \\
                                                                                       & F1 ocena    &  0.929              & \textbf{0.930}                   & 0.876               & 0.876      \\
\hline
\textbf{Povzemanje}                                      &  ROUGE-L  & 0.192                & 0.306                  & 0.201               & \textbf{0.330}    \\
  \hline
\textbf{Prepoznavanje besednih zvez}  	                           &  Priklic  & 0.573                & 0.543                  & 0.622              & 0.530 \\
										   & Natančnost  & 0.475                & 0.637                  & 0.513              & 0.670 \\
                                                                                       & F1 ocena    & 0.519                & 0.586                  & 0.562               &\textbf{0.592}   \\
\hline
\textbf{Uvrščanje besedil}                                         &  Priklic  & 0.926                &  0.962                   &  0.763                &  0.920  \\
										   & Natančnost  & 0.930                &  0.957                   &  0.858                &  0.880  \\
                                                                                       & F1 ocena    & \textbf{0.928}                &  0.907                   &  0.808                &  0.900     \\
\hline
\textbf{Zaznava objektov}  					    & Točnost  & 0.940                & 0.977                  & \textbf{0.980}               & 0.965  \\
   \hline
   \hline
\end{tabular}}
\end{table}
Pomembno je omeniti, da so vse oblačne storitve po rezultatih tesno skupaj v nekaterih primerih, kot je razvidno iz tabele analize je za  uvrščanje besedila  odprtokodna rešitev Hugging Face Transformers je imela najboljši rezultat.
Pri testitranju  imenovanje imenskih entitet je najvišjo uspešnost dosegla storitev AWS Sage Maker. Na drugem mestu je bila odprtokodna storitev Hugging Face Transformers, medtem ko je tretje mesto zasedla storitev Vertex AI ponudnika Google Cloud.

Pri testiranju sentimentalne analize je najboljše rezultate dosegla storitev AWS SageMaker. Na drugo mesto se je uvrstila odprtokodna rešitev Hugging Face Transformers, medtem ko je tretje mesto zasedla storitev Vertex AI podjetja Google.

Najboljši rezultati  pri povzemanju besedila so bili doseženi z uporabo storitve Azure Cognitive Services. Na drugem mestu se je uvrstil Vertex AI, medtem ko je tretje mesto pripadlo AWS SageMaker.

Pri ocenjevanju izvlečka besednih zvez je prvo mesto osvojila storitev Azure Cognitive Services. Na drugem mestu je Vertex AI, medtem ko je tretjem mestu  AWS SageMaker.

Pri uvrščanju besedila se je najboljša učinkovitost pokazala pri odprtokodni platformi Hugging Face Transformers. Na drugem mestu je bila storitev Vertex AI, medtem ko je tretje mesto pripadlo storitvi Azure Cognitive Services.

V zaznavanju objektov je prvo mesto zasedla storitev Azure Cognitive Services, takoj za njo je sledil Vertex AI, medtem ko je tretje mesto pripadlo odprtokodni rešitvi Hugging Face Transformers.


\section{Odločitvena tabela}

\begin{table}[h!]
\centering
\caption{Odločitvena tabela }
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}
\multicolumn{1}{r}{}    & \textbf{Cena}             & \textbf{Enostavnost}                & \textbf{Uspešnost}                                        \\ \hline    \hline
\textbf{Hugging Face Transformers}   & 2  & 4            & 4                                                          \\
\hline
\textbf{Google Vertex AI}         & 3  & 3              & 1                                                            \\
\hline
\textbf{AWS SageMaker}  & 4  & 2             & 2                                                    \\
\hline
\textbf{Azure Cognitive Services}   & 1  & 1            & 2                             \\

\hline\hline
\end{tabular}}
\end{table}

Ocena cene v tabeli je bila določena glede na stroške ene iteracije glede na storitev. Pomembno je omeniti da smo za odprtokodno rešitev koristili virtualni stroj.
Ocena enostavnosti uporabe temelji na naših izkušnjah iz uporabe storitev. Pri uporabi Azure Cognitive Services smo ugotovili, da je ta storitev izjemno enostavna za uporabo. Ponuja dobro dokumentacijo in uporabniku prijazen vmesnik, ki omogoča preprost razvoj storitev. Pri AWS SageMakerju smo opazili, da je potrebnih nekoliko več izkušenj z vmesniki. Ta platforma zahteva več truda pri učenju in je bolj tehnično zahtevna v primerjavi z Azure Cognitive Services. Google Vertex AI je bil ob v času raziskave še v razvoju in opaziti je bilo številne mankajoče informacije. To pomeni, da ta storitev morda ni tako zrela in dobro dokumentirana kot ostale storitve v analizi raziskave. Pri uporabi Transformerjev je bilo potrebno tehnično znanje za postavitev ustreznega delovnega okolja.

 \newpage
 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{graf.png}
\end{center}
\caption{ Slikovni prikaz odločitvene tabele}
\label{pic2}
\end{figure}

Iz grafa je razvidno, da je najprimernejša storitev Azure Cognitive Services saj je najcenejša ter najenostavnejša rešitev za uporabo.

%----------------------------------------------------------------
% Poglavje (Chapter) 6
%----------------------------------------------------------------
\chapter{Zaključek}
\label{ch8}

Magistrska naloga je obravnavala širok spekter področij obdelave naravnega jezika z uporabo oblačnih ter odprtokodne rešitev Hugging Face Transformers. Cilj raziskave je bil razumeti, kako se različni ponudniki odzivajo na različne izzive in naloge ter določiti njihovo uspešnost na posameznih področjih. Analiza je zajemala prepoznavanje imenskih entitet, analizo sentimenta, povzemanje besedil, luščenje ključnih besed, uvrščanje besedila ter zaznavo objektov.


Na podlagi raziskave smo ugotovili, da se je vsak ponudnik specializiral in izkazal za najboljšega na določenem področju. Pri prepoznavanju imenskih entitet je izstopal AWS SageMaker s svojo natančnostjo. Google Cloud Vertex AI je blestel pri analizi sentimenta, kar je ključno za razumevanje čustev in mnenj v besedilu. Pri povzemanju besedila se je Azure Cognitive Services izkazal kot najboljši, kar poudarja njegovo sposobnost za ustvarjanje povzetkov besedilnih vsebin. Pri luščenju ključnih besed je bila rešitev Azure Cognitive Services v ospredju, saj je omogočala najboljši izvleček bistvenih informacij iz besedil. Hugging Face Transformers je prevzel vodilno vlogo pri analizi sentimenta z natančnostjo določanja čustvenega tona besedil.  AWS SageMaker pa se je izkazal kot močan v zaznavanju objektov.

Vendar pa je pomembno poudariti, da ima vsak ponudnik v oblaku svoje prednosti in omejitve ter da izbira med njimi temelji na specifičnih potrebah in zahtevah uporabnika. Pri izbiri pravega ponudnika je potrebno upoštevati različne faktorje, kot so natančnost, hitrost, stroške, prilagodljivost in integracija z obstoječimi sistemi.

Pomembno je izpostaviti, da so rezultati analize odvisni od specifičnih nalog, modelov in korpusov, ki so bili uporabljeni v tej raziskavi. Prav tako se tehnologije in zmogljivosti ponudnikov v oblaku nenehno razvijajo, zato je pomembno, da podjetja in raziskovalci ostanejo pozorni na nove in izboljšane modele za obdelavo naravnega jezika in zaznavo objektov.

V sklepni fazi je jasno, da noben ponudnik v oblaku ne izstopa kot absolutno najboljši na vseh področjih. Različni ponudniki imajo svoje prednosti in posebne zmogljivosti glede na določene naloge obdelave naravnega jezika. Izbiro ustrezne platforme je torej smiselno prilagoditi specifičnim potrebam in zahtevam. Obetavno pa je  opazovati, kako odprtokodne rešitve, kot je  Hugging Face Transformers pridobivajo na veljavi in omogočajo raziskovalcem in razvijalcem, da izkoristijo najboljše iz več različnih tehnologij.

Zaključimo, da je obdelava naravnega jezika ter zaznave objektov v oblaku zelo dinamično in obetavno področje, ki bo še naprej oblikovalo način, kako napredujemo s tehnologijo in kako razumemo ter uporabljamo jezikovne vsebine v digitalnem svetu.


% ---------------------------------------------------------------
% Appendix
% ---------------------------------------------------------------
%00\appendix
%\addcontentsline{toc}{chapter}{Razširjeni povzetek}
%\chapter{Title of the appendix 1}

%Example of the appendix.

%----------------------------------------------------------------
% SLO: bibliografija
% ENG: bibliography
%----------------------------------------------------------------
\bibliographystyle{elsarticle-num}

%----------------------------------------------------------------
% SLO: odkomentiraj za uporabo zunanje datoteke .bib (ne pozabi je potem prevesti!)
% ENG: uncomment to use .bib file (don't forget to compile it!)
%----------------------------------------------------------------
%\bibliography{bibliography}

%----------------------------------------------------------------
% SLO: zakomentiraj spodnji del, če uporabljaš zunanjo .bib datoteko
% ENG: comment the part below if using the .bib file
%----------------------------------------------------------------

\begin{thebibliography}{99}
\bibitem{hugging} Hugging Face. Dostopno na: \url{https://huggingface.co/learn/nlp-course/chapter1/4}  [Dostopano 10. 06. 2023].
\bibitem{transformers} Transformers. Dostopno na: \url{https://huggingface.co/learn/nlp-course/chapter2/1?fw=pt}  [Dostopano 10. 06. 2023].
\bibitem{google} Google Cloud. Dostopno na: \url{https://cloud.google.com/natural-language#section-1}  [Dostopano 10. 06. 2023].
\bibitem{vertex} Vertex AI. Dostopno na: \url{https://cloud.google.com/vertex-ai}  [Dostopano 10. 06. 2023].
\bibitem{aws} Amazon Web Services (AWS).  Dostopno na: \url{https://aws.amazon.com/}  [Dostopano 10. 06. 2023].
\bibitem{sage} Amazon SageMaker.  Dostopno na: \url{https://aws.amazon.com/sagemaker/}  [Dostopano 10. 06. 2023].
\bibitem{azure} Azure. Dostopno na: \url{https://azure.microsoft.com/en-us}  [Dostopano 10. 06. 2023].
\bibitem{cognitive} Azure Cognitive Services. Dostopno na: \url{https://azure.microsoft.com/en-gb/products/cognitive-services}  [Dostopano 10. 06. 2023].
\bibitem{ner} Named Entity Recognition. Dostopno na: \url{https://www.shaip.com/blog/named-entity-recognition-and-its-types/}  [Dostopano 10. 06. 2023].
\bibitem{sentiment} Sentiment Analysis. Dostopno na: \url{https://aws.amazon.com/what-is/sentiment-analysis/}  [Dostopano 10. 06. 2023].
\bibitem{povzetek} Summarization. Dostopno na: \url{https://huggingface.co/tasks/summarization}  [Dostopano 10. 06. 2023].
\bibitem{luscenje} Keyphrase Extraction. Dostopno na: \url{https://www.geeksforgeeks.org/keyphrase-extraction-in-nlp/}  [Dostopano 10. 06. 2023].
\bibitem{klasifikacija} Text Classification. Dostopno na: \url{https://huggingface.co/tasks/text-classification}  [Dostopano 10. 06. 2023].
\bibitem{object} Object Detection. Dostopno na: \url{https://huggingface.co/tasks/object-detection}  [Dostopano 10. 06. 2023].
\bibitem{truevsfalse} True vs. False and Positive vs. Negative. Dostopno na: \url{https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative}  [Dostopano10. 06. 2023].
\bibitem{conll}Erik F. Tjong Kim Sang and Fien De Meulder  ``Introduction to the CoNLL-2003''. Dostopno na: \url{https://aclanthology.org/W03-0419.pdf}  [Dostopano 10. 06. 2023].
\bibitem{imdb} IMDB Dataset Reviews. Dostopno na: \url{https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews}  [Dostopano 10. 06. 2023].
\bibitem{coco} COCO 2017 Dataset. Dostopno na: \url{https://www.kaggle.com/datasets/awsaf49/coco-2017-dataset}  [Dostopano 10. 06. 2023].
\bibitem{cnn} CNN dailymail Dataset. Dostopno na: \url{https://huggingface.co/datasets/cnn_dailymail}  [Dostopano 10. 06. 2023].
\bibitem{semeval} SemEval-datasetst. Dostopno na: \url{https://www.kaggle.com/datasets/azzouza2018/semevaldatadets?resource=download}  [Dostopano 10. 06. 2023].
\bibitem{accuracy} Accuracy. Dostopno na: \url{https://developers.google.com/machine-learning/crash-course/classification/accuracy}  [Dostopano 10. 06. 2023].
\bibitem{percision} Precision and Recall. Dostopno na: \url{https://developers.google.com/machine-learning/crash-course/classification/precision-and-re