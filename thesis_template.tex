%================================================================
% SLO
%----------------------------------------------------------------
% datoteka: 	thesis_template.tex
%
% opis: 		predloga za pisanje diplomskega dela v formatu LaTeX na
% 				Univerza v Ljubljani, Fakulteti za računalništvo in informatiko
%
% pripravili: 	Matej Kristan, Zoran Bosnić, Andrej Čopar,
%			  	po začetni predlogi Gašperja Fijavža
%
% popravil: 	Domen Rački, Jaka Cikač, Matej Kristan
%
% verzija: 		30. september 2016 (dodan razširjeni povzetek)
%================================================================


%================================================================
% SLO: definiraj strukturo dokumenta
% ENG: define file structure
%================================================================
\documentclass[a4paper, 12pt]{book}


%================================================================
% SLO: Odkomentiraj '\SLOtrue ' za izbiro slovenskega jezika
% ENG: Uncomment '\SLOfalse' to chose English languagge
%================================================================
\newif\ifSLO
\newif\ifTRACKEXIST
\newif\ifTRACKCS
\newif\ifPROGRAMMM

% ---------------------------------------------------------------------------------------
% IMPORTANT: Adjust the thesis language, your study program and course within this block
% ---------------------------------------------------------------------------------------
% switch language
\SLOtrue % Enables Slovenian language
%SLOfalse  % Enables English language

% switch programs: Computer science and Multimedia. Set to false if the program is in Multimedia
\PROGRAMMMfalse
%\PROGRAMMMtrue

% switch on if your program is divided into tracks CS and DS, otherwise leave it false
% CAUTION: if you were first enrolled into your program before school year 2019/2020, your program is not divided into tracks. In any case, be absolutely sure you select the correct variant. IF IN DOUBT, always contact the student office to advise you.
%
 \TRACKEXISTfalse
%\TRACKEXISTtrue

% default course name is 'Computer science' if your course name is 'Data science', set the following switch to false
\TRACKCStrue % uncomment if the thesis is from course 'Information science'
%\TRACKCSfalse % uncomment if the thesis is from course 'Data Science'
% -------------------------------------------------------------------------------------------
% End of language, program and course adjustment
% -------------------------------------------------------------------------------------------


%================================================================
% SLO: vključi oblikovanje in pakete
% ENG: include design and packages
%================================================================
\input{style/thesis_style}

%----------------------------------------------------------------
% |||||||||||||||||||||| USTREZNO POPRAVI |||||||||||||||||||||||
% |||||||||||||||||||||| EDIT ACCORDINGLY |||||||||||||||||||||||
%----------------------------------------------------------------
\newcommand{\ttitle}{Primerjava uspešnosti odprtokodnih in komercialnih orodij za luščenje podatkov}
\newcommand{\ttitleEn}{Performance comparison of open source and commercial information extraction tools}
\newcommand{\tsubject}{\ttitle}
\newcommand{\tsubjectEn}{\ttitleEn}
\newcommand{\tauthor}{Romana Grilj}
\newcommand{\temail}{romana.grilj@gmai.com}
\newcommand{\myyear}{2023}
\newcommand{\tkeywords}{analiza podatkov, ekstrakcija podatkov, strukturni podatki, spletno rudarjenje}
\newcommand{\tkeywordsEn}{Data analysis, Information Retrieval, structural data, Web Mining}
\newcommand{\mysupervisor}{doc.~dr.\ Slavko Žitnik}
%\newcommand{\mycosupervisor}{akad.~prof.~dr.\ Martin Krpan}
% include formatted front pages
\input{style/thesis_front_pages}

%================================================================
% ENG: main pages of the thesis
%================================================================f

%----------------------------------------------------------------
% Poglavje (Chapter) 1
%----------------------------------------------------------------
\chapter{Uvod}
\label{ch:uvod}

Sodobni digitalni svet je priča izjemnemu napredku na področju obdelave naravnega jezika, ki seže preko širokega spektra aplikacij in storitev ter ima pomembno vlogo v sodobnem digitalnem okolju. Sposobnost učinkovitega obvladovanja in analize besedila postajata nepogrešljiva veščina, ki se širi iz informacijskih tehnologij in trženja v številne druge sektorje, vključno z zdravstvom in novinarstvom. Kljub temu se tako večja kot manjša podjetja vsakodnevno soočajo z izzivi, ki jih prinaša obdelava in razumevanje besedilnih in vizualnih podatkov. Eden izmed ključnih izzivov, ki jim lahko olajšave, je povezan s tako imenovanimi tehnikami naravnega jezika  in zaznavo objektov.

Kot najbolj zanimiva poročja v obdelavni naravnega jezika se bomo osredotočili na šest zelo uporabnih ter zanimivih poročij. Prvo področje opisuje prepoznavanje imenskih entitet, katero uporabnikom lahko močno olajša vsakodnevno delo z strankami, saj lahko prepozna imena strnk ter datume v elektronskih sporočilih za lažje sledenje naročilom. Naslenje področje pokriva analizo sentimenta s pomočjo katere uporabniki na družbenih omrežjih lahko ugotovijo, kako se stranke odzivajo na njihove produkte ter s tem prilagajajo svoje produkte glede na rezultate.  Naslednje zelo pomembno področje je povzemanje, ki hitro ustvarja krajše povzetke dolgih poročil in analiz, kar zaposlenim omogoča bolj učinkovito pregledovanje ključnih informacij. Zelo pomembno je tudi prepoznavanje besednih zvez za indetifikacijo ključnih pojmov v strateških dokumentih, kar. Pomaga pri načrtovanju marketinških kompanij in analiz konkurenčnega okolja. Uvrščanje besedil pomaga uporabnikom  pri analizi strankinih mnenj in ocen, kar jim pomaga razumeti, kako se izdelki ali storitve pozicionirajo na trgu v primerjavi z konkurenco. Zadnje področje, ki ga bomo raziskali se na naša na zaznavo objektov, ki jo lahko uporabljamo za nadzor in identifikacijo neželenih oseb ali predmetov na območju objekta, kar prispeva k izboljšani varnosti in nadzoru.

Cilj te magisterske naloge je podrobneje raziskati ter analizirati različne ponudnike storitev za obdelavo naravnega jezika ter zaznavo objektov, uporabo različnih korpusov glede na različna področja uporabe, predstavljene bodo najpogosteje uporabljene metrike za evalvacijo modelov. Potrebno je povdariti, da je na trgu prisotnih veliko storitev, tako za velika podjetja kot tudi za končne uporabnike. Opazimo lahko tudi veliko število odprtokodnih rešitev, ki so lahko nekoliko specifična glede na področje uporabe.

V nadaljevanju se bomo osredotočili na pomembnost kakovostnih korpusov za uspešno učenje modelov. Pregledali bomo obstoječe in priljubljene korpuse, ki se uporabljajo za različne naloge.
Kot ključen element bomo preučili metrike za ocenjevanje učinkovitosti modelov, kot so priklic, Ocena F1, ROUGE in druge. Razložili bomo, kako se uporabljajo za različne naloge in kako lahko z njimi ocenimo zmogljivost modelov.

Nato se bomo posvetili raznolikim področjem uporabe tehnologij obdelave naravnega jezika. Raziskali bomo, kako se tehnologije uporabljajo v  analizi čustev, povzemanje, iskanju informacij in še več. Preučili bomo tudi izzive in omejitve, s katerimi se srečujejo modeli pri uporabi na različnih področjih.

V poglavju  najpogosteje uporabljenih algoritmov (poglavje~\ref{ch4}) bomo podrobneje spoznali izbrane funkcionalnosti, ki jih omogočajo modeli, ki temeljijo na umetni inteligenci in strojnem učenju ter so zasnovane za obdelavo, razumevanje in generiranje naravnega jezika. Različni modeli se uporabljajo za reševanje različnih nalog, povezanih z obdelavo jezika, kot so avtomatsko prevajanje, analiza čustev, razumevanje besedil, odgovarjanje na vprašanja, izluščevanje informacij iz besedil, uvrščanje besedil in še več.

V poglavju o korpusih (glej poglavje~\ref{ch5}) bomo podrobneje spoznali uporabljene korpuse, ki so ključnega pomena za uspešen razvoj, učenje in evalvacijo modelov. Korpusi so zbirke podatkov, ki so ročno označeni ali označeni s pomočjo algoritmov za različne naloge.

V poglavju o metrikah temeljito raziskali različne metrike (glej poglavje~\ref{ch6}), ki omogočajo oceno učinkovitosti modelov glede na njihove specifične naloge. Raznolikost nalog na področju obdelave naravnega jezika zahteva prilagodljivost pri izbiri metrik. Predstavljene bodo ključne metrike, ki jih bodo uporabljene pri evalvaciji modelov.



Pridobili bomo pregled nad uporabo modelov ter njihovo uporabo za različna področja. Cilj raziskave je prispevati k boljšemu razumevanju  tehnologij obdelave naravnega jezika ter zaznave objektov in predstaviti rezultate med različnimi ponudkniki storitev.

\subsection{Motivacija in ciji }

Sodobni digitalni svet je priča izjemnemu napredku na področju obdelave naravnega jezika, ki seže preko širokega spektra aplikacij in storitev ter ima pomembno vlogo v sodobnem digitalnem okolju. Sposobnost učinkovitega obvladovanja in analize besedila postajata nepogrešljiva veščina, ki se širi iz informacijskih tehnologij in trženja v številne druge sektorje, vključno z zdravstvom in novinarstvom. Kljub temu se tako večja kot manjša podjetja vsakodnevno soočajo z izzivi, ki jih prinaša obdelava in razumevanje besedilnih in vizualnih podatkov. Eden izmed ključnih izzivov, ki jim lahko oljša, je povezan s tako imenovanimi tehnikami naravnega jezika  in zaznavo objektov.

Umetna inteligenca je v današnjem času ključna za številna področja. AI modeli se uporabljajo v različnih industrijah, kot so računalniški vid  (angl:Computer Vision),  analiza zvoka (angl: Audio), obdelava tabelarnih podatkov (angl: Tabular), okrepitveno učenje (angl: Reinforcement Learning), večmodalni pristop (angl:Multimodal), prepoznavanje govora (angl:Speech), odločitveno modeliranje (angl:Decision Making) in analitika podatkov (angl:Analytics) . Vendar se bomo v naši raziskavi osredotočili na dve ključni področji: obdelavo naravnega jezika, ki se ukvarja z razumevanjem in generiranjem besedil, ter zaznavanje objektov (angl:Object detection), ki omogoča identifikacijo objektov v slikah in videoposnetkih.

Kot najbolj zanimiva poročja v obdelavni naravnega jezika se bomo osredotočili na šest zelo uporabnih ter zanimivih poročij. Prvo področje opisuje prepoznavanje imenskih entitet, katero uporabnikom lahko močno olajša vsakodnevno delo z strankami, saj lahko prepozna imena strnk ter datume v elektronskih sporočilih za lažje sledenje naročilom. Naslenje področje pokriva analizo sentimenta s pomočjo katere uporabniki na družbenih omrežjih lahko ugotovijo, kako se stranke odzivajo na njihove produkte ter s tem prilagajajo svoje produkte glede na rezultate.  Naslednje zelo pomembno področje je povzemanje, ki hitro ustvarja krajše povzetke dolgih poročil in analiz, kar zaposlenim omogoča bolj učinkovito pregledovanje ključnih informacij. Zelo pomembno je tudi prepoznavanje besednih zvez za indetifikacijo ključnih pojmov v strateških dokumentih, kar. Pomaga pri načrtovanju marketinških kompanij in analiz konkurenčnega okolja. Uvrščanje besedil pomaga uporabnikom  pri analizi strankinih mnenj in ocen, kar jim pomaga razumeti, kako se izdelki ali storitve pozicionirajo na trgu v primerjavi z konkurenco. Zadnje področje, ki ga bomo raziskali se na naša na zaznavo objektov, ki jo lahko uporabljamo za nadzor in identifikacijo neželenih oseb ali predmetov na območju objekta, kar prispeva k izboljšani varnosti in nadzoru.

V nadaljevanju bomo prevrili kateri so najboljši odprtokodni ponudniki na trgu in izbrali enega izmed najboljših ter naredili primerjavo z najbolj prepoznavnimi oblačnimi ponudniki. Trenutno so na trgu najbolj prepoznavni Google Cloud, Microsoft  Azure ter Amazon Web Services . 

Za merjenje uspešnosti posameznega področja, bomo uporabili dobro uveljavljene in standardne metrike. Te metrike predstavljajo ključno orodje za oceno učinkovitosti različnih rešitev na izbranem področju.

Cilj magistrske naloge je raziskati, kateri ponudnik je najboljši na določenem področju, ter na podlagi analize cenovne ugodnosti, enostavnosti uporabe in uspešnosti določiti, katerega ponudnika se najbolj izplača izbrati.

\subsection{Prispevki}
Magistrska naloga bo temeljila na obsežni analizi specifičnih področij naravnega jezika in obdelave slik. Naša raziskava bo usmerjena v prepoznavanje najboljših ponudnikov za vsako od teh izbranih področij. Osredotočili se bomo na razumevanje, kateri ponudniki na teh področjih izstopajo in kako se primerjajo glede na pomembne dejavnike, kot so cenovna konkurenčnost, uspešnost ter enostavnost uporabe njihovih rešitev.

Glavni cilj magistrske naloge bo organizacijam in posameznikom pomagati pri odločitvi, kateri ponudnik obdelave naravnegajezika in slik rešitev je najbolj primeren za njihove specifične potrebe. S tem bomo izvedli poglobljeno analizo in preverili, kako se posamezni ponudniki odrežejo na različnih področjih uporabe naravnega jezika  in obdelave slik.

Naš prispevek bo poudaril, kateri ponudnik ponuja najboljšo kombinacijo cenovne ugodnosti, visoke uspešnosti in enostavne uporabe na izbranih področjih. S tem bomo zagotovili bolj preučene odločitve in pripomogli k uspešni uporabi teh tehnologij na raznolikih področjih.
%----------------------------------------------------------------
% Poglavje (Chapter) 2
%----------------------------------------------------------------

%----------------------------------------------------------------
% Poglavje (Chapter) 3
%----------------------------------------------------------------

%----------------------------------------------------------------
% Poglavje (Chapter) 4
%----------------------------------------------------------------

%----------------------------------------------------------------
% Poglavje (Chapter) 5
%----------------------------------------------------------------


%----------------------------------------------------------------
% Poglavje (Opis funkciionalnosti) 5
%----------------------------------------------------------------
\chapter{Opis ponudnikov in storitev}
\label{ch3}
Izbrani ponudniki so bili Google Cloud, Amazon Web Services in Microsoft Azure, saj so bili po raziskavi na spletu prepoznani kot najbolj razširjeni in zanesljivi oblačni ponudniki na trgu. 

V članku je Marek Hernans naredil raziskavo stotih najboljših oblačnih ponudnikov storitev\cite{najboljsi_cloud}, kjer poudari da so trenutno vodillni Google Cloud, Microsoft in Amazon Web Services ponudniki.  

Prav tako Paulo Gardini Miguel v svojem članku, kjer naredi analizo najboljših 23 ponudnikov\cite{najboljsi1_cloud} potrdi da je na prvem mestu najboljši ponudnik Amazon Web Services na drugem mestu Microsoft Azure, ter na tretjem mestu Google Cloud. 

Za analizo je bila uporabljena odprtokodna platforma Hugging Face Transformers, ki je po objavljenih člankih dosegla najboljše rezultate. Platforma je bila je prepoznana kot izjemno učinkovita in zmogljiva, ki se je odlično izkazala pri obdelavi različnih nalog.

Pri raziskavi se tako ODSC (ang. Open Data Scince)\cite{hf1} kot tud Juliette iz NLP Cloud portala\cite{hf2} soupadata z mnenem da je Hugging Face najboljša izbira pri odprtokodnih podnudnikih. Saj je ponudnik pri katerem je enostavno uporabljati, ter dodajati nove modele. 

\section{Hugging Face}
\label{sec:transformers}
Hugging Face je platforma na področju obdelave naravnega jezika in strojnega učenja. Njihova rešitev je postala zelo uporabna na področju raziskav, razvoja in uporabe strojnega učenja. 

Njihova glavna odprtokodna knjižnica Hugging Face Transformers je postala temelj raziskav obdelave naravnega jezika, saj ponuja več kot 315.000 modelov, kot so GPT, BERT, RoBERTa in drugih, ki so ključni za različne naloge, vključno z razumevanjem jezika, strojnim prevajanjem, analizo čustev in generiranjem besedila.

Hugging Face Hub \cite{hugging} je platforma, ki spodbuja sodelovanje in izmenjavo med raziskovalci, razvijalci in navdušenci nad strojnim učenjem. Ta platforma omogoča enostavno odkrivanje modelov, kar olajša razvoj novih aplikacij in omogoča dostop do vnaprej treniranih modelov.
Področje obdelave naravnega jezika je prvič bilo na voljo leta 2017. Podpora različnih jezikov je pogojena v prvi vrsti z izbiro modela.

Vizija Hugging Face je ''demokratizirati'' obdelavo naravnega jezika in postati ''Github strojnega učenja''.

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=9cm]{transf.png}
\end{center}
\caption{Hugging Face}
\label{pic2}
\end{figure}

\subsection{Hugging Face Transformers }
Hugging Face Transformers \cite{transformers} je odprtokodna knjižnica, ki je postala ena najpomembnejših orodij za obdelavo naravnega  jezika in strojnega učenja. Njen cilj je ponuditi razvijalcem enostaven dostop do najnovejših arhitektur in modelov. Zgrajena je na osnovi Pythona in je postala ključno orodje za reševanje izzivov na področju obdelave naravnega jezika in razvoja aplikacij ter storitev.

Ena od ključnih prednosti Hugging Face Transformers je enostavnost uporabe. Razvijalci lahko z nekaj vrsticami kode dostopajo do pred-treniranih modelov za takojsno uporabo. Med drugim knjižnica omogoča tudi prilagajanje modelov in ponuja odprtokodno skupnost, ki nenehno prispeva z novimi modeli, izboljšavami in rešitvami.

Knjižnica ponuja tudi funkcionalnosti za preprosto prenosljivost modelov med različnimi platformami in orodji za povečanje učinkovitosti uporabe modelov na različnih sistemih. Med drugim Hugging Face Transformers omogoča tudi preprosto združevanje z drugimi knjižnicami za strojno učenje in obdelavo podatkov.  

Podpora različnih jezikov je pogojena v prvi vrsti z izbiro modela.
Transformerji ponujajo širok nabor storitev za obdelavo naravnega jezika in sicer: uvrščanje besedil, prevajanje, povzemanje, znakovno uvrščanje, tabela vprašanj odgovorov, odgovori na vprašanja, razvrščanje brez vzorcev, klepet, generiranje besedila, dodajanje mankajočih besed, podobnost besed, in druge.


\section{Google Cloud}
\label{sec:google}
Google Cloud\cite{google}  je vodilna platforma za računalništvo v oblaku, ki zagotavlja široko paleto storitev in rešitev za podjetja in razvijalce. Ta platforma omogoča shranjevanje in obdelavo podatkov, razvoj aplikacij, umetno inteligenco, strojno učenje in še veliko več.

Google Cloud podpira številne storitve za shranjevanje podatkov, vključno z Cloud Storage, Cloud SQL in Cloud Bigtable, ki omogočajo enostavno in zanesljivo shranjevanje ter upravljanje podatkov v oblaku. Poleg tega omogoča obdelavo podatkov s storitvami, kot so Google Cloud Dataflow in BigQuery, ki omogočajo analizo in obdelavo podatkov v realnem času.

Kar zadeva umetno inteligenco, Google Cloud ponuja številne storitve in orodja za razvoj, usposabljanje in razporejanje modelov strojnega učenja. Na primer, Google Cloud AutoML omogoča enostavno ustvarjanje strojno učenih modelov brez potrebe po globokem strojnem znanju. Poleg tega platforma podpira tudi TensorFlow in PyTorch za razvoj naprednih modelov.

Ko se osredotočimo na obdelavo naravnega jezika, Google Cloud ponuja močne rešitve, kot je Vertex AI, ki omogoča analizo besedil, razumevanje sentimenta in identifikacijo entitet v besedilih. Poleg tega Cloud Translation omogoča prevajanje besedil med različnimi jeziki, kar je koristno za globalna podjetja in aplikacije.

Poleg tega je Google Cloud Vertex AI postala nepogrešljiva platforma za razvoj aplikacij s področja NLP. S svojimi zmogljivostmi za upravljanje podatkov, treniranje modelov in avtomatizacijo razvojnega cikla omogoča hitro in učinkovito razvijanje in razširjanje modelov za obdelavo naravnega jezika. Vertex AI prinaša napredne tehnologije, kot so transformerski modeli, ki so postali temeljni gradnik v razvoju najnovejših NLP aplikacij. S tem omogoča razvijalcem ustvarjanje bolj natančnih in zmogljivih sistemov za razumevanje in generiranje besedila, kar ima velik vpliv na različna področja, od obdelave besedilnih podatkov do avtomatizacije odzivanja na stranke. Vertex AI tako omogoča razvijalcem, da izkoristijo najnovejše dosežke na področju NLP in jih vključijo v svoje aplikacije ter izboljšajo uporabniško izkušnjo in učinkovitost svojih sistemov.


Področje obdelave naravnega jezika je bilo dodano v Google Cloud leta 2015. Ponuja več kot 100 različnih modelov, najbolj prepoznavni modeli so OWL-ViT, BERT ter PaLM, kateri se uporablja za obdelavo naravnega jezika.


 \begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm]{google.png}
\end{center}
\caption{Google Cloud storitve}
\label{pic2}
\end{figure}
 \newpage
\subsection{Vertex AI }
Vertex AI \cite{vertex} je napredna platforma za umetno inteligenco v oblaku, ki jo ponuja Google Cloud. S podporo za številne priljubljenena ogrodja za strojno učenje, kot so TensorFlow ter PyTorch je Vertex AI odlična izbira za razvijalce z različnimi potrebami in izkušnjami.
Platforma Vertex AI ponuja tudi številne napredne storitve in orodja za razvoj in optimizacijo modelov. Vključuje integrirano orodje, ki omogoča hitro in enostavno oceno uspešnosti modelov na različnih primerih rabe. Prav tako ponuja samodejno prilagajanje hiperparametrov, kar omogoča avtomatsko iskanje najboljših hiperparametrov za izboljšanje zmogljivosti modelov. 
Prvotno je bila izdana leta 2020 in ima že več kot 100.000 uporabnikov po vsem svetu. Uporabljajo jo raznolika podjetja, od majhnih startupov do velikih korporacij, kot so Walmart, Pfizer in Coca-Cola.
Podpirajo kar 11 različnih jezikov in sicer:  Angleščina, Francoščina, Nemščina, Španščina, Kitajščina (poenostavljena), Kitajščina (tradicionalna), Japonščina, Korejščina, Portugalščina ter Ruščina. 

Vertex AI ponujaja širok nabor storitev za obdelavo naravnega jezika in sicer: analiza sentimenta, analiza entitete, povzemanje, izvleček besedne zveze analiza sintakse, vsebinsko uvrščanje in ostale.   
Vertex AI lahko uporabljamo z več programskimi jeziki kot so: Go, Java, Node.js, Python. 

Ena od ključnih funkcij Vertex AI je tudi funkcija Vertex Data Labeling, ki omogoča enostavno označevanje podatkov za učenje modelov. 

\section{Amazon Web Services }
\label{sec:aws}
Amazon Web Services\cite{aws} je ena izmed platform za računalniške storitve v oblaku, ki ponuja širok nabor storitev za podjetja in razvijalce. Zagotavlja zmogljivosti za shranjevanje podatkov, obdelavo, analizo, varnost in dostop do oblačnih virov za izvajanje aplikacij in storitev na globalni ravni. Med glavnimi področji, ki jih podpira, so računalništvo v oblaku, shranjevanje, mreženje, baza podatkov, analitika, umetna inteligenca, strojno učenje in obdelava naravnega jezika.

V kontekstu obdelave naravnegajezika se uveljavlja kot močna platforma za razvoj in izvajanje aplikacij. AWS ponuja storitve, kot je SageMaker, ki omogočajo analizo besedil in razumevanje sentimenta, jezika ter entitet v besedilih. Amazon Transcribe omogoča pretvorbo govora v besedilo, medtem ko Amazon Polly omogoča sintezo besedila v govor. Poleg tega AWS omogoča tudi gradnjo naprednih modelov obdelave naravnega jezika s storitvijo Amazon SageMaker.

Amazon SageMaker je platforma za strojno učenje, ki omogoča razvijalcem in strokovnjakom za podatke gradnjo, usposabljanje in izvajanje modelov strojnega učenja. Z SageMakerjem lahko enostavno ustvarimo modele za različne naloge. Storitev ponuja orodja za obdelavo in analizo besedila, izboljšano prepoznavanje besed in ustvarjanje visoko zmogljivih modelov za NLP aplikacije. Poleg tega omogoča avtomatizacijo celotnega cikla strojnega učenja, kar pospešuje razvoj in implementacijo NLP projektov v okviru AWS ekosistema. SageMaker je zato ključna komponenta za razvoj naprednih NLP rešitev na platformi Amazon Web Services.

Področje obdelave naravnega jezika je bilo dodano leta 2017. V Evropi pa je bil dostopen šele leto kasneje. Ponuja več kot 500 vnaprej treniranih modelov, med njimi lahko najdemo 
Mobilenet, YOLO, Faster R-CNN, BERT, lightGBM ter druge.

Podpora različnih jezikov je pogojena v prvi vrsti z izbiro modela.



 \begin{figure}[h!]
\begin{center}
\includegraphics[width=8cm]{amazonAWS1}
\end{center}
\caption{Amazon Web Services storitve}
\label{pic2}
\end{figure}


\subsection{Amazon SageMaker}
Amazon SageMaker \cite{sage} je storitev za strojno učenje, ki jo ponuja Amazon Web Services. Omogoča hitro in enostavno izgradnjo, usposabljanje in razporejanje zmogljivih modelov, kar omogoča razvoj naprednih rešitev in izboljšanje procesov. Ponuja intuitiven uporabniški vmesnik in API-je, ki omogočajo hitro postavitev in upravljanje. SageMaker ponuja tudi integrirano okolje Jupyter, ki omogoča uporabo interaktivnih beležnic za raziskovanje in analizo podatkov. 

Amazon SageMaker ponujaja širok nabor storitev za obdelavo naravnega jezika in sicer: uvrščanje besedil, analiza sentimenta, prepoznavanje imenskih entitet, prevanjanje, povzemanje ter druge. 

Uporabljamo ga lahko z pomočjo dveh različnih programskih jezikov R ter Python. 

Področje obdelave naravnega jezika je bilo dodano leta 2017. 

\section{Microsoft Azure}
\label{sec:azure}
Microsoft Azure\cite{azure}  je oblačna platforma, ki omogoča organizacijam, da razvijajo, upravljajo in gostujejo svoje aplikacije ter storitve v varnem in skalabilnem okolju. Azure ponuja širok nabor storitev in funkcionalnosti, ki podpirajo različna področja, vključno z računalništvom v oblaku, infrastrukturnimi storitvami, kot so virtualni stroji in omrežna infrastruktura, razvojem in upravljanjem aplikacij, oblačnimi storitvami za podatkovno analitiko in umetno inteligenco ter varnostjo in upravljanjem identitet. Na področju računalništva v oblaku Azure omogoča uporabnikom, da svoje aplikacije izvajajo v skalabilnem in visoko razpoložljivem okolju, ki se samodejno prilagaja obremenitvam. V področju razvoja aplikacij Azure ponuja različne storitve za razvijalce, kot so Azure App Service, Azure Functions in Azure DevOps, ki olajšajo razvoj in testiranje aplikacij. Poleg tega Azure omogoča tudi oblačno shranjevanje in obdelavo podatkov. Ponuja storitve za učinkovito upravljanje ter hranjenje podatkovnih baz in drugih virov. Na področju umetne inteligence in obdelave naravnega jezika pa Azure omogoča uporabo naprednih analitičnih algoritmov, strojnega učenja in globokih nevronskih mrež za reševanje kompleksnih nalog na področju razumevanja in generiranja naravnega jezika.

Azure Cognitive Services ponuja izjemno zmogljive in specializirane funkcionalnosti na področju obdelave naravnega jezika in slik. Podpira različne naloge v povezavi z obdelavno naravnega jezika, vključno s prepoznavanjem in analizo besedila, prevajanjem besedil med jeziki, določanjem sentimenta v besedilih, izvajanjem poizvedb v naravnem jeziku (NLP Search), prepoznavanjem imenovanih entitet, in še veliko več. Na primer, organizacije lahko uporabljajo Azure Cognitive Services za avtomatizacijo odgovarjanja na vprašanja strank prek chatbotov, za analizo sentimenta na družbenih omrežjih, za prepoznavanje ključnih informacij v besedilih, kot so datumi ali kraji, ter za strojno prevajanje med različnimi jeziki. 


Področje obdelave naravnega jezika je bilo dodano leta 2018. Ponuja 26 osnovnih modelov, ki so pripravljeni za takojšno uporabo. Kot zanimivost lahko omenimodva svetovo poznana modela text-davinci-003 ter GPT-35-turbo, ki je svetovo znan kot ChatGPT. 

Ponuja široko podporo različnim jezikom, skupno več kot 96. Nekateri izmed njih so: Angleščina, Finščina, Francoščina, Danščina ter druge. Pomembo bi bilo izpozstaviti da pordpira tudi Slovenski jezik.   

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=14cm]{MS.png}
\end{center}
\caption{Microsoft Azure storitve}
\label{pic2}
\end{figure}

\subsection{Azure Cognitive Services }
Azure Cognitive Services \cite{cognitive} je celovita in napredna platforma za umetno inteligenco, ki jo ponuja Microsoftova platforma Azure. Te storitve omogočajo analizo in Microsoft Azure je vodilna platforma za računalništvo v oblaku, ki zagotavlja širok nabor storitev in zmogljivosti za organizacije in razvijalce. Podpira gostovanje virtualnih strojev, omogoča razvoj in upravljanje aplikacij s pomočjo aplikacijskih strežnikov, kot so Azure App Service in Azure Functions, ter ponuja različne podatkovne storitve, vključno s SQL Database, Cosmos DB in Azure Synapse Analytics.
Kar zadeva naravno obdelavo jezika (NLP), je Azure izredno zmogljiv. Omogoča razvijalcem, da ustvarijo aplikacije in rešitve, ki razumejo, analizirajo in generirajo človeški jezik. Azure ponuja številne orodja in storitve za podporo NLP, vključno s strojnim učenjem, globokim učenjem in analizo besedila.

Azure Cognitive Services so ključni del Azure-jevih zmogljivosti za NLP. Te storitve uporabljajo napredne algoritme in modele, da omogočijo razvoj aplikacij za razumevanje govora, prepoznavo besedila, prevajanje jezikov, analizo sentimenta in še več. 

S pomočjo Azure Cognitive Services lahko razvijalci enostavno integrirajo obdelavo naravnega jezika v svoje aplikacije in storitve, ne da bi morali globoko razumeti podrobnosti obdelave jezika. To omogoča hitrejši razvoj in uporabo naprednih aplikacij, ki lahko razumejo, komunicirajo in se odzivajo na človeški jezik, kar pa povečuje uporabniško izkušnjo in funkcionalnost številnih aplikacij v različnih panogah. Azure Cognitive Services tako prispevajo k razvoju bolj inteligentnih in interaktivnih aplikacij ter spodbujajo inovacije na področju naravne obdelave jezika.

Azure podpira kontejnerizacijo z orodji, kot sta Azure Kubernetes Service in Azure Container Instances, za enostavno upravljanje in orkestracijo kontejnerjev. Za razvojnih skupin ponuja Azure DevOps orodja za upravljanje procesov razvoja in nenehno dostavo aplikaciij. 



Azure Cognitive Services ponujaja širok nabor storitev za obdelavo naravnega jezika in sicer: prepoznavanje imenskih entitet, sentimentalna analiza, odgovarjanje na vprašanja, prevajanje ter druge. 

Uporabljamo ga lahko z pomočjo več različnih programskih jezikov, kot so: C\#, Java, JavaScript ter Python. 


 \begin{figure}[h!]
\begin{center}
\includegraphics[width=14cm]{tabela_ponudniki.png}
\end{center}
\caption{Primerjava ponudnikov glede na ceno in funkcionalnosti}
\label{pic2}
\end{figure}
 \newpage
V tabeli so predstavljeni stroški uporabe posameznih storitev. Pri nekaterih je potrebno plačati le virtualna okolja, za Azure Cognitive Services pa plačamo glede na zahtevke. Pomembno je omeniti, da je v tabeli uporabljena cena za Hugging Face Transformers, katere lahko uporabljamo brez uporabe plačljive infrastrukture. 
%----------------------------------------------------------------
% Poglavje (Opis funkciionalnosti) 5
%----------------------------------------------------------------
\chapter{Izbrana področja uporabe}
V tem poglavju se bomo podrobneje posvetili analizi izbranih področij obdelave naravnega jezika in zaznave objektov. Na področju obdelave naravnega jezika bomo izvedli celovito analizo na enem konkretnem primeru, ki bo zajemal vse ključne vidike tega področja. Hkrati pa se bomo osredotočili na obdelavo slik, pri čemer bomo prav tako uporabili en primer za poglobljeno analizo.


\begin{center}
Besedilo za ponazoritev analize:
\label{ex1}

\fbox{\begin{minipage}[h!]{29em}
The tower is 324 metres tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres on each side. During its construction, the Eiffel Tower surpassed the Washington Monument  to become the tallest man-made structure in the world. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler. The Eiffel Tower is connected with an organization known as the Société d'Exploitation de la Tour Eiffel or the Eiffel Tower Operating Company  in English . It was designed by the French engineer Gustave Eiffel.
\end{minipage}}
\end{center}


\section{Najpogosteje uporabljeni algoritmi po področjih uporabe}

 Različni algoritmi strojnega učenja se uporabljajo za različne naloge, najboljši algoritem za uporabo pa je odvisen od specifičnega problema. Na primer, linearna regresija je dobra izbira za naloge, pri katerih je potrebno napovedati stalno vrednost, kot je cena hiše. Logistična regresija je dobra izbira za naloge, pri katerih morate predvideti kategorično vrednost, na primer, ali je e-poštno sporočilo nezaželjeno ali ne. Odločitvena drevesa so dobra izbira za naloge, pri katerih se je potrebno odločiti na podlagi niza funkcij, na primer, ali odobriti posojilo ali ne. SVM-ji so dobra izbira za naloge, pri katerih morate ločiti podatkovne točke v različne razrede, kot je razvrščanje slik kot mačk ali psov. K najbližjih sosedov je dobra izbira za naloge, kjer morate poiskati podobne podatkovne točke, kot je priporočanje izdelkov strankam. 
 
 Za prepoznavanje imenskih entitet  v naravnem jeziku je najbolj poznan algoritem CRF\cite{ner_clanek}, ki se uporablja zaradi svoje visoke natančnosti in učinkovitosti. Uporablja se v številnih aplikacijah, ki zahtevajo identifikacijo imenskih entitet, kot so prepoznavanje imen oseb, krajev, organizacij ter druge.
 

Pri analizi sentimenta so med najbolj znanimi algoritmi Naive Bayes, Support Vector Machine,  Logistic Regression, Decision Tree, Maximum Entropy  ter K-nearest Neighbors\cite{sent_clanek}. Ti algoritmi se uporabljajo za določanje čustvenega tona v besedilu, kot je pozitivn, negativen ali nevtralen. Pri izbiri ustreznega algoritma za analizo sentimenta je ključno upoštevati specifične potrebe naloge in raznolikost podatkov. 

Za povzemanje besedila sta najpogosteje uporabljena algoritema PageRank in TextRank\cite{summ_clanek}.
Za luščenje ključnih besed je napogosteje uporabljen algoritem TextRank\cite{kljucne_clanek}. 
Pri uvrščanju besedila je najpogosteje uporabljen algoritem SVM\cite{summ_clanek}. 
Pri zazavi objektov so najogosteje uporabljeni R-CNN, R-FCN, FPN, in Casecade R-CNN algoritmi\cite{zaznava_clanek}.

\label{ch4}
\section{Prepoznavanje imenskih entitet}
\label{sec:ner}
Prepoznavanje imenskih entitet\cite{ner} je tehnika na področju obdelave naravnega jezika, ki se uporablja za prepoznavanje in uvrščanje besed v besedilu. Te posebne vrste so imenovane entitete, kot so imena oseb, organizacij, lokacij, datumov, številk, denarnih zneskov in drugih specifičnih poimenovanj.

Cilj je prepoznati in določiti začetek in konec posameznih entitet v besedilu ter jim pripisati ustrezno kategorijo.

Številne praktične uporabe:
\begin{enumerate}
 \item  Avtomatsko označevanje imenskih entitet v novicah, člankih in drugih besedilnih vsebinah.
 \item Razumevanje strukture in vsebine dokumentov za informacijsko iskanje in kategorizacijo.
 \item Pomoč pri analizi sentimenta, kjer želimo razumeti, kako se osebe, organizacije ali druge entitete omenjene v besedilu nanašajo na določeno temo ali izdelek.
\end{enumerate}
 
Primer prepoznavanja imenskih entitet:
\begin{center}
\fbox{\begin{minipage}[h!]{29em}
The tower is 324 metres tall, about the same height as an 81-storey building, and the tallest structure in \colorbox{blue!50}{Paris} \textcolor{blue!50}{{\textbf{\tiny (LOC)}}} . Its base is square, measuring 125 metres on each side. During its construction, the \colorbox{blue!50}{Eiffel Tower} \textcolor{blue!50}{{\textbf{\tiny (LOC)}}} surpassed the \colorbox{blue!50}{Washington Monument} \textcolor{blue!50}{{\textbf{\tiny (LOC)}}}   to become the tallest man-made structure in the world. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the \colorbox{brown!50}{Chrysler} \textcolor{brown!90}{{\textbf{\tiny (ORG)}}}. \colorbox{blue!90}{Eiffel Tower} \textcolor{blue!50}{{\textbf{\tiny (LOC)}}} is connected with an organization known as the \colorbox{brown!50}{Société d'Exploitation de la Tour Eiffel} \textcolor{brown!90}{{\textbf{\tiny (ORG)}}} or the \colorbox{brown!50}{Eiffel Tower Operating Company} \textcolor{brown!90}{{\textbf{\tiny (ORG)}}}  in \colorbox{gray!90}{English} \textcolor{gray!90}{{\textbf{\tiny (MISC)}}}. It was designed by the French engineer \colorbox{red!70}{Gustave Eiffel} \textcolor{red!70}{{\textbf{\tiny (PER)}}}.
\end{minipage}}
\end{center}



\section{Analiza sentimenta}
Analiza sentimenta \cite{sentiment} je proces določanja čustvenega odziva, nagnjenosti ali stališča zapisanega besedila. Cilj analize sentimenta je ugotoviti, ali je določeno besedilo pozitivno, negativno ali nevtralno. To je lahko koristno pri analizi mnenj strank, razumevanju čustvenega odziva na izdelke, blagovne znamke, dogodke in druge. 


 Obstaja več pristopov k analizi sentimenta:
\begin{enumerate}
 \item Pravilni pristopi: Uporabljajo se predvsem pravila in vzorci za identifikacijo pozitivnih in negativnih izrazov v besedilu. Na primer, besede, kot so 'dobro', 'fantastično', 'radostno' itd., bi bile označene kot pozitivne, medtem ko bi bile besede, kot so 'slabo','žalostno', 'neznosno' in tako dalje označene kot negativne.
 \item Strojno učenje na podlagi besedila: Ta pristop vključuje uporabo algoritmov strojnega učenja, ki so naučeni prepoznati čustveni naboj besed v besedilu na podlagi velikega števila označenih podatkov (besedil s čustvenimi oznakami). 
 \item Analiza sentimenta s čustvenimi slovarji: Ta pristop vključuje uporabo slovarjev z besedami in izrazoslovjem, ki so povezani z določenimi čustvi. Besedilo se nato preveri in oceni glede na prisotnost pozitivnih ali negativnih besed iz čustvenih slovarjev.
 \end{enumerate}
 

\begin{table}[h!]
\centering
\caption{Rezultat sentimentalne analize besedila dodanega v začetku poglavja (glej začetek poglavja~\ref{ex1})}
\label{my-label}
%\resizebox{\textwidth}{!}{%
\resizebox{!}{0.09\textheight}{
\begin{tabular}{lrrrrrr}
\multicolumn{1}{r}  \textbf{sentiment}      & verjetnost               \\ \hline    \hline                                                                                                                                                                                                                                                                                                                                       
pozitiven   & 0.557                                                                      \\
\hline
nevtralen  & 0.437                                                    \\
\hline
negativen   & 0.006                           \\

\hline\hline                                                                   
\end{tabular}}
\end{table}


\newpage
 \section{Povzemanje besedila}
Pri povzermanju besedila \cite{povzetek} gre za postopek ustvarjanja krajšega in jedrnatega povzetka iz daljšega besedila, kot je članek ali dokument. Namen povzemanja je izluščiti ključne informacije in ideje iz izvornega besedila ter jih predstaviti na bolj pregleden in krajši način. To je zelo koristno pri velikih količinah podatkov, ko želimo hitro pridobiti bistvo informacij, ne da bi brali celotno besedilo.

Tehnike za povzemanje uporabljajo različne algoritme in metode, ki vključujejo strojno učenje in obdelavo naravnega jezika, da bi učinkovito izluščile ključne besede, stavke ali odstavke, ki predstavljajo osrednje ideje v izvornem besedilu. Rezultat je običajno kratek povzetek, ki ohranja pomembne informacije iz izvirnega besedila. Ta tehnologija ima širok spekter uporabe, kot so samodejno povzemanje novic, generiranje opisov izdelkov, izdelava povzetkov raziskovalnih člankov in še veliko več. 


Rezultat povzemanja besedila dodanega v začetku poglavja (glej začetek poglavja~\ref{ex1}):
\begin{center}
\fbox{\begin{minipage}[h!]{29em}
The tower is 324 metres tall, about the same height as an 81-storey building. Its base is square, measuring 125 metres on each side. During its construction, it surpassed the Washington Monument to become the tallest man-made structure in the world. Due to the addition of a broadcasting aerial at the top of the tower, it is now taller than the Chrysler.
\end{minipage}}
\end{center}

 
 \section{Prepoznavanje besedih zvez}
Prepoznavanje besedih zvez  \cite{luscenje}  se nanaša na besede ali izraze, ki so najpomembnejši ali najbolj značilni za določeno besedilo ali dokument. Te besede so običajno tiste, ki nosijo ključne informacije ali so bistvene za razumevanje vsebine.

Je pomembna naloga, saj nam omogoča, da hitro ugotovimo, o čem govori določeno besedilo. Te besede so lahko uporabne tudi za avtomatsko indeksiranje dokumentov, iskanje relevantnih informacij in razumevanje teme besedila brez potrebe po branju celotnega besedila.

Rezultat prepoznavanja besedih zvez besedila dodanega v začetku poglavja (glej začetek poglavja 3):
\begin{center}
\fbox{\begin{minipage}[h!]{29em}
The tower is 324 metres tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres on each side. During its construction, the \colorbox{gray!90}{Eiffel Tower} \textcolor{gray!90}{{\textbf{\tiny (KEY)}}} surpassed the \colorbox{gray!90}{Washington Monument} \textcolor{gray!90}{{\textbf{\tiny (KEY)}}}  to become the tallest man-made structure in the world. Due to the addition of a \colorbox{gray!90}{broadcasting} \textcolor{gray!90}{{\textbf{\tiny (KEY)}}} aerial at the top of the tower in 1957, it is now taller than the \colorbox{gray!90}{Chrysler} \textcolor{gray!90}{{\textbf{\tiny (KEY)}}}. The \colorbox{gray!90}{Eiffel Tower} \textcolor{gray!90}{{\textbf{\tiny (KEY)}}} is connected with an organization known as the Société d'Exploitation de la Tour Eiffel or the \colorbox{gray!90}{Eiffel Tower Operating Company} \textcolor{gray!90}{{\textbf{\tiny (KEY)}}} in English . It was designed by the French engineer Gustave Eiffel.
\end{minipage}}
\end{center}


 \section{Uvrščanje besedil}
 Uvrščanje besedil \cite{klasifikacija} je tehnika, pri kateri avtomatizirano določimo kategorijo ali razred določenega besedila na podlagi vsebine besedila. To je lahko zelo uporabno, saj nam omogoča razvrščanje besedil v različne skupine glede na njihovo vsebino. 

Postopek uvrščanja besedila se običajno začne s pripravo in čiščenjem besedila. To vključuje odstranjevanje nepotrebnih znakov, šumnikov, posebnih znakov, pretvorbo vseh črk v male črke, lahko pa tudi odstranjevanje pogostih besed, ki nimajo velikega pomena za uvrščanje besedila (npr. 'in', 'ali', 'je', 'na' ter ostali).

Nato se besedila predstavijo v obliki, ki jo lahko uporabimo za učenje modela. Pogosto se uporablja metoda imenovana vreča besed, kjer se besedilo pretvori v nabor besed, ki se pojavljajo v njem, in število pojavitev teh besed. Ta postopek lahko ponazorimo s pomočjo vektorja. 



\begin{table}[h!]
\centering
\caption{Rezultat uvrščanja besedila (glej začetek poglavja~\ref{ex1})}
\label{my-label}
%\resizebox{\textwidth}{!}{%
\resizebox{!}{0.09\textheight}{
\begin{tabular}{lrrrrrr}
\multicolumn{1}{r}  \textbf{sentiment}      & verjetnost               \\ \hline    \hline                                                                                                                                                                                                                                                                                                                                       
finance   & 0.399                                                                      \\
\hline
potovanje  & 0.157                                                   \\
\hline
slike   & 0.100                          \\
\hline
novice   & 0.086                           \\
\hline
poltika   & 0.041                           \\
\hline\hline                                                                   
\end{tabular}}
\end{table}

 
 
  \section{Zaznava objektov}
Zaznava objektov \cite{object} je tehnika, ki se uporablja za avtomatsko zaznavanje in identifikacijo objektov na digitalnih slikah ali video posnetkih. Namen te tehnike je, da  prepozna in označi različne objekte, ter jih loči od ozadja ali drugih objektov.

Postopek objektnega zaznavanja običajno vključuje naslednje korake:
\begin{enumerate}
 \item Zaznavanje: Model preučuje sliko ali video posnetek in identificira regije, kjer bi se lahko nahajali objekti.
 \item Zaznava lokacije: Po tem, ko so bile regije prepoznane, algoritem določi omejitvene okvirje, ki natančno označujejo položaje in mejne točke objektov na sliki.
 \item Uvrščanje: Ko so objekti omejeni z omejitvenimi okviri, analizira vsebino znotraj teh okvirov in jih razvrsti v različne kategorije (npr. avto, pes, zgradba, itd.).
 \item  Sledenje: V video posnetkih je lahko zaželeno, da algoritem sledi objektom skozi različne kadre in tako beleži njihovo gibanje.
 \end{enumerate}
Zaznava objektov se uporablja v številnih aplikacijah, kot tudi v samovozečih vozilih za zaznavanje drugih vozil in pešcev, identifikacijo prometnih znakov, nadzorne kamere, prepoznavanje obrazov, analiza medicinskih slik in še veliko drugega. Gre za enega ključnih elementov umetne inteligence. 
 \begin{figure}[h!]
\begin{center}
\includegraphics[width=12cm]{objectDT.png}
\end{center}
\caption{Primer zaznave objektov}
\label{pic2}
\end{figure}

 %----------------------------------------------------------------
% Poglavje (Uporabljeni dataseti) 6
%----------------------------------------------------------------f
\chapter{Korpusi}
\label{ch5}

Je zbirka podatkov, ki so organizirani in shranjeni v strukturirani ali ne-strukturirani obliki ter označeni za namen analize, raziskave, učenja modelov ali drugih postopkov obdelave podatkov. Korpusi vsebujejo različne vrste podatkov od številk, besedil, slik, zvokov, videoposnetkov do drugih tipov informacij.
V kontekstu računalniškega znanstvenega modeliranja in strojnega učenja so korpusi ključnega pomena, saj služijo kot osnova za razvoj, treniranje in evalvacijo modelov. Modeli se učijo na teh podatkih, tako da prepoznajo vzorce in povezave med vhodnimi podatki in ciljnimi izhodi.
Na primer, v naravnojezikovni obdelavi  korpusov vsebuje besedilne podatke, ki so lahko članki, knjige, novičarski članki ali socialni mediji. 

\vspace{\baselineskip}
Nekatere ključne točke o uporabi korpusov:

\emph{Učenje modelov: } Korpusi se uporabljajo za učenje modelov, pri čemer modeli na osnovi teh podatkov pridobivajo razumevanje jezika in njegove strukture. Čeprav obstajajo tudi nespremljani pristopi, večina uspešnih modelov zahteva velike, kakovostne in označene korpuse za doseganje najboljših rezultatov.

\emph{Razvoj in optimizacija:}  Razvijalci modelov uporabljajo različne korpuse za optimizacijo modelov in prilagajanje hiperparametrov. Z vzorci podatkov iz korpusov se preizkušajo različne arhitekture modelov in strategije učenja.

\emph{Evaluacija:}  Korpusi se uporabljajo za evalvacijo modelov. Preizkušajo se na ločenem testnem korpusu, ki modelom omogoča, da se oceni, kako dobro delujejo na novih, nevidenih podatkih.

\emph{Nadzor kakovosti:}  Kvaliteta korpusov je ključnega pomena za uspešno delovanje modelov. Zato je pomembno, da so korpusi natančno označeni in urejeni. Nadzor kakovosti pomaga prepoznati morebitne napake ali pristranskosti v korpusih.

\emph{Prilagajanje specifičnim aplikacijam: } Včasih so potrebni specializirani modeli za določene aplikacije ali domene. V takih primerih je morda potrebno ustvariti ali prilagoditi korpuse, ki se bolje prilegajo ciljni uporabi.

\emph{Razvoj modelov za redke jezike: } Razvoj  modelov obdelave naravnega jezika za redke jezike zahteva ustrezne korpuse v ciljnem jeziku, kar je lahko izziv, saj so ti korpusi pogosto omejeni ali pa jih sploh ni na voljo.



Pomembno je, da so korpusi pravilno pripravljeni, imajo ustrezne metapodatke in so primerni za ciljno nalogo, da bi omogočili kakovostno analizo in doseganje uporabnih rezultatov.

\section{Uporabljeni korpusi}
\subsection{CoNLL 2003}
\label{sec:ch8}
 Je zbirka podatkov, ki se uporablja za razvoj in evalvacijo sistema obdelavo naravnega jezika, prevsem za nalogo imenskih entitet.  Imenuje se po konferenci CoNLL leta 2003, kjer je bil ta nabor podatkov predstavljen v okviru tekmovanja za prepoznavanje imenovanih entitet.
 Korpus CoNLL 2003 je priljubljen referenčni korpus za prepoznavanje poimenovanih entitet naravnega jezika v obdelavi naravnega jezika. Uporabljen je bil v skupni nalogi na konferenci o računalniškem učenju naravnega jezika (CoNLL) leta 2003.

Poimenovane entitete so razdeljene v štiri glavne kategorije:
\begin{enumerate}
 \item Oseba (PER): Posamezna imena ljudi.
 \item Organizacija (ORG): Imena podjetij, ustanov ali organizacij.
 \item Lokacija (LOC): Imena geografskih lokacij, kot so mesta, države ali regije.
 \item Razno (MISC): Druge poimenovane entitete, ki ne spadajo v zgoraj navedene kategorije, na primer datumi, odstotki ali denar.
 \end{enumerate}
 Podatki v korpusu so predstavljeni v obliki ene besede na vrstico, kjer vsaka vrstica predstavlja besedo in pripadajočo oznako v stavku. Besede in oznake so ločene z presledkom.
 Korpus CoNLL 2003\cite{conll}se pogosto uporablja za evalvacijo zmogljivosti modelov za prepoznavanje poimenovanih entitet in je že več let standardno merilo za raziskovalce in strokovnjake v skupnosti obdelave naravnega jezika. Ostaja dragocen vir za razvoj in preizkušanje novih algoritmov in sistemov za prepoznavo imenskih intitet. 

\begin{table}[h!]
\caption{Primer CoNLL 2003 korpusa}
    \begin{center}
        \begin{tabular}{l|ccc}
                        {He PRP B-NP O} \\
{will MD B-VP O} \\
{probably RB I-VP O} \\
{be VB I-VP O} \\
{replaced VBN I-VP O} \\
{by IN B-PP O} \\
{Shearer NNP B-NP B-PER} \\
{'s POS B-NP O} \\
{Newcastle NNP I-NP B-ORG} 
                        
        \end{tabular}
    \end{center}
\label{tbl:1}
\end{table}


CoNLL2003  podatkovna zbirka je  razdeljena na tri sklope:
\begin{enumerate}
 \item učni  z 14.000 vrsticami  primerov
 \item validacijski  z 3.250 vrsticami primerov
 \item preizkusni z 3.450 vrsticami primerov
 \end{enumerate}

\subsection{IMDb Reviews}
\label{sec:ch9}
IMDB podatkovna zbirka, znana tudi kot IMDB Movie Reviews Dataset \cite{imdb}. Sestavljen iz pregledov filmov, ki so jih prispevali uporabniki na spletni strani IMDb\cite{imdb_page}.

Podatki vsebujejo ocene in besedilne komentarje, ki jih je ustvarila skupnost uporabnikov IMDb. Vsak pregled vsebuje besedilni komentar in oceno filma, ki se giblje med 1 (najslabša) in 10 (najboljša). Cilj te podatkovne zbirke je razviti modele, ki lahko avtomatsko analizirajo besedilne komentarje in napovedo, ali je pregled pozitiven ali negativen glede na oceno in besedilo. 

\begin{table}[h!]
\centering
\caption{Primer IMDB korpusa }
\resizebox{\textwidth}{!}{%
 \begin{tabular}{l|ccc}
\hline
{pregled}            & sentiment             \\ \hline                                                                                                                                                                                                                                                                                                                                           
If you like original gut wrenching laughter you will like movie.   & positive            \\
A rating of '1', depressing and relentlessly bad this movie is.  & negative                                                                     
\end{tabular}}
\end{table}



IMDB podatkovna zbirka je  razdeljena na dva sklopa: 
\begin{enumerate}
 \item učni  z 25.000 vrsticami  primerov
 \item preizkusni z 25.000 vrsticami primerov
 \end{enumerate}
Vsak sklop vsebuje tisoče pregledov filmov. To je idealna podatkovna zbirka za naloge analize čustvenega tona besedil, kjer se ocenjuje ali je mnenje v besedilu pozitivno, negativno ali nevtralno.

\subsection{ COCO }
\label{sec:coco}
COCO\cite{coco} je nabor podatkov v področju računalniškega vida in zaznave objektov. Namenjen je zagotavljanju celovite in raznolike zbirke slik za različne naloge, vključno z zaznavo objektov, segmentacijo in podnaslavljanjem. Nabor podatkov naj bi odražal scenarije iz resničnega sveta in vsebuje slike, ki so kompleksne ter vključujejo več objektov v različnih kontekstih.

Nabor podatkov je obsežen in vsebuje deset tisoče slik z milijoni označenih posameznih objektov. Slike prihajajo iz različnih virov, zajemajo raznolike prizore, ozadja, svetlobne pogoje in velikosti objektov.


Ključne značilnosti:
\begin{enumerate}
 \item Kategorije slik: Nabor podatkov  vsebuje slike, ki zajemajo 80 različnih kategorij objektov, od splošnih objektov, kot so 'oseba', 'avto' in 'pes' do bolj specifičnih objektov, kot so 'mobilni telefon', 'zobna ščetka' in 'zmaj'.

 \item Anotacije: Vsaka slika v korpusu je opremljena z oznakami na ravni objekta in koordinatami  okvirja. To pomeni, da je vsak posamezen objekt določene kategorije znotraj slike označen, okoli njega pa je narisano območje z okvirjem, ki označuje njegovo lokacijo. Informacije o anotacijah so ključnega pomena za usposabljanje modelov za detekcijo objektov in segmentacijo.

 \item Segmentacija objektov: zagotavlja maske segmentacije na ravni slikovnih pik za vsak posamezen objekt. To pomeni, da so objekti ne le lokalizirani z okviri, ampak so natančno določene tudi meje objektov na ravni slikovnih pik. 
 \end{enumerate}
 
 Korpus je razdeljen na dva sklopa: 
\begin{enumerate}
 \item učni  z 117.000 primeri
 \item preizkusni z 4.950 primeri
 \end{enumerate}
 
   \begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm]{000000502136.jpg}
\end{center}
\caption{000000502136.jpg}
\label{pic2}
\end{figure}
 
 
\begin{figure}[h!]
 \centering
 \begin{tiny}
\begin{verbatim}
   [{
        'license': 3,
        'file_name': '000000502136.jpg',
        'coco_url': 'http://images.cocodataset.org/val2017/000000502136.jpg',
        'height': 423,
        'width': 500,
        'date_captured': '2013-11-15 17:08:30',
        'flickr_url': 'http://farm3.staticflickr.com/2253/1755223462_fabbeb8dc3_z.jpg',
        'id': 502136
    },
    {
        'segmentation': [
            [
                54.74,
                350.34,
                53.75,
                353.33,
                    ...
                    349.35
            ]
        ],
        'area': 4651.359250000001,
        'iscrowd': 0,
        'image_id': 502136,
        'bbox': [
            3.98,
            289.63,
            120.43,
            103.51
        ],
        'category_id': 64,
        'id': 21011
    }]
\end{verbatim}
\end{tiny}
\caption{COCO .json primer}
\end{figure}
 
 \newpage
 
 
 \subsection{ CNN/Daily Mail }
 \label{sec:cnn}
 CNN/Daily Mail je zbirka novičarskih člankov skupaj s povzetki, ki se uporablja za usposabljanje in preizkušanje modelov za povzemanje besedil. Ta nabor podatkov vsebuje različne novičarske članke in njihove povzetke, zaradi česar je primeren za naloge abstraktivnega povzemanja, kjer se ustvarijo povzetki v lastnih besedah, ne le izbirajo stavke iz izvornega besedila.
 Nabor podatkov vsebuje na tisoče člankov s pripadajočimi povzetki, kar omogoča raziskovalcem obsežno treniranje in evaluiranje modelov.\cite{cnn}
 
Ključne značilnosti korpusa:
 \begin{enumerate}
  \item Novičarski članki in povzetki: Nabor podatkov vsebuje novičarske članke iz medijskih virov, kot sta CNN in Daily Mail, skupaj s pripadajočimi povzetki. Ti članki pokrivajo različne teme in dogodke ter so različnih dolžin.
 \item Abstraktno Povzemanje: Vključuje ustvarjanje povzetka v povsem novih besedah. 
  \end{enumerate}
 
 \begin{table}[h!]
\centering
\caption{Primer cnn\_dailymail korpusa }
\resizebox{\textwidth}{!}{%
 \begin{tabular}{l|ccc}
\hline
{label}            & text     & highlights          \\ \hline                                                                                                                                                                                                                                                                                                                                           
002509a...   &Fears are growing that Britain's jails are becoming... & Athens pushes through...            \\
7526a1...  &  It was a farce that would lead to... &AZ Alkmaar were playing....                                                                     
\end{tabular}}
\end{table}
 
 
  
  
Korpus jerazdeljen na tri sklope: 
\begin{enumerate}
 \item učni (train) z 287.000 vrsticami  primerov
 \item validacijski (validation) z 13.400 vrsticami primerov
 \item preizkusni (test) z 11.500 vrsticami primerov
 \end{enumerate}
 
 \subsection{ SemEval 2017}
  \label{sec:semeval}
SemEval- 2017 \cite{semeval} je zbirka besedilnih podatkov, ki je anotirana za različne naloge na področju obdelave naravnega jezika.
 
Ključne značilnosti korpusa SemEval:
\begin{enumerate}
 \item Anotacije: Podatki so anotirani, kar pomeni, da so označeni z dodatnimi informacijami. Na primer, v korpus zbirki za naloge razreševanja sentimenta bi bili vzorci besedil označeni s pozitivnimi, negativnimi ali nevtralnimi sentimenti.
 \item Raznolikost: Zajemajo širok spekter nalog, jezikov in domen. To omogoča raziskovalcem primerjavo modelov in pristopov na različnih področjih.
 \end{enumerate}
 
 Raziskovalna skupnost: So postale pomemben del naravnega jezika raziskovalne skupnosti, saj omogočajo primerjavo najnovejših pristopov in tehnologij na enotnem naboru podatkov. 

 
 \begin{table}[h!]
\caption{Primer Semeval-2017 korpusa}
    \begin{center}
        \begin{tabular}{l|ccc}
            label & {\tt text}  \\ \hline
                        {\tt -1} & I missed the Barcelona game yesterday.  \\
                        {\tt 0}   & I'm bout to just listen to nicki minaj all night \\
                        {\tt 1}   & One Night like In Vegas I make dat Nigga Famous
        \end{tabular}
    \end{center}
\label{tbl:1}
\end{table}


Korpus razdeljen na tri sklope: 
\begin{enumerate}
 \item učni  z 49.547 vrsticami  primerov
 \item validacijski z 12.285 vrsticami primerov
 \item preizkusni  z 12.285 vrsticami primerov
 \end{enumerate}
 
 %----------------------------------------------------------------
% Poglavje (Uporabljeni korpusi) 6
%----------------------------------------------------------------
\chapter{Metrike}
\label{ch6}
V tem poglavju bomo obravnavali ključne metrike, ki so izbrane zaradi njihove univerzalnosti in razširjenosti v znanstvenih člankih za poročanje rezultatov. Te metrike predstavljajo standardni način izražanja in ocenjevanja raziskovalnih ugotovitev ter omogočajo primerjavo z drugimi študijami. Uporaba teh splošno priznanih metrik bo zagotovila natančno in ustrezno vrednotenje rezultatov naše raziskave.

\section{Spremenljivke za izračun metrik}
\textbf{Pravilno pozitivni }

Pravilno pozitivni \cite{truevsfalse} je izraz, ki se uporablja v statistiki in strojnem učenju za opis primerov, kjer je model pravilno napovedal pozitiven rezultat za določeno skupino. To pomeni, da je model prepoznal pozitiven pojav, ko je bil dejansko prisoten. 

\emph{Primer:}

Predpostavimo, da razvijamo model za prepoznavanje nezaželenih sporočil v elektronski pošti. Model pravilno prepozna 25 sporočil kot nezaželena, ki dejansko vsebujejo nezaželeno vsebino. To pomeni, da imamo 25 primerov 'pravilno pozitivnih'. Te primere model pravilno prepozna kot nezaželjene, ker resnično vsebujejo neželeno vsebino.





\textbf{Napačno pozitivni}

Napačno pozitivni \cite{truevsfalse} označujejo situacijo, ko model napačno napove, da je nekaj pozitivno, medtem ko je v resnici negativno. Gre za vrsto napake, kjer model napačno identificira primer kot pripadajoč pozitivnemu razredu, čeprav dejansko pripada negativnemu razredu.


\emph{Primer:}

Predpostavimo, da imamo model za prepoznavanje nezaželjenih sporočil v elektronski pošti. Če model označi sporočilo kot nezaželjeno, čeprav dejansko ni imamo situacijo lažno pozitivnega primera. Drugače povedano, model je napačno napovedal pozitiven primer (nezaželjeno), ko je dejansko negativen primer torej ni nezaželjeno. 





\textbf{Napačno negativni}

Napačno negativni \cite{truevsfalse} označujejo napako, ki se pojavi v kontekstu uvrščanja besedila ali analize besedila, ko model napačno napove, da je nekaj negativno, čeprav je v resnici pozitivno. To je vrsta napake, kjer model spregleda ali ne prepozna pozitivnih primerov. 
V primeru analize besedila v naravni jezikovni obdelavi, false negative se zgodi, ko model ne uspe zaznati pozitivnega elementa v besedilu, ki bi ga moral prepoznati. Na primer, če imamo model za prepoznavanje pozitivnih izjav v komentarjih in model spregleda pozitivno izjavo, to bi bil primer napačno negativni. 

\emph{Primer:}


Predpostavimo, da imamo napreden sistem za filtriranje nezaželjenih sporočil, ki ga uporabljamo za preverjanje prihajajočih e-poštnih sporočil. Sistem je zasnovan tako, da prepoznava in premika neželena sporočila v mapo za neželeno pošto.

Vendar pa se pojavi napačno negativen rezultat, ko sistem napačno presodi e-poštno sporočilo kot varno (ne nezaželjeno), čeprav vsebuje vse znake neželene vsebine. Na primer, če e-poštno sporočilo vsebuje povezave do nerealnih ponudb ali oglasev za sumljive izdelke, bi bila takšna sporočila številčno gledano ena od 'Napačno negativni'.

V tem primeru je sistem spregledal prepoznavo neželene vsebine, kar je povzročilo, da je sporočilo pristalo v glavnem predalu prejete pošte namesto v mapi za neželeno pošto. To lahko predstavlja težavo, saj se takšni neželeni vsebini lahko izognemo le, če sistem zanesljivo prepozna vse takšne primere. 


\section{Natančnost}

Natančnost \cite{percision} je pomembna metrika za ocenjevanje uspešnosti modelov v različnih nalogah. Povdarja natančnost pozitivnih napovedi, torej tistih primerov, ki jih model prepozna kot pozitivne. Visoka preciznost pomeni, da so pozitivne napovedi modela zanesljive in imajo malo lažno pozitivnih napak.

V kontekstu naravne jezikovne obdelave, natančnost igra ključno vlogo pri razumevanju besedila. Na primer, pri analizi sentimenta želimo natančno ugotoviti, ali je izraz pozitiven ali negativen. Visoka preciznost v tem primeru pomeni, da so napovedi modela o sentimentu točne in se malo zmotijo.

 
 Formula za izračun:
\begin{center}
  \Large{Natančnost = \(\frac{Pravilno Pozitivni}{Pravilno Pozitivni + Napacno Pozitivni}\)}
\end{center}


\section{Priklic }
Priklic se \cite{percision} nanaša na eno od metrik uspešnosti pri vrednotenju modelov za obdelavo naravnega jezika. Meri kot razmerje med številom pravilno prepoznanih relevantnih primerov in celotnim številom dejansko obstoječih relevantnih primerov. Višji priklic pomeni, da je model bolje usposobljen za iskanje in pridobivanje vseh relevantnih informacij, vendar to lahko vodi tudi v več lažno pozitivnih rezultatov. Zato je pomembno doseči uravnoteženost med priklicom in natančnostjo pri oceni uspešnosti modelov. Primer uporabe priklica je v iskalnih sistemih, kjer želimo zagotoviti, da se relevantni dokumenti ali informacije ne izpustijo pri iskanju. S pravilno optimizacijo modelov lahko dosežemo visoko kakovostno izluščevanje informacij iz besedil, kar je ključno za številne aplikacije, kot so avtomatizirano odzivanje na povratne informacije strank, analiza sentimenta in razumevanje besedil v različnih jezikih. 

 Formula za izračun:
\begin{center}
 \Large{Priklic = \(\frac{Pravilno Pozitivni}{Pravilno Pozitivni + Napacno Negativni}\)}
\end{center}

\section{Ocena F1}

F1 ocena je pomembna metrika za ocenjevanje uspešnosti modelov v obdelavi besedil. Združuje natančnost in priklic v eno metriko, ki odraža ravnotežje med tema dvema metrikama. Pri  nalogah, kot so uvrščanje besedil, luščenje informacij ali identifikacija entitet, sta tako natančnost  kot priklic ključni. Visoka natančnost pomeni pravilno identifikacijo relevantnih elementov, medtem ko visoki priklic zagotavlja prepoznavanje vseh resnično pozitivnih primerov. Izračuna se kot povprečje med natančnost in priklicom, dajeta pa ji enako težo. To omogoča, da ocenimo, kako dobro model obvladuje oba cilja hkrati. Visoka vrednost F1 ocene kaže, da je model uspešno uskladil identifikacijo pravih pozitivnih primerov z izogibanjem napačno pozitivnim rezultatom. Uporaba metrike je zlasti smiselna, ko sta metriki natančnost in priklic pomembni za končni rezultat in ko želimo doseči optimalno uravnoteženost med tema dvema vidikoma.


 Formula za izračun:
\begin{center}
 \Large{ Ocena F1= 2 x \(\frac{Natancnost \times Priklic }{Natancnost + Priklic}\)}
\end{center}

\section{Točnost}
Točnost \cite{accuracy} je metrika, ki se pogosto uporablja za ocenjevanje uspešnosti modelov v strojnem učenju, vključno z modeli uporabljenimi v obdelavi naravnega jezika. Ta metrika meri, kako pravilno model napove razrede ali kategorije za vhodne podatke v primerjavi z dejanskimi vrednostmi.

V kontekstu obdelave naravnega jezika se natančnost uporablja, na primer, pri nalogah uvrščanja besedila. Predpostavimo, da imamo model, ki se uči razvrščati besedila v določene kategorije, kot so 'pozitivno', 'negativno' ali 'neutralno'. Za vsako besedilo ima model svojo napoved, kateri kategoriji pripada.

 Formula za izračun:
\begin{center}
  \large{Točnost = \(\frac{Pravilno Pozitivni + Pravilno Negativni}{Pravilno Pozitivni + Pravilno Negativni + Napacno Pozitivni + Napacno Negativni}\)}
\end{center}

\section{ROUGE}
Je metrika, ki se uporablja za ocenjevanje kakovosti generiranih besedil v primerjavi z referenčnimi besedili. Gre za kratico, ki označuje 'Recall-Oriented Understudy for Gisting Evaluation'. Metrika je pogosto uporabljena v področju obdelave naravnega jezika, še posebej v nalogah avtomatskega povzemanja besedil.

Primerja generirano besedilo z referenčnim besedilom (običajno človeško ustvarjenim besedilom) in oceni, kako dobro so se ujemale. Metrika upošteva različne vidike, kot so prekrivanje besed, besedni nizi in skupna dolžina besedil. Glavni cilj metrike je merjenje stopnje, do katere je generirano besedilo sposobno pravilno povzeti pomembne informacije iz referenčnega besedila.

Obstajajo različne različice metrike ROUGE, kot so ROUGE-1, ROUGE-2, ROUGE-L itd. Vsaka različica meri različne vidike podobnosti med generiranim besedilom in referenčnim besedilom. Na primer, ROUGE-1 meri prekrivanje eno-besednih nizov med generiranim in referenčnim besedilom, medtem ko ROUGE-2 meri prekrivanje dvo-besednih nizov.

Metrika ima širok nabor uporabe v raziskavah in nalogah, ki vključujejo avtomatsko povzemanje besedil, strojno prevajanje in druge naloge, kjer je pomembno oceniti kakovost generiranih besedil v primerjavi z referenčnimi besedili. Metrika lahko pomaga raziskovalcem in razvijalcem oceniti učinkovitost svojih modelov in tehnik ter izboljšati rezultate pri generiranju besedil.


  %----------------------------------------------------------------
% Poglavje (Analiza raziskave) 6
%----------------------------------------------------------------
\chapter{Primerjava orodij}
\label{ch7}
Pimerjava ponudnikov ter storitev je bila izvedena v času od Februarja do Maja 2023. 

Izbrani so bili trije največji ponudniki storitev v oblaku: Google Cloud, Amazon Web Services ter Microsoft Azure. Pri izbiri odprtokodne rešitve je bilo težko izbrati najboljšega, saj so v tem času tri najboljše odprtokodne rešitve zelo tesno skupaj kakor tudi povezane. Na podlagi pregledanih funkcionalnosti ter uporabe je bil izbran Hugging Face  Transformers. 

\textbf{Analiza napak}


Pri raziskovanju modelov in korpusov, hitro spoznamo da so lahko modeli celo preveč prilagojeni  določenemu področju, kar pomeni da preveč podrobno pozna eno področje, na katerem je bil model treniran in ne more dobro razumeti novih podatkov/primerov, kakor tudi da so premalo podrobni ali premalo raznoliki. 

Zato so najbolj poznani in razširjeni modeli, učeni na širokem naboru različnih podatkov, da je možnost napake manjša. 

 
Prepoznane pogoste napake modelov:

\emph{Nezadostni podatki:} Za gradnjo natančnega modela je potrebna velika količina podatkov. Če ni dovolj podatkov, bo model morda težko naučil vzorce v podatkih. 

\emph{Nezadostna raznolikost podatkov: }Pomembno je, da imajo podatki za usposabljanje dobro razpršenost. Če so podatki preveč homogeni, bo model morda težko naučil vzorce, ki veljajo za splošne primere. 

\emph{Nekvalitetni podatki:} Pomembno je, da so podatki za usposabljanje kakovostni. Če so podatki napačni ali pristranski, bo model morda težko naučil natančen model. 

\emph{Napačen algoritem:} Obstaja veliko različnih algoritmov za stojno učenje, zato je pomembno, da se izbere algoritem, ki je primeren za specifično nalogo. Če je izbran algoritem  napačen, bo morda težko zgraditi natančen model. 

\emph{Napačna nastavitev parametrov:} Večina algoritmov stojnega učenja ima parametre, ki jih je mogoče prilagoditi za izboljšanje natančnosti modela. Če niso pravilno nastavljeni parametri, bo morda težko zgraditi natančen model. 

V nadaljevanju so predstavljeni podrobnejši rezultati treh iteracij  z povprečnimi vrednostmi pripadajočih metrik ter  standardni odklon kateri je merilo razpršenosti podatkov. Pomaga nam razumeti, koliko se podatki razlikujejo od povprečne vrednosti. Rezultati v vseh tabelah so zaokroženi na tri decimalna mesta. 

\textbf{Izbrani testni podatki}

Za analizo obdelave naravnega jezika so bile izbrane tri množice testne testnih podatkov, vsaka od njih je vsebovala 50 primerov. Razdeljene so bile v tri različne kategorije: novice, finance ter šport. 
Pri zaznavi objektov pa so bile izbrane nslednje kategorije: osebe, živali ter vozila.

V nadaljevanju so predstavljeni podrobnejši rezultati treh iteracij  z povprečnimi vrednostmi pripadajočih metrik ter  standardni odklon kateri je merilo vrednosti od povprečja. Pomaga nam razumeti, koliko se podatki razlikujejo od povprečne vrednosti. Rezultati v vseh tabelah so zaokroženi na tri decimalna mesta. 

\newpage

\section{Prepoznavanje imenskih entitet (named entity recognition)}

Google Vertex AI klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]    
client.analyze_entities(
        request={"document": besedilo, "encoding_type": encoding_type}
    )
    \end{lstlisting}
    
AWS SageMaker klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
client.detect_entities(besedilo, LanguageCode='en')
    \end{lstlisting}
   

Azure Cognitive Services klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
client.recognize_entities(besedilo)
    \end{lstlisting}
   
\begin{table}[h!]
\centering
\caption{Prepoznavanje imenskih entitet (named entity recognition)}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}
\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje}                            \\ \hline                                                                                                                                                                                                                                                                                                                                           
 \hline
\textbf{Hugging Face Transformers}   & Priklic  & 0.929              & 0.912                  & 0.917              & 0.919 (± 0.009)                                     \\
				    &  Natančnost  & 0.924              & 0.945                  & 0.901               & 0.923 (± 0.022)  \\
                                     & F1 ocena    & 0.927                 & 0.928                  & 0.909             & 0.921 (± 0.011)   \\
  \hline
\textbf{Google Vertex AI}         & Priklic  & 0.946             & 0.914              & 0.896              & 0.919 (± 0.025 )                                         \\
                                   &  Natančnost & 0.895              & 0.923              & 0.942              & 0.920 (± 0.024  )                                   \\
                                   & F1 ocena   & 0.920              & 0.918              & 0.918              & 0.919 (± 0.001 )                                          \\
  \hline  
\textbf{AWS SageMaker}   & Priklic & 0.981              & 0.962              & 0.941              & \textbf{0.961} (± 0.020)                                          \\
                                   &  Natančnost & 0.962              & 0.980              & 0.921              & \textbf{0.954} (± 0.030  )                                 \\
                                   & F1 ocena   & 0.971              & 0.971              & 0.931              & \textbf{0.958} (±0.023 )      \\
  \hline
\textbf{Azure Cognitive Services}   & Priklic  & 0.821              & 0.831             & 0.821            & 0.824  (± 0.006)                                             \\
                       &  Natančnost & 0.831              & 0.841              & 0.903              & 0.858  (±0.039 )                                        \\
                        & F1 ocena   & 0.826              & 0.836              & 0.860              & 0.841 (± 0.017 )                                   \\  
  \hline
   \hline  
  \textbf{Najboljši rezultat z članka}   & Priklic    &               &             &               & 0.918                                           \\
                       &  Natančnost &               &               &             & 0.913                                          \\
                        & F1 ocena   &              &             &               & 0.916 (± 0.33)                                           \\  
     \hline
       \hline                                                   
\end{tabular}}
\end{table}

 
 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{NER.png}
\end{center}
\caption{Prepoznavanje imenskih entitet Ocena F1}
\label{pic2}
\end{figure}

Pri analizi imenskih entitet je bil uporabljen CONLL-2003 korpus (glej poglavje~\ref{sec:ch8}).

Za prepoznavanje oseb (PER) in organizacij (ORG) se je najbolje izkazala storitev Vertex AI. Na splošno pa je bil v vseh področjih najboljši AWS SageMaker, saj je bil najboljši kar na obeh področjih, tako pri priklicu kot pri natančnosti. 


Kot referenco vidimo v tabeli tudi najboljše rezultate iz članka\cite{ner_clanek}, kjer je Arya Roy naredil primerjavo med več modeli, razberemo lahko da se je najboljše izkazal model Chiu and Nichols (2015) + emb + lex.

\subsection{Analiza napak pri prepoznavanje imenskih entitet} 
\begin{table}[h!]
\begin{center}
\caption {Primeri napak pri prepoznavanje imenskih entitet} \label{tab:title}
\begin{tabularx}{1.1\textwidth} { 
  | >{\centering\arraybackslash}X 
  | >{\centering\arraybackslash}X 
  | >{\centering\arraybackslash}X  
    | >{\centering\arraybackslash}X  
    | >{\centering\arraybackslash}X |}
 \hline
  \textbf{Besedilo}  & \textbf{ Imenske entitete}   & \textbf{AWS SageMaker} &  \textbf{Hugging Face Transformers}    \\
 \hline
 John Doe je živel v San Franciscu.  & John Doe, San Francisco  & John Doe, San Francisco  & John Doe, San Fran  \\ 
\hline
  Apple je bila ustanovljena leta 1976. & Apple, 1976  & Apple, 1976   & Apple, ustanovljena \\ 
    \hline
     To je velikanski robot. & robot  &    & robot \\ 
    \hline
\end{tabularx}
\end{center}
\end{table}

Kot je razvidno iz tabele so pri prvem primeru Hugging Face Transformers naredil napako pri zvezi 'San Franciscu', kjer je izpustil del besede. V drugem primeru je AWS SageMaker izpustil pomembno entiteto 'ustanovljena'. V zadnjem primeru pa lahko vidimo da AWS SageMaker ni zaznal nobene imenske entitete. 

Najpogosteje opažene napake pri prepoznavi imenskih entitet:  
\begin{enumerate}
 \item Napake imen: to so napake v imenu imenske entitete, na primer napačna črka ali napačen zlog, zapletene besede ali tuje besede. To lahko oteži identifikacijo imena in njegovo kategorizacijo. 
 \item Napake v tipu: napaka v tipu imenske entitete, na primer napačno označitev osebe kot kraja ali obratno. Ime je zapleteno ali dvoumno zato, ker imajo zapletena imena lahko več kot eno pomensko področje. 
 \item Izpuščanje/nekategorizacija: napaka, pri katerih se imenska entiteta izpusti iz besedila. 
 \item Ponavljanje: napaka, pri katerih se imenska entiteta ponovi v besedilu. 
 \end{enumerate}

\section{Analiza sentimenta }

Google Vertex AI klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
client.analyze_sentiment(
        request={"document": besedilo, "encoding_type": encoding_type}
    )
    \end{lstlisting}
    
AWS SageMaker klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
client.detect_sentiment(Text=besedilo, LanguageCode='en'))
    \end{lstlisting}
   

Azure Cognitive Services klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
client.analyze_sentiment(besedilo)
    \end{lstlisting}
   

\begin{table}[h!]
\centering
\caption{Analiza sentimenta(sentiment analaysis)}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}

\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje}                              \\ \hline     \hline                                                                                                                                                                                                                                                                                                                                      
\textbf{Hugging Face Transformers}   & Priklic  & 0.937              & 0.912                 & 0.930              & 0.926 (±0.013)                                     \\
				    &  Natančnost  & 0.938              & 0.987                  & 0.860               & \textbf{0.928} (±0.064)                                     \\
                                     & F1 ocena    & 0.937                 & 0.952                  & 0.893             & 0.929 (±0.031)                    \\
\hline
\textbf{Google Vertex AI}         & Priklic  & 0.921              & 0.948              & 0.938              & 0.936 (±0.014)                                           \\
                                   &  Natančnost & 0.942             & 0.888              & 0.943              & 0.924 (±0.031)                                         \\
                                   & F1 ocena   & 0.931            & 0.917            & 0.940              & \textbf{0.930}  (±0.012)                                        \\
\hline
\textbf{AWS SageMaker}   & Priklic  & 0.901              & 0.882              & 0.891              & 0.891 (±0.010)                                           \\
                                   &  Natančnost & 0.821              & 0.853              & 0.912              & 0.862 (±0.046 )                                           \\
                                   & F1 ocena   & 0.859              & 0.867              & 0.901              & 0.876 (±0.022)                                                  \\
  \hline                                 
\textbf{Azure Cognitive Services}   & Priklic  & 0.881              & 0.905              & 0.887              & \textbf{0.981} (±0.012)                                            \\
                       &  Natančnost & 0.852              & 0.884              & 0.851              & 0.862 (±0.019)                                          \\
                        & F1 ocena   & 0.866              & 0.894              & 0.869              & 0.876  (±0.015)                                          \\  
  \hline   
   \hline                           
  \textbf{Najboljši rezultat z članka}   & Priklic    &               &             &               & 0.928                                           \\
                       &  Natančnost &               &               &             & 0.915                                          \\
                        & F1 ocena   &              &             &               & 0.921                                         \\  
                         
\hline
\hline                            
\end{tabular}}
\end{table}

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{KP.png}
\end{center}
\caption{Analiza sentimenta Ocena F1}
\label{pic2}
\end{figure}

Pri analizi sentimenta je bil uporabljen  IMDb Reviews korpus (glej poglavje~\ref{sec:ch9}).
Za analizo sentimenta  je bila najboljša Vertex AI storitev.

Kot referenco vidimo v tabeli tudi najboljše rezultate iz članka\cite{sent1_clanek}, kjer so Guizian Xu in ostali naredili analizo na Twiter korpusu.


\newpage

\subsection{Analiza napak pri analizi sentimenta} 
\begin{table}[h!]
\begin{center}
\caption {Primeri napak pri analizi sentimenta} \label{tab:title}
\begin{tabularx}{1.1\textwidth} { 
  | >{\centering\arraybackslash}X 
  | >{\centering\arraybackslash}X 
  | >{\centering\arraybackslash}X  
    | >{\centering\arraybackslash}X  
        | >{\centering\arraybackslash}X  
    | >{\centering\arraybackslash}X |}
 \hline
  \textbf{Besedilo}  & \textbf{ Imenske entitete}   & \textbf{Google Vertex AI  } &  \textbf{Hugging Face Transformers}    \\
 \hline
Ta knjiga je zelo zanimiva.   &Pozitivno    & Pozitivno   &Negativno   \\ 
\hline
  To je zelo dolgočasno.  &Negativno  &Nevtralno    &Nevtralno  \\ 
    \hline
  Ta igra je bila zelo napeta. &Pozitivno    & Pozitivno & Nevtralno \\ 
      \hline
  Ta politični govor je bil zelo kontroverzen.  &Negativno    & Negativno & Pozitivno \\ 
    \hline
\end{tabularx}
\end{center}
\end{table}

Opazimo da sta obe storitvi naredili isto napako pri istem primeru, saj sta zaznali dolgočasno kot nevtralno in ne negativno. 

Najpogosteje opažene napake pri analizi sentimenta:  
\begin{enumerate}
 \item Nepravilna identifikacija sentimenta: je ena izmed najpogosteje opaženih napak, ki se je pojavila pri analizi sentimenta, kar je lahko ko je beseda ali besedna zveza dvoumna in lahko pomeni tako pozitiven kot negativen sentiment. Lahko je tudi napaka v zapisu same besede ali besedne zveze, kot tudi da je model premalo naučen za določeno področje. 
 \item Nepravilna kategorizacija sentimenta: se pojavi, ko analiza sentimenta pravilno identificira sentiment, vendar ga napačno kategorizira. To lahko povzroči, da analiza sentimenta ne bo uporabna za namen, za katerega je bila namenjena. 
 \item Napaka v kontekstu: se zgodi ko analiza sentimenta pravilno identificira sentiment in ga pravilno kategorizira, vendar ga napačno razvrsti v kontekstu. To lahko povzroči, da analiza sentimenta ne bo uporabna za namen, za katerega je bila namenjena. 
 \item Napaka v viru: zaznamo jo, ko analiza sentimenta pravilno identificira sentiment, ga pravilno kategorizira in ga pravilno razvrsti v kontekstu, vendar ga napačno dobi iz vira. To lahko povzroči, da analiza sentimenta ne bo uporabna za namen, za katerega je bila namenjena. 
 \end{enumerate}

\newpage
\section{Povzemanje besedila}
Google Vertex AI klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
document = language.Document(content=besedilo, type_=language.Document.Type.PLAIN_TEXT)
response = client.text_summarization(document=document, encoding_type=EncodingType.UTF8)
    \end{lstlisting}
    
AWS SageMaker klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
query_response = query(model_predictor, besedilo)
summary_text = parse_response(query_response)
    \end{lstlisting}
   

Azure Cognitive Services klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
client.begin_abstract_summary(besedilo)
    \end{lstlisting}



\begin{table}[h!]
\centering
\caption{Povzemanje besedila (summarization)}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}
\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje}                          \\ \hline   \hline                                                                                                                                                                                                                                                                                                                                        
\textbf{Hugging Face Transformers}   & ROUGE-L   & 0.178              & 0.187                 & 0.212              & 0.192 (±0.018)                                    \\
\hline
\textbf{Vertex AI}         & ROUGE-L   & 0.312              & 0.291              & 0.315              & 0.306 (±0.013)                                          \\
\hline
\textbf{AWS SageMaker}.   & ROUGE-L   & 0.203             & 0.184              & 0.216             & 0.201 (±0.016)                                           \\
\hline
\textbf{Azure Cognitive Services}   & ROUGE-L   & 0.387              & 0.318             & 0.284             & \textbf{0.330} (±0.052)                  \\
\hline
 \hline  
\textbf{Rezultati članka}   & ROUGE-L   &               &              &             & 0.392                   \\
\hline
\hline                                                                                              
\end{tabular}}
\end{table}

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{SUMM.png}
\end{center}
\caption{Povzemanje Ocena F1}
\label{pic2}
\end{figure}

Pri povzemanju je bil uporabljen korpus CNN/Daily Mail (glej poglavje~\ref{sec:cnn}).

Kot najboljša izbira za ustvarjanje povzetkov se je izkazala storitev Azure Cognitive Services.

Kot referenco vidimo v tabeli tudi najboljše rezultate iz članka\cite{povz_clanek}, kjer so Guizian Xu in ostali naredili analizo na različnih korpusih, kjer pa je najboljši rezultat dosegel CNN/ DailyMail.

\newpage

\subsection{Analiza napak pri povzemanju besedila} 
\begin{table}[h!]
\begin{center}
\caption {Primeri napak pri povzemanju besedila} \label{tab:title}
\begin{tabularx}{0.9\textwidth} { 
  | >{\centering\arraybackslash}X 
  | >{\centering\arraybackslash}X 
  | >{\centering\arraybackslash}X  
    | >{\centering\arraybackslash}X  
    | >{\centering\arraybackslash}X |}
 \hline
  \textbf{Besedilo}  & \textbf{ Imenske entitete}   & \textbf{Azure Cognitive Services} &  \textbf{Hugging Face Transformers}    \\
 \hline
John Doe je živel v San Franciscu. Bil je uspešen poslovnež.   &John Doe, uspešen poslovnež iz San Francisca.    &John Doe je živel v San Franciscu in bil poslovnež. & John Doe, poslovnež, živel v San Franciscu.       \\ 
\hline
Apple je bila ustanovljena leta 1976. Je ena največjih tehnoloških podjetij na svetu.  &Apple, ustanovljeno leta 1976, je eno največjih tehnoloških podjetij na svetu.  &Apple, ustanovljeno leta 1976, je največje tehnološko podjetje na svetu. &Apple, tehnološko podjetje, ustanovljeno leta 1976.        \\ 
    \hline
     To je velikanski robot.  &Robot je velikanski.    & To je velikanski robot, ki je zelo močan.  & Velikanski, robot.   \\ 
    \hline
\end{tabularx}
\end{center}
\end{table}

Kot je razvidno iz tabele je Hugging Face Transformers vse stavke zelo slabo oblikoval in so zelo nepovezani. 

\vspace{\baselineskip}



Najpogosteje opažene napake pri povzemanju besedila:  
\begin{enumerate}
 \item Izpuščanje pomembnih informacij: kar pomeni, da je povzetek netočen ali nepopoln. To se lahko zgodi iz več razlogov, na primer zaradi tega, da model ne prepozna pomembnih informacij ali pa ne more pravilno razumeti pomena besedila. 
  \item Dodajanje napačnih informacij: povzroča, da je povzetek netočen ali zavajajoč. To se lahko zgodi iz več razlogov, na primer zaradi tega, da model napačno intrepterira besedilo ali pa uporablja napačne podatke pri treniranju modela. 
 \item Slab slog in gramatika: ustvarjeni povzetki, ki so slabo napisani ali vsebujejo napake v slogu in gramatiki, kar je lahko posledica napačnega algoritma. 
  \end{enumerate}

%----------------------------------------------------------------
%Izvleček besedne zveze 

%----------------------------------------------------------------

\section{Prepoznavanje besednih zvez (key pharses)}
Google Vertex AI klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
client.extractKeywords(request={"document":besedilo})
    \end{lstlisting}
    
AWS SageMaker klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
client.detect_phrases(
    Text=besedilo,
    LanguageCode='en')
    \end{lstlisting}
   

Azure Cognitive Services klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
client.extract_key_phrases(besedilo)
    \end{lstlisting}


\begin{table}[h!]
\centering
\caption{Prepoznavanje besednih zvez (Key pharses)}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}
\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje}                        \\ \hline \hline                                                                                                                                                                                                                                                                                                                                            
\textbf{Hugging Face Transformers}   & Priklic  & 0.523              & 0.640                  & 0.556              & 0.573 (±0.060)                                        \\
				    &  Natančnost  & 0.398               & 0.499                 & 0.528               & 0.475 (±0.068 )  	          	   \\
                                     & F1 ocena    & 0.452                  & 0.561                  & 0.542              & 0.519 (±0.058)  			   \\
                                     \hline  
\textbf{Google Vertex AI}         & Priklic  & 0.499              & 0.541              & 0.589              & 0.543 (±0.045)                                            \\
                                   &  Natančnost & 0.688             & 0.635              & 0.589              & \textbf{0.637} (±0.050 )                                          \\
                                   & F1 ocena   & 0.578             & 0.584              & 0.589              & 0.586 (±0.005)                                          \\
                                   \hline  
\textbf{AWS SageMaker}   & Priklic  & 0.675              & 0.605              & 0.587              &\textbf{0.622}  (±0.046)                                         \\
                                   &  Natančnost & 0.520              & 0.492             & 0.526             & 0.513 (±0.018)                                            \\
                                   & F1 ocena   & 0.587             & 0.543             & 0.555              & 0.562 (±0.023)   					  \\
                                   \hline  
\textbf{Azure Cognitive Services}   & Priklic  & 0.532              & 0.559             & 0.500              & 0.530 (±0.030 )                                        \\
                       &  Natančnost & 0.674              & 0.648             & 0.689              & 0.670 (±0.021)                                         	  \\
                        & F1 ocena   & 0.595              & 0.600              & 0.579              & \textbf{0.592}  (±0.011)                                                   \\
                                   \hline  
                                    \hline  
\textbf{Rezultati članka}  & F1 ocena   &               &              &               &0.406                                                     \\

                                               \hline  
                        \hline                  
\end{tabular}}
\end{table}

  \newpage
 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{KEY.png}
\end{center}
\caption{Prepoznavanje besednih zvez Ocena F1}
\label{pic2}
\end{figure}


Pri izvajanju naloge zvlečka besedne zveze je bil uporabljen korpus SemEval 2017(glej poglavje~\ref{sec:semeval}).

Kot najboljša rešitev za izvleček besedne zveze pa se je izkazala storitev Azure Cognitive Services.


Kot referenco vidimo v tabeli tudi najboljše rezultate iz članka\cite{key_phrases_clanek}, kjer so Xingdi Yuan in ostali naredili analizo na različnih korpusih, kjer pa je najboljši rezultat dosegel NUS, na drugem mestu pa je bil SemEval, kateri je dosegel oceno 0,357.

  \newpage
\subsection{Analiza napak pri izvlečeku besedne zveze} 

\begin{table}[h!]
\begin{center}
\caption {Primeri napak pri izvlečeku besedne zveze} \label{tab:title}
\begin{tabularx}{0.9\textwidth} { 
  | >{\centering\arraybackslash}X 
  | >{\centering\arraybackslash}X 
  | >{\centering\arraybackslash}X  
    | >{\centering\arraybackslash}X  
    | >{\centering\arraybackslash}X |}
 \hline
  \textbf{Besedilo}  & \textbf{ Imenske entitete}   & \textbf{Azure Cognitive Services} &  \textbf{Hugging Face Transformers}    \\
 \hline
John Doe je živel v San Franciscu. Bil je uspešen poslovnež.    &John Doe, uspešen poslovnež, San Francisco    &John Doe, San Francisco  & John Doe, Francisco        \\ 
\hline
Apple je bila ustanovljena leta 1976. Je ena največjih tehnoloških podjetij na svetu.   &Apple, podjetje, tehnološko, ustanovljeno leta 1976  &Apple, tehnološko podjetje, ustanovljeno  1976  &Apple, podjetje, ustanovljeno leta 1976, tehnološko        \\ 
    \hline
     To je velikanski robot.     & velikanski robot &velikanski, robot  &velikanski, robot, ki je zelo močan  \\ 
    \hline
\end{tabularx}
\end{center}
\end{table}

Iz tabele lahko razberemo, da je do napak prišlo pri uporabi obeh storitev, kot pri Hugging Face Transformers kakor tudi pri Azure Cognitive Services. Opazimo lahko makajoči  del ključne besede kateri je zelo pomemben, napačno povezovanje besed ter dodajanje neresničnih podatkov.

Najpogosteje opažene napake pri izvlečeku besedne zveze:  
\begin{enumerate}
 \item Napačne oznake: napake v oznaki besednih zvez, na primer napačno označitev besedne zveze kot pomembne, čeprav ni pomembna ali obratno. 
  \item Izpuščanje: napake, pri katerih se besedna zveza izpusti iz izvlečka, na primer zaradi napake pri prepoznavanju besednih zvez ali zaradi napake pri razdelitvi besedila na stavke. 
  \item   Ponavljanje: To so napake, pri katerih se besedna zveza ponovi v izvlečku, na primer zaradi napake pri razdelitvi besedila na stavke ali zaradi napake pri ohranitvi besedne zveze. 
 \end{enumerate}




%----------------------------------------------------------------
% Klasifikacija besedila 
%----------------------------------------------------------------

\section{Uvrščanje besedil ( Text classification)}

Google Vertex AI klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
client.classify_text( request={"document": besedilo} )
    \end{lstlisting}
    
AWS SageMaker klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
 query_response = query_endpoint(text.encode("utf-8"))
    probabilities, labels, predicted_label = parse_response(query_response)
    \end{lstlisting}
   

Azure Cognitive Services klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
client.begin_multi_label_classify(besedilo)
    \end{lstlisting}



\begin{table}[h!]
\centering
\caption{Uvrščanje besedil}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}
\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje}      
                 \\ \hline      \hline                                                                                                                                                                                                                                                                                                                                       
\textbf{Hugging Face Transformers}   & Priklic  & 0.933             & 0.948                  &  0.896             &  0.926 (±0.027)                                         \\
				    &  Natančnost  &  0.898               & 0.935                 & 0.958               &  0.930 (±0.030)   		      \\
                                     & F1 ocena    &  0.915                  &  0.941                  &  0.926              &  \textbf{0.928} (±0.013) 		     \\
                                     \hline  
\textbf{Google Vertex AI}         & Priklic  &  0.842              &  0.901              &  0.844             & \textbf{ 0.962} (±0.034)                                             \\
                                   &  Natančnost &  0.989              &  0.924              &  0.959              &  \textbf{0.957} (±0.033)                                             \\
                                   & F1 ocena   &  0.910              &  0.912              &  0.989              &  0.907 (± 0.008)                                            \\
                                   \hline  
\textbf{AWS SageMaker}   & Priklic  &  0.789              &  0.802             &  0.697              &  0.763 (±0.057)                                            \\
                                   &  Natančnost &  0.879              &  0.799              &  0.895              &  0.858  (±0.051)                                           \\
                                   & F1 ocena   &  0.832              &  0.800              &  0.784              &  0.808 (±0.024)   			    \\
                                   \hline  
\textbf{Azure Cognitive Services}   & Priklic  &  0.935              &  0.925             &  0.900              &  0.920  (±0.018)                                           \\
                       &  Natančnost &  0.827              &  0.888              &  0.925             &  0.880 (±0.049)                                            \\
                        & F1 ocena   &  0.878              &  0.906              &  0.912              &  0.900(±0.018)                                           \\
                                   \hline  
                                    \hline  
\textbf{Rezultati članka}   & Priklic  &                &               &              &  0.9057                                            \\
                       &  Natančnost &                &               &             & 0.8975                                            \\
                        & F1 ocena   &                &                &                &  0.9018                                        \\
                        \hline  
                        \hline                                  
\end{tabular}}
\end{table}

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{CLASSIFICATION.png}
\end{center}
\caption{Uvrščanje besedil  Ocena F1}
\label{pic2}
\end{figure}

  \newpage
Pri izvajanju naloge uvrščanja besedila je bil uporabljen korpus IMDb Reviews (glej poglavje~\ref{sec:ch9}).

Kot najboljša rešitev za naloge uvrščanje besedila pa se je izkazala storitev Hugging Face Transformers.

Kot referenco vidimo v tabeli tudi najboljše rezultate iz članka\cite{imdb1_clanek}, kjer so Shanshan Yu in ostali naredili analizo na IMDb Reviews korpusu.


\subsection{Analiza napak pri uvrščanje besedila} 

\begin{table}[h!]
\begin{center}
\caption {Primeri napak pri uvrščanje besedila} \label{tab:title}
\begin{tabularx}{1.1\textwidth} { 
  | >{\centering\arraybackslash}X 
  | >{\centering\arraybackslash}X 
  | >{\centering\arraybackslash}X  
    | >{\centering\arraybackslash}X  
    | >{\centering\arraybackslash}X |}
 \hline
  \textbf{Besedilo}  & \textbf{ Imenske entitete}   & \textbf{Google Vertex AI } &  \textbf{Hugging Face Transformers}    \\
 \hline
John Doe je živel v San Franciscu.     &Novice     &Novice  & Novice        \\ 
\hline
Apple je bila ustanovljena leta 1976.    &Novice  &Tehnologija   &Novice        \\ 
    \hline
     Ta koncert je bil zelo ganljiv.      & Umetnost  &Glasba  &Glasba  \\ 
    \hline
\end{tabularx}
\end{center}
\end{table}

Iz tabele lahko razberemo da so bile narejene napake pri obeh ponudnikih, vendar je Hugging Face Transformers imel manj napak. 

Najpogosteje opažene napake pri uvrščanju besedila:  

\begin{enumerate}
  \item Napačno uvrščanje razredov: zaradi pomanjkanja jasnih ločnic med razredi ali zaradi podobnosti med besedili različnih razredov. 
    \item Nezaznavanje: kadar se izpustijo pomembne informacije iz besedila, kar la povzroči, da je uvrščanje netočno ali nepopolno. 


 \end{enumerate}
%----------------------------------------------------------------
% Zaznava objektov 
%---------------------------------------------------------------

\section{Zaznava objektov (object detection)}

Google Vertex AI klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
predict_image_object_detection_sample(
    project: str,
    endpoint_id: str,
    filename: str,
    location: str = "us-central1",
    api_endpoint: str = "us-central1-aiplatform.googleapis.com",
)
    \end{lstlisting}
    
AWS SageMaker klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
query_response = query(model, url)
    \end{lstlisting}
   

Azure Cognitive Services klic:
\begin{lstlisting}[ basicstyle=\tiny,frame=single]
client.analyze_image(url,visual_features=[VisualFeatureTypes.tags])
    \end{lstlisting}


\begin{table}[h!]
\centering
\caption{Zaznava objektov }
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}
\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje }                            \\ \hline    \hline                                                                                                                                                                                                                                                                                                                                       
\textbf{Hugging Face Transformers}   & Točnost  & 0.900             & 0.970                  & 0.940              & 0.940 (±0.018 )                                    \\
\hline
\textbf{Google Vertex AI}         & Točnost  & 0.963              & 0.991              & 0.977             & 0.977 (±0.014)                                           \\
\hline
\textbf{AWS SageMaker}  & Točnost  & 0.995              & 0.963              & 0.982              & \textbf{0.980} (±0.016)                                    \\
\hline
\textbf{Azure Cognitive Services}   & Točnost  & 0.960             & 0.950              & 0.985             & 0.965 (±0.017)               \\
\hline
 \hline  
\textbf{Rezultati članka}   & Točnost  &             &               &              & 0.948               \\
\hline\hline                                                                   
\end{tabular}}
\end{table}


 \begin{figure}[h!]
\begin{center}
\includegraphics[width=9cm]{OBJECT.png}
\end{center}
\caption{ Zaznava objektov Ocena F1}
\label{pic2}
\end{figure}


Pri zaznavi objektov je bil uporabljen  COCO korpus (glej poglavje~\ref{sec:coco}).

Kot najboljša izbira za zaznavanje objektov pa se je izkazala storitev AWS SageMaker.


Kot referenco vidimo v tabeli tudi najboljše rezultate iz članka\cite{obj1_clanek} spisanega leta 2019, kjer sta Ali Borji in Seyed Mehdi Iranmanesh naredila analizo na različnih korpusih, kjer pa je najboljši rezultat dosegel VOC, tretje mesto pa je zasedel COCO z 0.867.

\subsection{Analiza napak pri zaznavi objektov} 
\begin{table}[h!]
\begin{center}
\caption {Primeri napak pri zaznavi objektov} \label{tab:title}
\begin{tabularx}{1.0\textwidth} { 
  | >{\centering\arraybackslash}X 
  | >{\centering\arraybackslash}X 
  | >{\centering\arraybackslash}X  
    | >{\centering\arraybackslash}X  
      | >{\centering\arraybackslash}X 
  | >{\centering\arraybackslash}X  
    | >{\centering\arraybackslash}X  
    | >{\centering\arraybackslash}X |}
 \hline
  \textbf{Slika}  & \textbf{ Pravilni objekti}   & \textbf{AWS SageMaker } &  \textbf{Hugging Face Transformers}    \\
 \hline
Psa     &Pes     &Pes  & Mačka        \\ 
\hline
Avtomobila    &Avtomobil  &Avtomobil, cesta   &Avtomobil        \\ 
    \hline
     Slika mize z rožami      & Miza, roža   &Miza  &Miza, roža   \\ 
         \hline
    Avtomobil, ki vozi po cesti      & Avtomobil, cesta   &Avtomobil, cesta   &Avtomobil, oseba, cesta   \\ 
             \hline
    Oseba, ki hodi po ulici       & Oseba, ulica,cesta   &Oseba, ulica,cesta   &Oseba, ulica   \\ 
    \hline
\end{tabularx}
\end{center}
\end{table}

Tudi pri tej tabeli lahko vidimo da sta obe storitvi naredili napake. Opazimo da je Hugging Face Transformers večkrat napačno kategoriziral. 

Do napak pri zazvanju objektov prihaja zaradi različnih razlogov, na primer zaradi napak v algoritmu za zaznavanje objektov, zaradi slabe kakovosti slik ali zaradi prisotnosti motenj v okolju. 

Najpogosteje opažene napake pri zaznavi objektov:
\begin{enumerate}
 \item  Nenamerna zaznava: zaznava objektov, ki v dejanskem okolju niso prisotni.
  \item Nezaznavanje: izpuščanje objektov, ki so dejansko pristotni v okolju.
   \item Napačna zaznava: AI modeli lahko nepravilno zaznajo objekte.
 \end{enumerate}


\section{Diskusija}
\begin{table}[h!]
\centering
\caption{Tabela analize}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}

\multicolumn{1}{r}{} &                                                & \textbf{Hugging Face Transformers}             & \textbf{Google Vertex AI}                & \textbf{AWS SageMaker}               & \textbf{Azure Cognitive Services}                             \\ \hline 
\hline                                                                                                                                                                                                                                                                                                                                          
\textbf{Prepoznavanje imenskih entitet}                         &  Priklic  & 0.919               & 0.919                           & 0.961               & 0.824 \\
										   & Natančnost  & 0.923                & 0.920                  &0.954              & 0.858                                         \\
                                                                                       & F1 ocena    & 0.921                & 0.919                  & \textbf{0.958}               & 0.841    \\
\hline
\textbf{Analiza sentimenta}                         		 &  Priklic  & 0.926              & 0.936                  & 0.891               & 0.981       \\
										   & Natančnost  & 0.928               & 0.924                  & 0.862               & 0.862    \\
                                                                                       & F1 ocena    &  0.929              & \textbf{0.930}                   & 0.876               & 0.876      \\            
\hline                                                                                                     
\textbf{Povzemanje}                                      &  ROUGE-L  & 0.192                & 0.306                  & 0.201               & \textbf{0.330}    \\
  \hline                                                                                     
\textbf{Prepoznavanje besednih zvez}  	                           &  Priklic  & 0.573                & 0.543                  & 0.622              & 0.530 \\
										   & Natančnost  & 0.475                & 0.637                  & 0.513              & 0.670 \\
                                                                                       & F1 ocena    & 0.519                & 0.586                  & 0.562               &\textbf{0.592}   \\   
\hline                                                                                       
\textbf{Uvrščanje besedil}                                         &  Priklic  & 0.926                &  0.962                   &  0.763                &  0.920  \\  
										   & Natančnost  & 0.930                &  0.957                   &  0.858                &  0.880  \\
                                                                                       & F1 ocena    & \textbf{0.928}                &  0.907                   &  0.808                &  0.900     \\
\hline                                                                                       
\textbf{Zaznava objektov}  					    & Točnost  & 0.940                & 0.977                  & \textbf{0.980}               & 0.965  \\
   \hline
   \hline                                                          
\end{tabular}}
\end{table}
Pomembno je omeniti, da so vse oblačne storitve po rezultatih tesno skupaj v nekaterih primerih, kot je razvidno iz tabele analize je za  uvrščanje besedila  odprtokodna rešitev Hugging Face Transformers je imela najboljši rezultat. 
Pri testitranju  imenovanje imenskih entitet je najvišjo uspešnost dosegla storitev AWS Sage Maker. Na drugem mestu je bila odprtokodna storitev Hugging Face Transformers, medtem ko je tretje mesto zasedla storitev Vertex AI ponudnika Google Cloud.

Pri testiranju sentimentalne analize je najboljše rezultate dosegla storitev AWS SageMaker. Na drugo mesto se je uvrstila odprtokodna rešitev Hugging Face Transformers, medtem ko je tretje mesto zasedla storitev Vertex AI podjetja Google.

Najboljši rezultati  pri povzemanju besedila so bili doseženi z uporabo storitve Azure Cognitive Services. Na drugem mestu se je uvrstil Vertex AI, medtem ko je tretje mesto pripadlo AWS SageMaker.

Pri ocenjevanju izvlečka besednih zvez je prvo mesto osvojila storitev Azure Cognitive Services. Na drugem mestu je Vertex AI, medtem ko je tretjem mestu  AWS SageMaker.

Pri uvrščanju besedila se je najboljša učinkovitost pokazala pri odprtokodni platformi Hugging Face Transformers. Na drugem mestu je bila storitev Vertex AI, medtem ko je tretje mesto pripadlo storitvi Azure Cognitive Services.

V zaznavanju objektov je prvo mesto zasedla storitev Azure Cognitive Services, takoj za njo je sledil Vertex AI, medtem ko je tretje mesto pripadlo odprtokodni rešitvi Hugging Face Transformers.


\section{Odločitvena tabela}

\begin{table}[h!]
\centering
\caption{Odločitvena tabela }
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}
\multicolumn{1}{r}{}    & \textbf{Cena}             & \textbf{Enostavnost}                & \textbf{Uspešnost}                                        \\ \hline    \hline                                                                                                                                                                                                                                                                                                                                       
\textbf{Hugging Face Transformers}   & 2  & 4            & 4                                                          \\
\hline
\textbf{Google Vertex AI}         & 3  & 3              & 1                                                            \\
\hline
\textbf{AWS SageMaker}  & 4  & 2             & 2                                                    \\
\hline
\textbf{Azure Cognitive Services}   & 1  & 1            & 2                             \\

\hline\hline                                                                   
\end{tabular}}
\end{table}

Ocena cene v tabeli je bila določena glede na stroške ene iteracije glede na storitev. Pomembno je omeniti da smo za odprtokodno rešitev koristili virtualni stroj. 
Ocena enostavnosti uporabe temelji na naših izkušnjah iz uporabe storitev. Pri uporabi Azure Cognitive Services smo ugotovili, da je ta storitev izjemno enostavna za uporabo. Ponuja dobro dokumentacijo in uporabniku prijazen vmesnik, ki omogoča preprost razvoj storitev. Pri AWS SageMakerju smo opazili, da je potrebnih nekoliko več izkušenj z vmesniki. Ta platforma zahteva več truda pri učenju in je bolj tehnično zahtevna v primerjavi z Azure Cognitive Services. Google Vertex AI je bil ob v času raziskave še v razvoju in opaziti je bilo številne mankajoče informacije. To pomeni, da ta storitev morda ni tako zrela in dobro dokumentirana kot ostale storitve v analizi raziskave. Pri uporabi Transformerjev je bilo potrebno tehnično znanje za postavitev ustreznega delovnega okolja. Za oceno uspešnosti pa so uprabili rezulate z tabela analize (glej Tabela analize), kjer smo ponudnike razvrstili glede na uspešnost na vsakem posameznem področju (1 mesto je dobil najboljši ponudnik, ter 4 mesto najslapši ponudnik). 

 \newpage
 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{graf.png}
\end{center}
\caption{ Slikovni prikaz odločitvene tabele}
\label{pic2}
\end{figure}

Iz grafa je razvidno, da je najprimernejša storitev Azure Cognitive Services saj je najcenejša ter najenostavnejša rešitev za uporabo. 

%----------------------------------------------------------------
% Poglavje (Chapter) 6
%----------------------------------------------------------------
\chapter{Zaključek}
\label{ch8}

Magistrska naloga je obravnavala širok spekter področij obdelave naravnega jezika z uporabo oblačnih ter odprtokodne rešitev Hugging Face Transformers. Cilj raziskave je bil razumeti, kako se različni ponudniki odzivajo na različne izzive in naloge ter določiti njihovo uspešnost na posameznih področjih. Analiza je zajemala prepoznavanje imenskih entitet, analizo sentimenta, povzemanje besedil, luščenje ključnih besed, uvrščanje besedila ter zaznavo objektov.


Po zaključku analize ponudnikov storitev laho zaključimo, da je bil Azure Cognitive Services najcenejši, če upoštevamo, da smo morali za Hugging Face Transformers ločeno zakupiti infrastrukturo. Poleg tega je Azure Cognitive Services izstopal zaradi svoje preproste uporabe, kar je olajšalo raziskavo. Kljub temu pa je Google Vertex AI blestel kot najboljši ponudnik glede uspešnosti, kar je ključnega pomena za projekte, ki zahtevajo visoko zmogljive modele globokega učenja. Končna izbira med ponudniki bo odvisna od specifičnih potreb in ciljev projekta.

% ---------------------------------------------------------------
% Appendix
% ---------------------------------------------------------------
%00\appendix
%\addcontentsline{toc}{chapter}{Razširjeni povzetek}
%\chapter{Title of the appendix 1}

%Example of the appendix.

%----------------------------------------------------------------
% SLO: bibliografija
% ENG: bibliography
%----------------------------------------------------------------
\bibliographystyle{elsarticle-num}

%----------------------------------------------------------------
% SLO: odkomentiraj za uporabo zunanje datoteke .bib (ne pozabi je potem prevesti!)
% ENG: uncomment to use .bib file (don't forget to compile it!)
%----------------------------------------------------------------
%\bibliography{bibliography}

%----------------------------------------------------------------
% SLO: zakomentiraj spodnji del, če uporabljaš zunanjo .bib datoteko
% ENG: comment the part below if using the .bib file
%----------------------------------------------------------------

\begin{thebibliography}{99}
\bibitem{hugging} Hugging Face. Dostopno na: \url{https://huggingface.co/learn/nlp-course/chapter1/4}  [Dostopano 10. 06. 2023].
\bibitem{transformers} Transformers. Dostopno na: \url{https://huggingface.co/learn/nlp-course/chapter2/1?fw=pt}  [Dostopano 10. 06. 2023].
\bibitem{google} Google Cloud. Dostopno na: \url{https://cloud.google.com/natural-language#section-1}  [Dostopano 10. 06. 2023].
\bibitem{vertex} Vertex AI. Dostopno na: \url{https://cloud.google.com/vertex-ai}  [Dostopano 10. 06. 2023].
\bibitem{aws} Amazon Web Services (AWS).  Dostopno na: \url{https://aws.amazon.com/}  [Dostopano 10. 06. 2023].
\bibitem{sage} Amazon SageMaker.  Dostopno na: \url{https://aws.amazon.com/sagemaker/}  [Dostopano 10. 06. 2023].
\bibitem{azure} Azure. Dostopno na: \url{https://azure.microsoft.com/en-us}  [Dostopano 10. 06. 2023].
\bibitem{cognitive} Azure Cognitive Services. Dostopno na: \url{https://azure.microsoft.com/en-gb/products/cognitive-services}  [Dostopano 10. 06. 2023].
\bibitem{ner} Named Entity Recognition. Dostopno na: \url{https://www.shaip.com/blog/named-entity-recognition-and-its-types/}  [Dostopano 10. 06. 2023].
\bibitem{sentiment} Sentiment Analysis. Dostopno na: \url{https://aws.amazon.com/what-is/sentiment-analysis/}  [Dostopano 10. 06. 2023].
\bibitem{povzetek} Summarization. Dostopno na: \url{https://huggingface.co/tasks/summarization}  [Dostopano 10. 06. 2023].
\bibitem{luscenje} Keyphrase Extraction. Dostopno na: \url{https://www.geeksforgeeks.org/keyphrase-extraction-in-nlp/}  [Dostopano 10. 06. 2023].
\bibitem{klasifikacija} Text Classification. Dostopno na: \url{https://huggingface.co/tasks/text-classification}  [Dostopano 10. 06. 2023].
\bibitem{object} Object Detection. Dostopno na: \url{https://huggingface.co/tasks/object-detection}  [Dostopano 10. 06. 2023].
\bibitem{truevsfalse} True vs. False and Positive vs. Negative. Dostopno na: \url{https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative}  [Dostopano10. 06. 2023].
\bibitem{conll}Erik F. Tjong Kim Sang and Fien De Meulder  ``Introduction to the CoNLL-2003''. Dostopno na: \url{https://aclanthology.org/W03-0419.pdf}  [Dostopano 10. 06. 2023].
\bibitem{imdb} IMDB Dataset Reviews. Dostopno na: \url{https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews}  [Dostopano 10. 06. 2023].
\bibitem{coco} COCO 2017 Dataset. Dostopno na: \url{https://www.kaggle.com/datasets/awsaf49/coco-2017-dataset}  [Dostopano 10. 06. 2023].
\bibitem{cnn} CNN dailymail Dataset. Dostopno na: \url{https://huggingface.co/datasets/cnn_dailymail}  [Dostopano 10. 06. 2023].
\bibitem{semeval} SemEval-datasetst. Dostopno na: \url{https://www.kaggle.com/datasets/azzouza2018/semevaldatadets?resource=download}  [Dostopano 10. 06. 2023].
\bibitem{accuracy} Accuracy. Dostopno na: \url{https://developers.google.com/machine-learning/crash-course/classification/accuracy}  [Dostopano 10. 06. 2023].
\bibitem{percision} Precision and Recall. Dostopno na: \url{https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall}  [Dostopano 10. 06. 2023].
\bibitem{key_phrases_clanek} Xingdi Yuan, Tong Wang, Rui Meng, Khushboo Thaker, Peter Brusilovsky, Daqing He, Adam Trischler: One Size Does Not Fit All: Generating and Evaluating Variable Number of Keyphrases. Dostopno na: \url{https://arxiv.org/pdf/1810.05241.pdf}  [Dostopano 10. 06. 2023].
\bibitem{ner_clanek} Arya Roy: Recent Trends in Named Entity Recognition (NER).Dostopno na: \url{https://arxiv.org/pdf/2101.11420.pdf}  [Dostopano 10. 06. 2023].
\bibitem{najboljsi_cloud} Marak Hernans: The 100 Coolest Cloud Computing Companies Of 2023.Dostopno na: \url{https://www.crn.com/news/cloud/the-100-coolest-cloud-computing-companies-of-2023 }  [Dostopano 10. 06. 2023].
\bibitem{najboljsi1_cloud}  Paulo Gardini Miguel: Guide To The 23 Best Cloud Service Providers in 2023.Dostopno na: \url{https://thectoclub.com/tools/best-cloud-service-providers/ }  [Dostopano 10. 06. 2023].
\bibitem{obj1_clanek} Ali Borji, Seyed Mehdi Iranmanesh: Empirical Upper Bound in Object Detection and More Dostopno na: \url{https://arxiv.org/pdf/1911.12451.pdf}  [Dostopano 10. 06. 2023].

\bibitem{hf1} ODSC: 12 Most Popular NLP Projects of 2022 So Far. Dostopno na: \url{https://odsc.medium.com/12-most-popular-nlp-projects-of-2022-so-far-e11cd01e9a8}  [Dostopano 10. 11. 2022].
\bibitem{hf2} Juliette (Marketing manager at NLP Cloud): Top 10 Natural Language Processing Frameworks, Services And Actors In 2022. Dostopno na: \url{https://nlpcloud.com/top-10-nlp-frameworks-services-2022.html#hugging-face}  [Dostopano 10. 11. 2022].

\bibitem{sent_clanek} Mayur Wankhade, Annavarapu Chandra Sekhara Rao, Chaitanya Kulkarni: A survey on sentiment analysis methods, applications,
and challenges. Dostopno na: \url{https://link.springer.com/article/10.1007/s10462-022-10144-1}  [Dostopano 10. 06. 2023].
\bibitem{sent1_clanek} GUIXIAN XU, YUETING MENG, XIAOYU QIU, ZIHENG YU and XU WU: Sentiment Analysis of Comment
Texts Based on BiLSTM. Dostopno na: \url{https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8684825}  [Dostopano 10. 06. 2023].
\bibitem{povz_clanek} Divakar Yadav, Jalpa Desai, Arun Kumar Yadav: Automatic Text Summarization Methods: A Comprehensive Review. Dostopno na: \url{https://arxiv.org/pdf/2204.01849.pdf}  [Dostopano 10. 06. 2023].
\bibitem{imdb1_clanek} Beakcheol Jang, Myeonghwi Kim, Gaspard Harerimana, Sang-ug Kang and Jong Wook Kim: Bi-LSTM Model to Increase Accuracy in Text Classification: Combining Word2vec CNN and Attention Mechanism. Dostopno na: \url{https://www.mdpi.com/2076-3417/10/17/5841}  [Dostopano 10. 06. 2023].
\bibitem{uvrscanje_clanek} Xiaoyu Luo: Efficient English text classification using selected Machine Learning Techniques. Dostopno na: \url{https://www.sciencedirect.com/science/article/pii/S1110016821000806}  [Dostopano 10. 06. 2023].
\bibitem{pharses_clanek} Debanjan Mahata, John Kuriakose, Rajiv Ratn Shah, Roger Zimmermann : Automatic Ranked Keyphrase Extraction from Scientific Articles using Phrase Embeddings. Dostopno na: \url{https://osf.io/j76y3/download}  [Dostopano 10. 06. 2023].
\bibitem{zaznava_clanek} Lixuan Du, Rongyu Zhang, Xiaotian Wang : Overview of two-stage object detection algorithms . Dostopno na: \url{https://iopscience.iop.org/article/10.1088/1742-6596/1544/1/012033/pdf}  [Dostopano 10. 06. 2023].
\bibitem{summ_clanek} NLP Text Summarization – Popular Machine Learning And Deep Learning Algorithms . Dostopno na: \url{https://spotintelligence.com/2022/12/01/nlp-text-summarization/}  [Dostopano 10. 06. 2023].
\bibitem{kljucne_clanek} Algorithms to Detect Phrases and Keywords from Text . Dostopno na: \url{https://saturncloud.io/blog/algorithms-to-detect-phrases-and-keywords-from-text/}  [Dostopano 10. 06. 2023].
\bibitem{imdb_page} IMDB . Dostopno na: \url{https://www.imdb.com/}  [Dostopano 10. 06. 2023].

\end{thebibliography}

\end{document}
