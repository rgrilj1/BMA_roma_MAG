%================================================================
% SLO
%----------------------------------------------------------------
% datoteka: 	thesis_template.tex
%
% opis: 		predloga za pisanje diplomskega dela v formatu LaTeX na
% 				Univerza v Ljubljani, Fakulteti za računalništvo in informatiko
%
% pripravili: 	Matej Kristan, Zoran Bosnić, Andrej Čopar,
%			  	po začetni predlogi Gašperja Fijavža
%
% popravil: 	Domen Rački, Jaka Cikač, Matej Kristan
%
% verzija: 		30. september 2016 (dodan razširjeni povzetek)
%================================================================


%================================================================
% SLO: definiraj strukturo dokumenta
% ENG: define file structure
%================================================================
\documentclass[a4paper, 12pt]{book}
 

%================================================================
% SLO: Odkomentiraj "\SLOtrue " za izbiro slovenskega jezika
% ENG: Uncomment "\SLOfalse" to chose English languagge
%================================================================
\newif\ifSLO
\newif\ifTRACKEXIST
\newif\ifTRACKCS
\newif\ifPROGRAMMM

% ---------------------------------------------------------------------------------------
% IMPORTANT: Adjust the thesis language, your study program and course within this block
% ---------------------------------------------------------------------------------------
% switch language
\SLOtrue % Enables Slovenian language
%SLOfalse  % Enables English language

% switch programs: Computer science and Multimedia. Set to false if the program is in Multimedia
\PROGRAMMMfalse
%\PROGRAMMMtrue

% switch on if your program is divided into tracks CS and DS, otherwise leave it false
% CAUTION: if you were first enrolled into your program before school year 2019/2020, your program is not divided into tracks. In any case, be absolutely sure you select the correct variant. IF IN DOUBT, always contact the student office to advise you.
%
 \TRACKEXISTfalse
%\TRACKEXISTtrue

% default course name is "Computer science" if your course name is "Data science", set the following switch to false
\TRACKCStrue % uncomment if the thesis is from course "Information science"
%\TRACKCSfalse % uncomment if the thesis is from course "Data Science"
% -------------------------------------------------------------------------------------------
% End of language, program and course adjustment
% -------------------------------------------------------------------------------------------


%================================================================
% SLO: vključi oblikovanje in pakete
% ENG: include design and packages
%================================================================
\input{style/thesis_style}

%----------------------------------------------------------------
% |||||||||||||||||||||| USTREZNO POPRAVI |||||||||||||||||||||||
% |||||||||||||||||||||| EDIT ACCORDINGLY |||||||||||||||||||||||
%----------------------------------------------------------------
\newcommand{\ttitle}{Primerjava uspešnosti odprtokodnih in komercialnih orodij za luščenje podatkov}
\newcommand{\ttitleEn}{Performance comparison of open source and commercial information extraction tools}
\newcommand{\tsubject}{\ttitle}
\newcommand{\tsubjectEn}{\ttitleEn}
\newcommand{\tauthor}{Romana Grilj}
\newcommand{\temail}{romana.grilj@gmai.com}
\newcommand{\myyear}{2023}
\newcommand{\tkeywords}{analiza podatkov, ekstrakcija podatkov, strukturni podatki, spletno rudarjenje}
\newcommand{\tkeywordsEn}{Data analysis, Information Retrieval, structural data, Web Mining}
\newcommand{\mysupervisor}{doc.~dr.\ Slavko Žitnik}
%\newcommand{\mycosupervisor}{akad.~prof.~dr.\ Martin Krpan}
% include formatted front pages
\input{style/thesis_front_pages}

%================================================================
% ENG: main pages of the thesis
%================================================================f

%----------------------------------------------------------------
% Poglavje (Chapter) 1
%----------------------------------------------------------------
\chapter{Uvod}
\label{ch:uvod}

Obdelava naravnega jezika je eno izmed najhitreje razvijajočih se področij v umetni inteligenci, ki se ukvarja z obdelavo, razumevanjem in generiranjem naravnega jezika, kot ga uporabljamo ljudje za komunikacijo. Napredne tehnike obdelave naravnega jezika in modeli so v zadnjem desetletju privedli do prebojev v številnih storitvah, ki segajo od avtomatskega prevajanja in analize čustev do odgovarjanja na vprašanja in samodejnega povzemanja besedil, zato je zelo zanimivo področje za analizo. 

Cilj te magisterske naloge je podrobneje raziskati ter analizirati različne ponudnike storitev za obdelavo naravnega jezika ter zaznavo objektov, uporabo različnih korpusov glede na različna področja uporabe, predstavljene bodo najpogosteje uporabljene metrike za evalvacijo modelov. Potrebno je povdariti, da je na trgu prisotnih veliko storitev, tako za velika podjetja kot tudi za končne uporabnike. Opazimo lahko tudi veliko število odprtokodnih rešitev, ki so lahko nekoliko specifična glede na področje uporabe.

V nadaljevanju se bomo osredotočili na pomembnost kakovostnih korpusov za uspešno učenje modelov. Pregledali bomo obstoječe in priljubljene korpuse, ki se uporabljajo za različne naloge.
Kot ključen element bomo preučili metrike za ocenjevanje učinkovitosti modelov, kot so natančnost, F1-ocena, ROUGE in druge. Razložili bomo, kako se uporabljajo za različne naloge in kako lahko z njimi ocenimo zmogljivost modelov.

Nato se bomo posvetili raznolikim področjem uporabe tehnologij obdelave naravnega jezika. Raziskali bomo, kako se tehnologije uporabljajo v  analizi čustev, povzemanje, iskanju informacij in še več. Preučili bomo tudi izzive in omejitve, s katerimi se srečujejo modeli pri uporabi na različnih področjih.

V poglavju~\nameref{ch4}  bomo podrobneje spoznali izbrane funkcionalnosti, ki jih omogočajo modeli, ki temeljijo na umetni inteligenci in strojnem učenju ter so zasnovane za obdelavo, razumevanje in generiranje naravnega jezika. Različni modeli se uporabljajo za reševanje različnih nalog, povezanih z obdelavo jezika, kot so avtomatsko prevajanje, analiza čustev, razumevanje besedil, odgovarjanje na vprašanja, izluščevanje informacij iz besedil, uvrščanje besedil in še več.

V poglavju~\nameref{ch5} bomo podrobneje spoznali uporabljene korpuse, ki so ključnega pomena za uspešen razvoj, učenje in evalvacijo modelov. Korpusi so zbirke podatkov, ki so ročno označeni ali označeni s pomočjo algoritmov za različne naloge.

V poglavju ~\nameref{ch6}  bomo temeljito raziskali različne metrike, ki omogočajo oceno učinkovitosti modelov glede na njihove specifične naloge. Raznolikost nalog na področju obdelave naravnega jezika zahteva prilagodljivost pri izbiri metrik. Predstavljene navedene ključne metrike, ki jih bomo uporabljali pri evalvaciji modelov.

V predzanjem poglavju ~\nameref{ch7}  so predstavljeni rezultati različnih ponudnikov ter njihovih storitev.



Pridobili bomo pregled nad uporabo modelov ter njihovo uporabo na različnih področij. Cilj raziskave je prispevati k boljšermu razumevanju  tehnologij obdelave naravnega jezika ter zaznave objektov in predstaviti rezultate med različnimi ponudkniki storitev.
%----------------------------------------------------------------
% Poglavje (Chapter) 2
%----------------------------------------------------------------

%----------------------------------------------------------------
% Poglavje (Chapter) 3
%----------------------------------------------------------------

%----------------------------------------------------------------
% Poglavje (Chapter) 4
%----------------------------------------------------------------

%----------------------------------------------------------------
% Poglavje (Chapter) 5
%----------------------------------------------------------------


%----------------------------------------------------------------
% Poglavje (Opis funkciionalnosti) 5
%----------------------------------------------------------------
\chapter{Opis ponudnikov in storitev}
\label{ch3}
Izbrani ponudniki so bili Google Cloud, Amazon Web Services in Microsoft Azure, saj so bili po člankih prepoznani kot najbolj razširjeni in zanesljivi oblačni ponudniki na trgu. 

Za analizo je bila uporabljena odprtokodna platforma Hugging Face Transforemers, ki je po objavljenih člankih dosegel najboljše rezultate. Platforma je bil je prepoznana kot izjemno učinkovita in zmogljiva, ki se je odlično izkazala pri obdelavi različnih nalog.


\section{Hugging Face}
\label{sec:transformers}
Hugging Face je platforma na področju obdelave naravnega jezika in strojnega učenja. Njihova rešitev je postala zelo uporabna na področju raziskav, razvoja in uporabe strojnega učenja. 

Njihova glavna odprtokodna knjižnica "Transformers" je postala temelj raziskav obdelave naravnega jezika, saj ponuja več kot 315.000 modelov, kot so GPT, BERT, RoBERTa in drugih, ki so ključni za različne naloge, vključno z razumevanjem jezika, strojnim prevajanjem, analizo čustev in generiranjem besedila.

Hugging Face Hub \cite{hugging} je platforma, ki spodbuja sodelovanje in izmenjavo med raziskovalci, razvijalci in navdušenci nad strojnim učenjem. Ta platforma omogoča enostavno deljenje in odkrivanje modelov, kar olajša razvoj novih aplikacij in omogoča dostop do že pripravljenih modelov.
Področje obdelave naravnega jezika je prvič bilo na voljo leta 2017.  

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=8cm]{transf.png}
\end{center}
\caption{Hugging Face}
\label{pic2}
\end{figure}

\subsection{Hugging Face Transformers }
Hugging Face Transformers \cite{transformers} je odprtokodna knjižnica, ki je postala ena najpomembnejših orodij za obdelavo naravnega  jezika in strojnega učenja. Njen cilj je ponuditi razvijalcem enostaven dostop do najnovejših arhitektur in modelov. Zgrajena je na osnovi Pythona in je postala ključno orodje za reševanje izzivov na področju obdelave naravnega jezika in razvoja aplikacij ter storitev.

Ena od ključnih prednosti Hugging Face Transformers je enostavnost uporabe. Razvijalci lahko z nekaj vrsticami kode dostopajo do pred-treniranih modelov in jih takoj uporabljajo. Poleg tega knjižnica omogoča tudi prilagajanje modelov in ponuja odprtokodno skupnost, ki nenehno prispeva z novimi modeli, izboljšavami in rešitvami.

Knjižnica ponuja tudi funkcionalnosti za preprosto prenosljivost modelov med različnimi platformami in orodji za povečanje učinkovitosti uporabe modelov na stvarnih sistemih. Poleg tega Hugging Face Transformers omogoča tudi preprosto združevanje z drugimi knjižnicami za strojno učenje in obdelavo podatkov.  

Podpora različnih jezikov je pogojena v prvi vrsti z izbiro modela.
Transforjerji ponujajo širok nabor storitev za obdelavo naravnega jezika in sicer: uvrščanje besedil, prevajanje, povzemanje, znakovno uvrščanje, tabela vprašanj odgovorov, odgovori na vprašanja, razvrščanje brez vzorcev, klepet, generiranje besedila, dodajanje mankajočih besed, podobnost besed  


\section{Google Cloud}
\label{sec:google}
Google Cloud  \cite{google} je celovita platforma za računalništvo v oblaku, ki jo zagotavlja Google. Ponuja različne storitve ko so: shranjevanje, bazami podatkov, strojnim učenjem, kar omogoča podjetjem, da gradijo in razvijajo aplikacije ter storitve v globalnem obsegu. Google Cloud zagotavlja prilagodljivo in razširljivo infrastrukturo, ki organizacijam omogoča inovacije ter optimizacijo operacij prek rešitev v oblaku. S svojimi podatkovnimi centri po vsem svetu Google Cloud zagotavlja zanesljivo zmogljivost, varnost in dostopnost za podjetja vseh velikosti.

Področje obdelave naravnega jezika je bilo dodano v Google cloud leta 2015. Ponuja več kot 100 različnih modelov, najbolj prepoznavni modeli so OWL-ViT, BERT ter PaLM kateri se uporablja za obdelavo naravnega jezika.


 \begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm]{cloud.png}
\end{center}
\caption{Google Cloud storitve}
\label{pic2}
\end{figure}
 \newpage
\subsection{Vertex AI }
Vertex AI \cite{vertex} je napredna platforma za umetno inteligenco v oblaku, ki jo ponuja Google Cloud. S podporo za številne priljubljenena ogrodja (framework) za strojno učenje, kot so TensorFlow ter PyTorch je Vertex AI odlična izbira za razvijalce z različnimi potrebami in izkušnjami.
Platforma Vertex AI ponuja tudi številne napredne storitve in orodja za razvoj in optimizacijo modelov. Vključuje integrirano orodje, ki omogoča hitro in enostavno oceno uspešnosti modelov na različnih primerih rabe. Prav tako ponuja samodejno prilagajanje hiperparametrov, kar omogoča avtomatsko iskanje najboljših hiperparametrov za izboljšanje zmogljivosti modelov. 
Prvotno je bila izdana leta 2020 in ima že več kot 100.000 uporabnikov po vsem svetu. Uporabljajo jo raznolika podjetja, od majhnih startupov do velikih korporacij, kot so Walmart, Pfizer in Coca-Cola.
Podpirajo kar 11 različnih jezikov in sicer: Angleščina, Francoščina, Nemščina, Španščina, Kitajščina (poenostavljena), Kitajščina (tradicionalna), Japonščina, Korejščina,Portugalščina ter Ruščina. 

Vertex AI ponujajo širok nabor storitev za obdelavo naravnega jezika in sicer: sentimentalna analiza, analiza entitete, analiza sentimenta entitete, analiza sintakse, vsebinsko uvrščanje.  
Vertex Ai lahko uporabljamo z več programskimi jeziki kot so: Go, Java, Node.js, Python. 

Ena od ključnih funkcij Vertex AI je tudi funkcija Vertex Data Labeling, ki omogoča enostavno označevanje podatkov za učenje modelov. 

\section{Amazon Web Services }
\label{sec:aws}
Amazon Web Services \cite{aws} je ponudnik storitev v oblaku, ki jih ponuja Amazon. Uporabnikom omogoča najem računalniških virov, kot so strežniki in shramba. To omogoča organizacijam, da prilagodljivo in učinkovito gradijo, upravljajo ter skalirajo svoje aplikacije in storitve brez potrebe po fizični strojni opremi. AWS je mednarodno priznan za svojo zanesljivost in širok nabor storitev za obdelavo podatkov, analitiko, umetno inteligenco ter druge poslovne potrebe. 

Področje obdelave naravnega jezika je bilo dodano leta 2017. V Evropi pa je bil dostopen šele leto kasneje. Ponuja več kot 500 vnaprej treniranih modelov, med njimi lahko najdemo 
Mobilenet, YOLO, Faster R-CNN, BERT, lightGBM ter druge.

Podpora različnih jezikov je pogojena v prvi vrsti z izbiro modela.

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=8cm]{amazonAWS}
\end{center}
\caption{Amazon Web Services storitve}
\label{pic2}
\end{figure}

 \newpage
\subsection{Amazon SageMaker}
Amazon SageMaker \cite{sage} je storitev za strojno učenje, ki jo ponuja Amazon Web Services (AWS). Omogoča hitro in enostavno izgradnjo, usposabljanje in razporejanje zmogljivih modelov, kar omogoča razvoj naprednih rešitev in izboljšanje procesov. Ponuja intuitiven uporabniški vmesnik in API-je, ki omogočajo hitro postavitev in upravljanje. SageMaker ponuja tudi integrirano okolje Jupyter, ki omogoča uporabo interaktivnih beležnic za raziskovanje in analizo podatkov. 

Amazon SageMaker ponujaja širok nabor storitev za obdelavo naravnega jezika in sicer: uvrščanje besedil, analiza sentimenta, prepoznavanje imenskih entitet, prevanjanje, povzemanje ter druge. 

Uporabljamo ga lahko z pomočjo dveh različnih programskih jezikov R ter Python. 

Področje obdelave naravnega jezika je bilo dodano leta 2017. 

\section{Microsoft Azure}
\label{sec:azure}
Azure \cite{azure} je oblačna platforma, ki jo ponuja Microsoft, namenjena podjetjem za razvoj, upravljanje in gostovanje njihovih aplikacij in storitev prek interneta v oblaku. Ponuja širok nabor storitev, vključno s spletnim gostovanjem, shranjevanjem podatkov, analitiko, umetno inteligenco in spletnimi storitvami. Uporabniki lahko ustvarjajo virtualne strežnike in omrežja ter jih prilagajajo glede na svoje potrebe. Azure zagotavlja visoko stopnjo varnosti in skladnosti, kar je ključno za zaščito podatkov in zagotavljanje zasebnosti strank. 

Področje obdelave naravnega jezika je bilo dodano leta 2018. Ponuja 26 osnovnih modelov, ki so pripravljeni za takojšno uporabo. Kot zanimivost lahko omenimodva svetovo poznana modela text-davinci-003 ter GPT-35-turbo, ki je svetovo znan kot ChatGPT. 

Azure ponuja široko podporo različnim jezikom, skupno več kot 96.Nekateri izmed njih so: Angleščina, Finščina, Francoščina, Danščina , ter druge. Kar je zelo pomembno omeniti podpira tudi Slovenski jezik.   

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=14cm]{MSAzure.png}
\end{center}
\caption{Microsoft Azure storitve}
\label{pic2}
\end{figure}

\subsection{Azure Cognitive Services }
Azure Cognitive Services \cite{cognitive} je celovita in napredna platforma za umetno inteligenco (AI), ki jo ponuja Microsoftova platforma Azure. Te storitve omogočajo analizo in razumevanje naravnega jezika v besedilu, kar omogoča razvoj aplikacij za avtomatsko razvrščanje besedil, odgovarjanje na vprašanja, prevajanje besedil in analizo sentimenta. Ponuja širok nabor naprednih storitev in API-jev, ki omogočajo prepoznavanje, razumevanje in generiranje naravnega jezika, prepoznavanje obrazov, prepoznavanje govora, analizo besedil, prevajanje med jeziki in še veliko več. Te storitve omogočajo razvoj pametnih aplikacij, ki temeljijo na umetni inteligenci, in reševanje različnih izzivov na področju razumevanja in analize podatkov. 

Azure Cognitive Services ponujaja širok nabor storitev za obdelavo naravnega jezika in sicer: prepoznava entitet, sentimentalna analiza, odgovarjanje na vprašanja, prevajanje. 

Uporabljamo ga lahko z pomočjo več različnih programskih jezikov C\#, Java, JavaScript, Python. 

%----------------------------------------------------------------
% Poglavje (Opis funkciionalnosti) 5
%----------------------------------------------------------------
\chapter{Izbrana področja uporabe}
\label{ch4}
\section{Prepoznavanje imenskih entitet}
\label{sec:ner}
Prepoznavanje imenskih entitet \cite{ner} je tehnika na področju obdelave naravnega jezika, ki se uporablja za prepoznavanje in klasifikacijo besed v besedilu. Te posebne vrste so imenovane entitete, kot so imena oseb, organizacij, lokacij, datumov, številk, denarnih zneskov in drugih specifičnih poimenovanj.

Cilj je prepoznati in določiti začetek in konec posameznih entitet v besedilu ter jim pripisati ustrezno kategorijo.

Številne praktične uporabe:
\begin{enumerate}
 \item  Avtomatsko označevanje imenskih entitet v novicah, člankih in drugih besedilnih vsebinah.
 \item Razumevanje strukture in vsebine dokumentov za informacijsko iskanje in kategorizacijo.
 \item Pomoč pri analizi sentimenta, kjer želimo razumeti, kako se osebe, organizacije ali druge entitete omenjene v besedilu nanašajo na določeno temo ali izdelek.
\end{enumerate}
 
 
 \begin{figure}[h!]
\begin{center}
\includegraphics[width=12cm]{named.png}
\end{center}
\caption{Primer prepoznavanja imenskih entitet}
\label{pic2}
\end{figure}




\section{Analiza sentimenta}
Analiza sentimenta \cite{sentiment} je proces določanja čustvenega odziva, nagnjenosti ali stališča zapisanega besedila. Cilj analize sentimenta je ugotoviti, ali je določeno besedilo pozitivno, negativno ali nevtralno. To je lahko koristno pri analizi mnenj strank, razumevanju čustvenega odziva na izdelke, blagovne znamke, dogodke in druge. 


 Obstaja več pristopov k analizi sentimenta:
\begin{enumerate}
 \item Pravilni pristopi: Uporabljajo se predvsem pravila in vzorci za identifikacijo pozitivnih in negativnih izrazov v besedilu. Na primer, besede, kot so "dobro", "fantastično", "radostno" itd., bi bile označene kot pozitivne, medtem ko bi bile besede, kot so "slabo", "žalostno", "neznosno" in tako dalje označene kot negativne.
 \item Strojno učenje na podlagi besedila: Ta pristop vključuje uporabo algoritmov strojnega učenja, ki so naučeni prepoznati čustveni naboj besed v besedilu na podlagi velikega števila označenih podatkov (besedil s čustvenimi oznakami). 
 \item Analiza sentimenta s čustvenimi slovarji: Ta pristop vključuje uporabo slovarjev z besedami in izrazoslovjem, ki so povezani z določenimi čustvi. Besedilo se nato preveri in oceni glede na prisotnost pozitivnih ali negativnih besed iz čustvenih slovarjev.
 \item Algoritmi globokega učenja.
 \end{enumerate}
 
 \begin{figure}[h!]
\begin{center}
\includegraphics[width=12cm]{sentiment.png}
\end{center}
\caption{Primer analize sentimenta}
\label{pic2}
\end{figure}


 \section{Povzemanje besedila}
Pri povzermanju besedila \cite{povzetek} gre za postopek ustvarjanja krajšega in jedrnatega povzetka iz daljšega besedila, kot je članek ali dokument. Namen povzemanja je izluščiti ključne informacije in ideje iz izvornega besedila ter jih predstaviti na bolj pregleden in krajši način. To je zelo koristno pri velikih količinah podatkov, ko želimo hitro pridobiti bistvo informacij, ne da bi brali celotno besedilo.

Tehnike za povzemanje uporabljajo različne algoritme in metode, ki vključujejo strojno učenje in obdelavo naravnega jezika, da bi učinkovito izluščile ključne besede, stavke ali odstavke, ki predstavljajo osrednje ideje v izvornem besedilu. Rezultat je običajno kratek povzetek, ki ohranja pomembne informacije iz izvirnega besedila. Ta tehnologija ima širok spekter uporab, kot so samodejno povzemanje novic, generiranje opisov izdelkov, izdelava povzetkov raziskovalnih člankov in še veliko več. 
 
  \begin{figure}[h!]
\begin{center}
\includegraphics[width=12cm]{povzetek.png}
\end{center}
\caption{Primer povzemanja besedila}
\label{pic2}
\end{figure}
 
 \section{Prepoznavanje besedih zvez}
Prepoznavanje besedih zvez  \cite{luscenje}Nanaša se na besede ali izraze, ki so najpomembnejši ali najbolj značilni za določeno besedilo ali dokument. Te besede so običajno tiste, ki nosijo ključne informacije ali so bistvene za razumevanje vsebine.

Je pomembna naloga, saj nam omogoča, da hitro ugotovimo, o čem govori določeno besedilo. Te besede so lahko uporabne tudi za avtomatsko indeksiranje dokumentov, iskanje relevantnih informacij in razumevanje teme besedila brez potrebe po branju celotnega besedila.

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=12cm]{kljucne.png}
\end{center}
\caption{Primer prepoznavanja besedih zvez}
\label{pic2}
\end{figure}


 \section{Uvrščanje besedil}
 Uvrščanje besedil \cite{klasifikacija} je tehnika, pri kateri avtomatizirano določimo kategorijo ali razred določenega besedila na podlagi vsebine besedila. To je lahko zelo uporabno, saj nam omogoča razvrščanje besedil v različne skupine glede na njihovo vsebino. 

Postopek klasifikacije besedil se običajno začne s pripravo in čiščenjem besedil. To vključuje odstranjevanje nepotrebnih znakov, šumnikov, posebnih znakov, pretvorbo vseh črk v male črke, lahko pa tudi odstranjevanje pogostih besed, ki nimajo velikega pomena za klasifikacijo (npr. "in", "ali", "je", "na", itd.).

Nato se besedila predstavijo v obliki, ki jo lahko uporabimo za učenje modela. Pogosto se uporablja metoda imenovana vreča besed ("Bag-of-Words"), kjer se besedilo pretvori v nabor besed, ki se pojavljajo v njem, in število pojavitev teh besed. Ta postopek lahko ponazorimo s pomočjo vektorja. 

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=12cm]{uvrscanje.png}
\end{center}
\caption{Primer uvrščanja besedil}
\label{pic2}
\end{figure}

 
 
  \section{Zaznava objektov}
Zaznava objektov \cite{object} je tehnika, ki se uporablja za avtomatsko zaznavanje in identifikacijo objektov na digitalnih slikah ali video posnetkih. Namen te tehnike je, da  prepozna in označi različne objekte v podobi ter jih loči od ozadja ali drugih objektov.

Postopek objektnega zaznavanja običajno vključuje naslednje korake:
\begin{enumerate}
 \item Zaznavanje: Model preučuje sliko ali video posnetek in identificira regije, kjer bi se lahko nahajali objekti.
 \item Zaznava lokacije: Po tem, ko so bile regije prepoznane, algoritem določi omejitveno okvirje (bounding boxes), ki natančno označujejo položaje in mejne točke objektov na sliki.
 \item Uvrščanje: Ko so objekti omejeni z omejitvenimi okviri, analizira vsebino znotraj teh okvirov in jih razvrsti v različne kategorije (npr. avto, pes, zgradba, itd.).
 \item  Sledenje: V video posnetkih je lahko zaželeno, da algoritem sledi objektom skozi različne kadre in tako beleži njihovo gibanje.
 \end{enumerate}
Zaznava objektov se uporablja v številnih aplikacijah, kot tudi v samovozečih vozilih za zaznavanje drugih vozil in pešcev, identifikacija prometnih znakov, nadzorne kamere, prepoznavanje obrazov, analiza medicinskih slik in še veliko drugega. Gre za enega ključnih elementov umetne inteligence. 
 \begin{figure}[h!]
\begin{center}
\includegraphics[width=12cm]{objectDT.png}
\end{center}
\caption{Primer zaznave objektov}
\label{pic2}
\end{figure}

 %----------------------------------------------------------------
% Poglavje (Uporabljeni dataseti) 6
%----------------------------------------------------------------f
\chapter{Korpusi}
\label{ch5}
\section{Kaj je korpus?}
Je zbirka podatkov, ki so organizirani in shranjeni v strukturirani ali ne-strukturirani obliki ter označeni za namen analize, raziskav, učenja modelov ali drugih postopkov obdelave podatkov. Korpusi vsebujejo različne vrste podatkov, od številk, besedil, slik, zvokov, videoposnetkov do drugih tipov informacij.
V kontekstu računalniškega znanstvenega modeliranja in strojnega učenja so korpusi ključnega pomena, saj služijo kot osnova za razvoj, treniranje in evalvacijo modelov. Modeli se učijo na teh podatkih, tako da prepoznajo vzorce in povezave med vhodnimi podatki in ciljnimi izhodi.
Na primer, v naravnojezikovni obdelavi  korpusov vsebuje besedilne podatke, ki so lahko članki, knjige, novičarski članki ali socialni mediji. 

\vspace{\baselineskip}
Nekatere ključne točke o uporabi korpusov:

\emph{Učenje modelov: } Korpusi se uporabljajo za učenje modelov, pri čemer modeli na osnovi teh podatkov pridobivajo razumevanje jezika in njegove strukture. Čeprav obstajajo tudi nespremljani pristopi, večina uspešnih modelov zahteva velike, kakovostne in označene korpuse za doseganje najboljših rezultatov.

\emph{Razvoj in optimizacija:}  Razvijalci modelov uporabljajo različne korpuse za optimizacijo modelov in prilagajanje hiperparametrov. Z vzorci podatkov iz korpusov se preizkušajo različne arhitekture modelov in strategije učenja.

\emph{Evaluacija:}  Korpusi se uporabljajo za evalvacijo modelov. Preizkušajo se na ločenem testnem korpusu, ki modelom omogoča, da se oceni, kako dobro delujejo na novih, nevidenih podatkih.

\emph{Nadzor kakovosti:}  Kvaliteta korpusov je ključnega pomena za uspešno delovanje modelov. Zato je pomembno, da so korpusi natančno označeni in urejeni. Nadzor kakovosti pomaga prepoznati morebitne napake ali pristranskosti v korpusih.

\emph{Prilagajanje specifičnim aplikacijam: } Včasih so potrebni specializirani modeli za določene aplikacije ali domene. V takih primerih je morda potrebno ustvariti ali prilagoditi korpuse, ki se bolje prilegajo ciljni uporabi.

\emph{Razvoj modelov za redke jezike: } Razvoj  modelov obdelave naravnega jezika za redke jezike zahteva ustrezne korpuse v ciljnem jeziku, kar je lahko izziv, saj so ti korpusi pogosto omejeni ali pa jih sploh ni na voljo.

Pomembno je, da so korpusi pravilno pripravljeni, imajo ustrezne metapodatke in so primerni za ciljno nalogo, da bi omogočili kakovostno analizo in doseganje uporabnih rezultatov.

\section{Uporabljeni korpusi}
\subsection{CoNLL 2003}
\label{sec:my_subsection}
 Je zbirka podatkov, ki se uporablja za razvoj in evalvacijo sistemov za obdelavo naravnega jezika, prevsem za nalogo imenskih entitet.  Imenuje se po konferenci CoNLL (Conference on Computational Natural Language Learning) leta 2003, kjer je bil ta nabor podatkov predstavljen v okviru tekmovanja za prepoznavanje imenovanih entitet.
 Korpus CoNLL 2003 je priljubljen referenčni korpus za prepoznavanje poimenovanih entitet naravnega jezika v obdelavi naravnega jezika. Uporabljen je bil v skupni nalogi na konferenci o računalniškem učenju naravnega jezika (CoNLL) leta 2003.

Poimenovane entitete so razdeljene v štiri glavne kategorije:
\begin{enumerate}
 \item Oseba (PER): Posamezna imena ljudi.
 \item Organizacija (ORG): Imena podjetij, ustanov ali organizacij.
 \item Lokacija (LOC): Imena geografskih lokacij, kot so mesta, države ali regije.
 \item Razno (MISC): Druge poimenovane entitete, ki ne spadajo v zgoraj navedene kategorije, na primer datumi, odstotki ali denar.
 \end{enumerate}
 Podatki v korpusu so predstavljeni v obliki ene besede na vrstico, kjer vsaka vrstica predstavlja besedo in pripadajočo oznako v stavku. Besede in oznake so ločene z presledkom.
 Korpus CoNLL 2003 \cite{conll}se pogosto uporablja za evalvacijo zmogljivosti modelov za prepoznavanje poimenovanih entitet in že več let je standardno merilo (benchmark) za raziskovalce in strokovnjake v skupnosti obdelave naravnega jezika. Ostaja dragocen vir za razvoj in preizkušanje novih algoritmov in sistemov za prepoznavo imenskih intitet. 

\begin{table}[h!]
\caption{Primer CoNLL 2003 korpusa}
    \begin{center}
        \begin{tabular}{l|ccc}
                        {He PRP B-NP O} \\
{will MD B-VP O} \\
{probably RB I-VP O} \\
{be VB I-VP O} \\
{replaced VBN I-VP O} \\
{by IN B-PP O} \\
{Shearer NNP B-NP B-PER} \\
{'s POS B-NP O} \\
{Newcastle NNP I-NP B-ORG} 
                        
        \end{tabular}
    \end{center}
\label{tbl:1}
\end{table}


CoNLL2003  podatkovna zbirka je običajno razdeljena na tri sklope:
\begin{enumerate}
 \item učni (train) z 14.000 vrsticami  primerov
 \item validacijski (validation) z 3.250 vrsticami primerov
 \item preizkusni (test) z 3.450 vrsticami primerov
 \end{enumerate}

\subsection{IMDb Reviews}
\label{sec:imdb}
IMDB podatkovna zbirka, znana tudi kot IMDB Movie Reviews Dataset \cite{imdb}. Sestavljen iz pregledov filmov, ki so jih prispevali uporabniki na spletni strani IMDb (Internet Movie Database).

Podatki vsebujejo ocene in besedilne komentarje, ki jih je ustvarila skupnost uporabnikov IMDb. Vsak pregled vsebuje besedilni komentar in oceno filma, ki se giblje med 1 (najslabša) in 10 (najboljša). Cilj te podatkovne zbirke v naravnem jeziku je razviti modele, ki lahko avtomatsko analizirajo besedilne komentarje in napovedo, ali je pregled pozitiven ali negativen glede na oceno in besedilo. 

\begin{table}[h!]
\centering
\caption{Primer IMDB korpusa }
\resizebox{\textwidth}{!}{%
 \begin{tabular}{l|ccc}
\hline
{review}            & sentiment             \\ \hline                                                                                                                                                                                                                                                                                                                                           
If you like original gut wrenching laughter you will like movie.   & positive            \\
A rating of "1", depressing and relentlessly bad this movie is.  & negative                                                                     
\end{tabular}}
\end{table}



IMDB podatkovna zbirka je običajno razdeljena na dva sklopa: 
\begin{enumerate}
 \item učni (train) z 25.000 vrsticami  primerov
 \item preizkusni (test) z 25.000 vrsticami primerov
 \end{enumerate}
Vsak sklop vsebuje tisoče pregledov filmov. To je idealna podatkovna zbirka za naloge analize čustvenega tona besedil (sentiment analysis), kjer modeli ocenjujejo, ali je mnenje v besedilu pozitivno, negativno ali nevtralno.

\subsection{ COCO }
\label{sec:coco}
COCO (Common Objects in Context) \cite{coco} je nabor podatkov v področju računalniškega vida in zaznave objektov. Namenjen je zagotavljanju celovite in raznolike zbirke slik za različne naloge, vključno z zaznavo objektov, segmentacijo in podnaslavljanjem. Nabor podatkov naj bi odražal scenarije iz resničnega sveta in vsebuje slike, ki so kompleksne ter vključujejo več objektov v različnih kontekstih.

Nabor podatkov je obsežen in vsebuje deset tisoče slik z milijoni označenih posameznih objektov. Slike prihajajo iz različnih virov, zajemajo raznolike prizore, ozadja, svetlobne pogoje in velikosti objektov.


Ključne značilnosti:
\begin{enumerate}
 \item Kategorije slik: Nabor podatkov  vsebuje slike, ki zajemajo 80 različnih kategorij objektov, od splošnih objektov, kot so "oseba," "avto" in "pes," do bolj specifičnih objektov, kot so "mobilni telefon," "zobna ščetka" in "zmaj."

 \item Anotacije: Vsaka slika v korpusu je opremljena z oznakami na ravni objekta in koordinatami  okvirja. To pomeni, da je vsak posamezen objekt določene kategorije znotraj slike označen, okoli njega pa je narisano območje z okvirjem, ki označuje njegovo lokacijo. Informacije o anotacijah so ključnega pomena za usposabljanje modelov za detekcijo objektov in segmentacijo.

 \item Segmentacija objektov: zagotavlja maske segmentacije na ravni slikovnih pik za vsak posamezen objekt. To pomeni, da so objekti ne le lokalizirani z okviri, ampak so natančno določene tudi meje objektov na ravni slikovnih pik. 
 \end{enumerate}
 
 Korpus je razdeljen na dva sklopa: 
\begin{enumerate}
 \item učni (train) z 117.000 primeri
 \item preizkusni (test) z 4.950 primeri
 \end{enumerate}
 
   \begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm]{000000502136.jpg}
\end{center}
\caption{000000502136.jpg}
\label{pic2}
\end{figure}
 
 
\begin{figure}[h!]
 \centering
 \begin{tiny}
\begin{verbatim}
   [{
        "license": 3,
        "file_name": "000000502136.jpg",
        "coco_url": "http://images.cocodataset.org/val2017/000000502136.jpg",
        "height": 423,
        "width": 500,
        "date_captured": "2013-11-15 17:08:30",
        "flickr_url": "http://farm3.staticflickr.com/2253/1755223462_fabbeb8dc3_z.jpg",
        "id": 502136
    },
    {
        "segmentation": [
            [
                54.74,
                350.34,
                53.75,
                353.33,
                    ...
                    349.35
            ]
        ],
        "area": 4651.359250000001,
        "iscrowd": 0,
        "image_id": 502136,
        "bbox": [
            3.98,
            289.63,
            120.43,
            103.51
        ],
        "category_id": 64,
        "id": 21011
    }]
\end{verbatim}
\end{tiny}
\caption{COCO .json primer}
\end{figure}
 
 \newpage
 
 
 \subsection{ CNN/Daily Mail }
 \label{sec:cnn}
 CNN/Daily Mail je zbirka novičarskih člankov skupaj s povzetki, ki se uporablja za usposabljanje in preizkušanje modelov za povzemanje besedil. Ta nabor podatkov vsebuje različne novičarske članke in njihove povzetke, zaradi česar je primeren za naloge abstraktivnega povzemanja, kjer se ustvarijo povzetki v lastnih besedah, ne le izbirajo stavke iz izvornega besedila.
 Nabor podatkov vsebuje na tisoče člankov s pripadajočimi povzetki, kar omogoča raziskovalcem obsežno treniranje in evaluiranje modelov.\cite{cnn}
 
Ključne značilnosti korpusa:
 \begin{enumerate}
  \item Novičarski Članki in Povzetki: Nabor podatkov vsebuje novičarske članke iz medijskih virov, kot sta CNN (Cable News Network) in Daily Mail, skupaj s pripadajočimi povzetki. Ti članki pokrivajo različne teme in dogodke ter so različnih dolžin.
 \item Abstraktno Povzemanje: Vključuje ustvarjanje povzetka v povsem novih besedah. 
  \end{enumerate}
 
 \begin{table}[h!]
\centering
\caption{Primer cnn\_dailymail korpusa }
\resizebox{\textwidth}{!}{%
 \begin{tabular}{l|ccc}
\hline
{label}            & text     & highlights          \\ \hline                                                                                                                                                                                                                                                                                                                                           
002509a...   &Fears are growing that Britain's jails are becoming... & Athens pushes through...            \\
7526a1...  &  It was a farce that would lead to... &AZ Alkmaar were playing....                                                                     
\end{tabular}}
\end{table}
 
 
  
  
Korpus jerazdeljen na tri sklope: 
\begin{enumerate}
 \item učni (train) z 287.000 vrsticami  primerov
 \item validacijski (validation) z 13.400 vrsticami primerov
 \item preizkusni (test) z 11.500 vrsticami primerov
 \end{enumerate}
 
 \subsection{ SemEval - 2017}
  \label{sec:semeval}
SemEval- 2017 \cite{semeval} je zbirka besedilnih podatkov, ki je anotirana za različne naloge na področju obdelave naravnega jezika.
 
Ključne značilnosti korpusa SemEval:
\begin{enumerate}
 \item Anotacije: Podatki so anotirani, kar pomeni, da so označeni z dodatnimi informacijami. Na primer, v korpus zbirki za naloge razreševanja sentimenta bi bili vzorci besedil označeni s pozitivnimi, negativnimi ali nevtralnimi sentimenti.
 \item Raznolikost: Zajemajo širok spekter nalog, jezikov in domen. To omogoča raziskovalcem primerjavo modelov in pristopov na različnih področjih.
 \end{enumerate}
 
 Raziskovalna skupnost: So postale pomemben del naravnega jezika raziskovalne skupnosti, saj omogočajo primerjavo najnovejših pristopov in tehnologij na enotnem naboru podatkov. 

 
 \begin{table}[h!]
\caption{Primer Semeval-2017 korpusa}
    \begin{center}
        \begin{tabular}{l|ccc}
            label & {\tt text}  \\ \hline
                        {\tt -1} & I missed the Barcelona game yesterday. http://t.co/AqpknXC  \\
                        {\tt 0}   & I'm bout to just listen to nicki minaj all night \\
                        {\tt 1}   & One Night like In Vegas I make dat Nigga Famous
        \end{tabular}
    \end{center}
\label{tbl:1}
\end{table}


Korpus razdeljen na tri sklope: 
\begin{enumerate}
 \item učni (train) z 49.547 vrsticami  primerov
 \item validacijski (dev) z 12.285 vrsticami primerov
 \item preizkusni (test) z 12.285 vrsticami primerov
 \end{enumerate}
 
 %----------------------------------------------------------------
% Poglavje (Uporabljeni korpusi) 6
%----------------------------------------------------------------
\chapter{Metrike}
\label{ch6}

\section{Spremenljivke za izračun metrik}
\textbf{Pravilno pozitivni (True Positive)}

Pravilno pozitivni \cite{truevsfalse} je izraz, ki se uporablja v statistiki in strojnem učenju za opis primerov, kjer je model pravilno napovedal pozitiven rezultat za določeno skupino. To pomeni, da je model prepoznal pozitiven pojav, ko je bil dejansko prisoten. 

\emph{Primer:}

Predpostavimo, da razvijamo model za prepoznavanje spam sporočil v elektronski pošti. Model pravilno prepozna 25 sporočil kot nezaželena (spam), ki dejansko vsebujejo nezaželeno vsebino. To pomeni, da imamo 25 primerov "pravilno pozitivnih". Te primere model pravilno prepozna kot nezaželjene, ker resnično vsebujejo neželeno vsebino.





\textbf{Napačno pozitivni (False Positive)}

Napačno pozitivni \cite{truevsfalse} označujejo situacijo, ko model napačno napove, da je nekaj pozitivno, medtem ko je v resnici negativno. Gre za vrsto napake, kjer model napačno identificira primer kot pripadajoč pozitivnemu razredu, čeprav dejansko pripada negativnemu razredu.


\emph{Primer:}

Predpostavimo, da imamo model za prepoznavanje nezaželjenih sporočil v elektronski pošti. Če model označi sporočilo kot nezaželjeno, čeprav dejansko ni imamo situacijo lažno pozitivnega primera. Drugače povedano, model je napačno napovedal pozitiven primer (nezaželjeno), ko je dejansko negativen primer torej ni nezaželjeno. 





\textbf{Napačno negativni (False Negatives)}

Napačno negativni \cite{truevsfalse} označujejo napako, ki se pojavi v kontekstu klasifikacije ali analize besedila, ko model napačno napove, da je nekaj negativno, čeprav je v resnici pozitivno. To je vrsta napake, kjer model spregleda ali ne prepozna pozitivnih primerov. 
V primeru analize besedila v naravni jezikovni obdelavi, false negative se zgodi, ko model ne uspe zaznati pozitivnega elementa v besedilu, ki bi ga moral prepoznati. Na primer, če imamo model za prepoznavanje pozitivnih izjav v komentarjih in model spregleda pozitivno izjavo, to bi bil primer false negative. 

\emph{Primer:}


Predpostavimo, da imamo napreden sistem za filtriranje nezaželjenih sporočil, ki ga uporabljamo za preverjanje prihajajočih e-poštnih sporočil. Sistem je zasnovan tako, da prepoznava in premika neželena sporočila v mapo za neželeno pošto.

Vendar pa se pojavi napačno negativen rezultat, ko sistem napačno presodi e-poštno sporočilo kot varno (ne nezaželjeno), čeprav vsebuje vse znake neželene vsebine. Na primer, če e-poštno sporočilo vsebuje povezave do nerealnih ponudb ali oglasev za sumljive izdelke, bi bila takšna sporočila številčno gledano ena od "Napačno negativni".

V tem primeru je sistem spregledal prepoznavo neželene vsebine, kar je povzročilo, da je sporočilo pristalo v glavnem predalu prejete pošte namesto v mapi za neželeno pošto. To lahko predstavlja težavo, saj se takšni neželeni vsebini lahko izognemo le, če sistem zanesljivo prepozna vse takšne primere. 


\section{Natančnost (Precision)}

Natančnost \cite{percision} je pomembna metrika za ocenjevanje uspešnosti modelov v različnih nalogah. Povdarja natančnost pozitivnih napovedi, torej tistih primerov, ki jih model prepozna kot pozitivne. Visoka preciznost pomeni, da so pozitivne napovedi modela zanesljive in imajo malo lažno pozitivnih napak.

V kontekstu naravne jezikovne obdelave, natančnost igra ključno vlogo pri razumevanju besedila. Na primer, pri analizi sentimenta želimo natančno ugotoviti, ali je izraz pozitiven ali negativen. Visoka preciznost v tem primeru pomeni, da so napovedi modela o sentimentu točne in se malo zmotijo.

 
 Formula za izračun:
\begin{center}
  \Large{Natančnost = \(\frac{Pravilno Pozitivni}{Pravilno Pozitivni + Napacno Pozitivni}\)}
\end{center}


\section{Priklic (Recall)}
Priklic se \cite{recall} nanaša na eno od metrik uspešnosti pri vrednotenju modelov za obdelavo naravnega jezika. Meri kot razmerje med številom pravilno prepoznanih relevantnih primerov in celotnim številom dejansko obstoječih relevantnih primerov. Višji priklic pomeni, da je model bolje usposobljen za iskanje in pridobivanje vseh relevantnih informacij, vendar to lahko vodi tudi v več lažno pozitivnih rezultatov. Zato je pomembno doseči uravnoteženost med priklicom in natančnostjo pri oceni uspešnosti modelov. Primer uporabe priklic je v iskalnih sistemih, kjer želimo zagotoviti, da se relevantni dokumenti ali informacije ne izpustijo pri iskanju. S pravilno optimizacijo modelov lahko dosežemo visoki kakovostno izluščevanje informacij iz besedil, kar je ključno za številne aplikacije, kot so avtomatizirano odzivanje na povratne informacije strank, analiza sentimenta in razumevanje besedil v različnih jezikih. 

 Formula za izračun:
\begin{center}
 \Large{Priklic = \(\frac{Pravilno Pozitivni}{Pravilno Pozitivni + Napacno Negativni}\)}
\end{center}

\section{Ocena F1 (F1-score)}

F1 ocena je pomembna metrika za ocenjevanje uspešnosti modelov v obdelavi besedil. Združuje natančnost in priklic v eno metriko, ki odraža ravnotežje med tema dvema metrikama. Pri  nalogah, kot so uvrščanje besedil, luščenje informacij ali identifikacija entitet, sta tako natančnost  kot priklic ključni. Visoka natančnost pomeni pravilno identifikacijo relevantnih elementov, medtem ko visoki priklic zagotavlja prepoznavanje vseh resnično pozitivnih primerov. Izračuna se kot povprečje med natančnost in priklicom, dajeta pa ji enako težo. To omogoča, da ocenimo, kako dobro model obvladuje oba cilja hkrati. Visoka vrednost F1 ocene kaže, da je model uspešno uskladil identifikacijo pravih pozitivnih primerov z izogibanjem napačno pozitivnim rezultatom. Uporaba metrike je zlasti smiselna, ko sta metriki natančnost in priklic pomembni za končni rezultat in ko želimo doseči optimalno uravnoteženost med tema dvema vidikoma.


 Formula za izračun:
\begin{center}
 \Large{ Ocena F1= 2 x \(\frac{Natancnost \times Priklic }{Natancnost + Priklic}\)}
\end{center}

\section{Točnost}
Točnost \cite{accuracy} je metrika, ki se pogosto uporablja za ocenjevanje uspešnosti modelov v strojnem učenju, vključno z modeli uporabljenimi v obdelavi naravnega jezika. Ta metrika meri, kako pravilno model napove razrede ali kategorije za vhodne podatke v primerjavi z dejanskimi vrednostmi.

V kontekstu obdelave naravnega jezika se natančnost uporablja, na primer, pri nalogah klasifikacije besedil. Predpostavimo, da imamo model, ki se uči razvrščati besedila v določene kategorije, kot so "pozitivno", "negativno" ali "neutralno." Za vsako besedilo ima model svojo napoved, kateri kategoriji pripada.

 Formula za izračun:
\begin{center}
  \large{Točnost = \(\frac{Pravilno Pozitivni + Pravilno Negativni}{Pravilno Pozitivni + Pravilno Negativni + Napacno Pozitivni + Napacno Negativni}\)}
\end{center}

\section{ROUGE}
Je metrika, ki se uporablja za ocenjevanje kakovosti generiranih besedil v primerjavi z referenčnimi besedili. Gre za kratico, ki označuje "Recall-Oriented Understudy for Gisting Evaluation". Metrika je pogosto uporabljena v področju obdelave naravnega jezika, še posebej v nalogah avtomatskega povzemanja besedil.

Primerja generirano besedilo z referenčnim besedilom (običajno človeško ustvarjenim besedilom) in oceni, kako dobro so se ujemale. Metrika upošteva različne vidike, kot so prekrivanje besed, besedni nizi in skupna dolžina besedil. Glavni cilj metrike je merjenje stopnje, do katere je generirano besedilo sposobno pravilno povzeti pomembne informacije iz referenčnega besedila.

Obstajajo različne različice metrike ROUGE, kot so ROUGE-1, ROUGE-2, ROUGE-L itd. Vsaka različica meri različne vidike podobnosti med generiranim besedilom in referenčnim besedilom. Na primer, ROUGE-1 meri prekrivanje eno-besednih nizov med generiranim in referenčnim besedilom, medtem ko ROUGE-2 meri prekrivanje dvo-besednih nizov.

Metrika ima širok nabor uporabe v raziskavah in nalogah, ki vključujejo avtomatsko povzemanje besedil, strojno prevajanje in druge naloge, kjer je pomembno oceniti kakovost generiranih besedil v primerjavi z referenčnimi besedili. Metrika lahko pomaga raziskovalcem in razvijalcem oceniti učinkovitost svojih modelov in tehnik ter izboljšati rezultate pri generiranju besedil.


  %----------------------------------------------------------------
% Poglavje (Analiza raziskave) 6
%----------------------------------------------------------------
\chapter{Primerjava orodij}
\label{ch7}
Pri analizi raziskave so bili izbrani trije največji ponudniki storitev v oblaku: Google Cloud, Amazon Web Services ter Microsoft Azure. Pri izbiri odprtokodne rešitve je bilo težko izbrati najboljšega, saj so v tem času tri najboljše odprtokodne rešitve zelo tesno skupaj kakor tudi povezane. Na podlagi pregledanih funkcionalnosti ter uporabe je bil izbran Hugging Face - Transformers. Pomembno je omeniti, da so vse oblačne storitve po rezultatih tesno skupaj v nekaterih primerih, kot je razvidno iz tabele analize je za  klasifikacijo besedila  odprtokodna rešitev Transformers je imela najboljši rezultat. 

\textbf{Analiza napak}


Pri raziskovanju modelov in korpusov, hitro spoznamo da so lahko modeli celo preveč prilagojeni (overfit) določenemu področju, kar pomeni da preveč podrobno pozna eno področje, na katerem je bil model treniran in ne more dobro generalizirati novih podatkov/primerov, kakor tudi da so premalo podrobni ali premalo raznoliki. 

Zato so najbolj poznani in razširjeni modeli, učeni na širokem naboru različnih podatkov, da je možnost napake manjša. 

 
Prepoznane pogoste napake modelov:

\emph{Nezadostni podatki:} Za gradnjo natančnega modela je potrebna velika količina podatkov. Če ni dovolj podatkov, bo model morda težko naučil vzorce v podatkih. 

\emph{Nezadostna raznolikost podatkov: }Pomembno je, da imajo podatki za usposabljanje dobro razpršenost. Če so podatki preveč homogeni, bo model morda težko naučil vzorce, ki veljajo za splošne primere. 

\emph{Nekvalitetni podatki:} Pomembno je, da so podatki za usposabljanje kakovostni. Če so podatki napačni ali pristranski, bo model morda težko naučil natančen model. 

\emph{Napačen algoritem:} Obstaja veliko različnih algoritmov za stojno učenje, zato je pomembno, da se izbere algoritem, ki je primeren za specifično nalogo. Če je izbran algoritem  napačen, bo morda težko zgraditi natančen model. 

\emph{Napačna nastavitev parametrov:} Večina algoritmov stojnega učenja ima parametre, ki jih je mogoče prilagoditi za izboljšanje natančnosti modela. Če niso pravilno nastavljeni parametri, bo morda težko zgraditi natančen model. 

\begin{table}[h!]
\centering
\caption{Tabela analize}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}

\multicolumn{1}{r}{} &                                                & \textbf{Transformers}             & \textbf{Google Vertex AI}                & \textbf{AWS SageMaker}               & \textbf{Azure Cognitive Services}                             \\ \hline 
\hline                                                                                                                                                                                                                                                                                                                                          
\textbf{Prepoznavanje imenskih entitet}                         &  Priklic  & 0.919               & 0.919                           & 0.961               & 0.824 \\
										   & Natančnost  & 0.923                & 0.920                  &0.954              & 0.858                                         \\
                                                                                       & F1 ocena    & 0.921                & 0.919                  & \textbf{0.958}               & 0.841    \\
\hline
\textbf{Analiza sentimenta}                         		 &  Priklic  & 0.926              & 0.936                  & 0.891               & 0.981       \\
										   & Natančnost  & 0.928               & 0.924                  & 0.862               & 0.862    \\
                                                                                       & F1 ocena    &  0.929              & \textbf{0.930}                   & 0.876               & 0.876      \\            
\hline                                                                                                     
\textbf{Povzemanje}                                      &  ROUGE-L  & 0.192                & 0.306                  & 0.201               & \textbf{0.330}    \\
  \hline                                                                                     
\textbf{Prepoznavanje besednih zvez}  	                           &  Priklic  & 0.573                & 0.543                  & 0.622              & 0.530 \\
										   & Natančnost  & 0.475                & 0.637                  & 0.513              & 0.670 \\
                                                                                       & F1 ocena    & 0.519                & 0.586                  & 0.562               &\textbf{0.592}   \\   
\hline                                                                                       
\textbf{Uvrščanje besedil}                                         &  Priklic  & 0.926                &  0.962                   &  0.763                &  0.920  \\  
										   & Natančnost  & 0.930                &  0.957                   &  0.858                &  0.880  \\
                                                                                       & F1 ocena    & \textbf{0.928}                &  0.907                   &  0.808                &  0.900     \\
\hline                                                                                       
\textbf{Zaznava objektov}  					    & Točnost  & 0.940                & 0.977                  & \textbf{0.980}               & 0.965  \\
   \hline
   \hline                                                          
\end{tabular}}
\end{table}

Pri testitranju  imenovanje imenskih entitet je najvišjo uspešnost dosegla storitev AWS Sage Maker. Na drugem mestu je bila odprtokodna storitev Hugging Face Transformers, medtem ko je tretje mesto zasedla storitev Vertex AI ponudnika Google Cloud.

Pri testiranju sentimentalne analize je najboljše rezultate dosegla storitev AWS SageMaker. Na drugo mesto se je uvrstila odprtokodna rešitev Hugging Face Transformers, medtem ko je tretje mesto zasedla storitev Vertex AI podjetja Google Cloud.

Najboljši rezultati so bili doseženi pri povzemanju z uporabo storitve Azure Cognitive Services. Na drugem mestu se je uvrstil Vertex AI, medtem ko je tretje mesto pripadlo AWS SageMaker.

Pri ocenjevanju izvlečka besednih zvez je prvo mesto osvojila storitev Azure Cognitive Services. Na drugem mestu je Vertex AI, medtem ko je tretjem mestu  AWS SageMaker.

Pri klasifikaciji besedila se je najboljša učinkovitost pokazala pri odprtokodni platformi Transformers. Na drugem mestu je bila storitev Vertex AI, medtem ko je tretje mesto pripadlo storitvi Azure Cognitive Services.

V zaznavanju objektov je prvo mesto zasedla storitev AWS Cognitive Services, takoj za njo je sledil Vertex AI, medtem ko je tretje mesto pripadlo odprtokodni rešitvi Transformers.



V nadaljevanju so predstavljeni podrobnejši rezultati treh iteracij  z povprečnimi vrednostmi pripadajočih metrik ter  standardni odklon kateri je merilo razpršenosti podatkov. Pomaga nam razumeti, koliko se podatki razlikujejo od povprečne vrednosti. Rezultati v vseh tabelah so zaokroženi na tri decimalna mesta. 

\newpage

\section{Prepoznavanje imenskih entitet}

Rezultati iz čankov so bili povzeti iz \cite{ner_clanek}.

\begin{table}[h!]
\centering
\caption{Prepoznavanje imenskih entitet}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}

\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje}                            \\ \hline                                                                                                                                                                                                                                                                                                                                           
 \hline
\textbf{Transformers}   & Priklic  & 0.929              & 0.912                  & 0.917              & 0.919 (± 0.009)                                     \\
				    &  Natančnost  & 0.924              & 0.945                  & 0.901               & 0.923 (± 0.022)  \\
                                     & F1 ocena    & 0.927                 & 0.928                  & 0.909             & 0.921 (± 0.011)   \\
  \hline
\textbf{Google Vertex AI}         & Priklic  & 0.946             & 0.914              & 0.896              & 0.919 (± 0.025 )                                         \\
                                   &  Natančnost & 0.895              & 0.923              & 0.942              & 0.920 (± 0.024  )                                   \\
                                   & F1 ocena   & 0.920              & 0.918              & 0.918              & 0.919 (± 0.001 )                                          \\
  \hline  
\textbf{AWS SageMaker}   & Priklic & 0.981              & 0.962              & 0.941              & 0.961 (± 0.020)                                          \\
                                   &  Natančnost & 0.962              & 0.980              & 0.921              & 0.954 (± 0.030  )                                 \\
                                   & F1 ocena   & 0.971              & 0.971              & 0.931              & \textbf{0.958} (±0.023 )      \\
  \hline
\textbf{Azure Cognitive Services}   & Priklic  & 0.821              & 0.831             & 0.821            & 0.824  (± 0.006)                                             \\
                       &  Natančnost & 0.831              & 0.841              & 0.903              & 0.858  (±0.039 )                                        \\
                        & F1 ocena   & 0.826              & 0.836              & 0.860              & 0.841 (± 0.017 )                                   \\  
  \hline
  \textbf{Najboljši rezultat z članka}   & Priklic    &               &             &               & 0.918                                           \\
                       &  Natančnost &               &               &             & 0.913                                          \\
                        & F1 ocena   &              &             &               & 0.916 (± 0.33)                                           \\  
     \hline
       \hline                                                   
\end{tabular}}
\end{table}

 
 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{NER.png}
\end{center}
\caption{Prepoznavanje imenskih entitet Ocena F1}
\label{pic2}
\end{figure}

Pri analizi imenskih entitet je bil uporabljen \hyperref[sec:my_subsection]{\underline {CONLL-2003}} korpus.

Za prepoznavanje oseb (PER) in organizacij (ORG) se je najbolje izkazala storitev Vertex AI. Na splošno pa je bil v vseh področjih najboljši AWS SageMaker.

\textbf{Analiza napak} 

Najpogosteje opažene napake pri prepoznavi imenskih entitet:  
\begin{enumerate}
 \item Napake imen: to so napake v imenu imenske entitete, na primer napačna črka ali napačen zlog, zapletene besede ali tuje besede. To lahko oteži identifikacijo imena in njegovo kategorizacijo. 
 \item Napake v tipu: napaka v tipu imenske entitete, na primer napačno označitev osebe kot kraja ali obratno. Ime je zapleteno ali dvoumno zato, ker imajo zapletena imena lahko več kot eno pomensko področje. 
 \item Izpuščanje/nekategorizacija: napaka, pri katerih se imenska entiteta izpusti iz besedila. 
 \item Ponavljanje: napaka, pri katerih se imenska entiteta ponovi v besedilu. 
 \end{enumerate}

\section{Analiza sentimenta}

\begin{table}[h!]
\centering
\caption{Analiza sentimenta}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}

\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje}                              \\ \hline     \hline                                                                                                                                                                                                                                                                                                                                      
\textbf{Transformers}   & Priklic  & 0.937              & 0.912                 & 0.930              & 0.926 (±0.013)                                     \\
				    &  Natančnost  & 0.938              & 0.987                  & 0.860               & 0.928 (±0.064)                                     \\
                                     & F1 ocena    & 0.937                 & 0.952                  & 0.893             & 0.929 (±0.031)                    \\
\hline
\textbf{Google Vertex AI}         & Priklic  & 0.921              & 0.948              & 0.938              & 0.936 (±0.014)                                           \\
                                   &  Natančnost & 0.942             & 0.888              & 0.943              & 0.924 (±0.031)                                         \\
                                   & F1 ocena   & 0.931            & 0.917            & 0.940              & \textbf{0.930}  (±0.012)                                        \\
\hline
\textbf{AWS SageMaker}   & Priklic  & 0.901              & 0.882              & 0.891              & 0.891 (±0.010)                                           \\
                                   &  Natančnost & 0.821              & 0.853              & 0.912              & 0.862 (±0.046 )                                           \\
                                   & F1 ocena   & 0.859              & 0.867              & 0.901              & 0.876 (±0.022)                                                  \\
  \hline                                 
\textbf{Azure Cognitive Services}   & Priklic  & 0.881              & 0.905              & 0.887              & 0.981 (±0.012)                                            \\
                       &  Natančnost & 0.852              & 0.884              & 0.851              & 0.862 (±0.019)                                          \\
                        & F1 ocena   & 0.866              & 0.894              & 0.869              & 0.876  (±0.015)                                          \\  
  \hline                            
  \textbf{Najboljši rezultat z članka}   & Priklic    &               &             &               & 0.918                                           \\
                       &  Natančnost &               &               &             & 0.913                                          \\
                        & F1 ocena   &              &             &               & 0.916 (± 0.33)                                           \\  
                         
\hline
\hline                            
\end{tabular}}
\end{table}

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{KP.png}
\end{center}
\caption{Analiza sentimenta Ocena F1}
\label{pic2}
\end{figure}

\newpage
Pri analizi imenskih entitet je bil uporabljen  \hyperref[sec:imdb]{\underline {IMDb Reviews}} korpus.
Za analizo sentimenta  je bila najboljša Vertex AI storitev.




\textbf{Analiza napak} 
\begin{enumerate}
 \item Nepravilna identifikacija sentimenta: je ena izmed najpogosteje opaženih napak, ki se je pojavila pri analizi sentimenta, kar je lahko ko je beseda ali besedna zveza dvoumna in lahko pomeni tako pozitiven kot negativen sentiment. Lahko je tudi napaka v zapisu same besede ali besedne zveze, kot tudi da je model premalo naučen za določeno področje. 
 \item Nepravilna kategorizacija sentimenta: se pojavi, ko analiza sentimenta pravilno identificira sentiment, vendar ga napačno kategorizira. To lahko povzroči, da analiza sentimenta ne bo uporabna za namen, za katerega je bila namenjena. 
 \item Napaka v kontekstu: se zgodi ko analiza sentimenta pravilno identificira sentiment in ga pravilno kategorizira, vendar ga napačno razvrsti v kontekstu. To lahko povzroči, da analiza sentimenta ne bo uporabna za namen, za katerega je bila namenjena. 
 \item Napaka v viru: zaznamo jo, ko analiza sentimenta pravilno identificira sentiment, ga pravilno kategorizira in ga pravilno razvrsti v kontekstu, vendar ga napačno dobi iz vira. To lahko povzroči, da analiza sentimenta ne bo uporabna za namen, za katerega je bila namenjena. 
 \end{enumerate}


\section{Povzemanje}
\begin{table}[h!]
\centering
\caption{Povzetek}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}
\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje}   & \textbf{St. odklon}                           \\ \hline   \hline                                                                                                                                                                                                                                                                                                                                        
\textbf{Transformers}   & ROUGE-L   & 0.178              & 0.187                 & 0.212              & 0.192                        & 0.018               \\
\hline
\textbf{Vertex AI}         & ROUGE-L   & 0.312              & 0.291              & 0.315              & 0.306                             & 0.013                \\
\hline
\textbf{AWS SageMaker}.   & ROUGE-L   & 0.203             & 0.184              & 0.216             & 0.201                   & 0.016                        \\
\hline
\textbf{Azure Cognitive Services}   & ROUGE-L   & 0.387              & 0.318             & 0.284             & \textbf{0.330}             & 0.052       \\
\hline
\hline                                                                                              
\end{tabular}}
\end{table}

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{SUMM.png}
\end{center}
\caption{Povzemanje Ocena F1}
\label{pic2}
\end{figure}

Pri izdelavi povzetka je bil uporabljen korpus  \hyperref[sec:cnn]{\underline {CNN/Daily Mail}}.

Kot najboljša izbira za ustvarjanje povzetkov je storitev Vertex AI.


\vspace{\baselineskip}

\textbf{Analiza napak} 

Najpogosteje opažene napake pri povzemanju besedila:  
\begin{enumerate}
 \item Izpuščanje pomembnih informacij: kar pomeni, da je povzetek netočen ali nepopoln. To se lahko zgodi iz več razlogov, na primer zaradi tega, da model ne prepozna pomembnih informacij ali pa ne more pravilno razumeti pomena besedila. 
  \item Dodajanje napačnih informacij: povzroča, da je povzetek netočen ali zavajajoč. To se lahko zgodi iz več razlogov, na primer zaradi tega, da model napačno intrepterira besedilo ali pa uporablja napačne podatke pri treniranju modela. 
 \item Slab slog in gramatika: ustvarjeni povzetki, ki so slabo napisani ali vsebujejo napake v slogu in gramatiki, kar je lahko posledica napačnega algoritma. 
  \end{enumerate}

%----------------------------------------------------------------
%Izvleček besedne zveze 

%----------------------------------------------------------------

\section{Prepoznavanje besednih zvez}


\begin{table}[h!]
\centering
\caption{Prepoznavanje besednih zvez}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}

\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje}        & \textbf{St. odklon}                       \\ \hline \hline                                                                                                                                                                                                                                                                                                                                            
\textbf{Transformers}   & Priklic  & 0.523              & 0.640                  & 0.556              & 0.573                             & 0.060             \\
				    &  Natančnost  & 0.398               & 0.499                 & 0.528               & 0.475  	          	 & 0.068  \\
                                     & F1 ocena    & 0.452                  & 0.561                  & 0.542              & 0.519  			 & 0.058  \\
                                     \hline  
\textbf{Google Vertex AI}         & Priklic  & 0.499              & 0.541              & 0.589              & 0.543                                       & 0.045      \\
                                   &  Natančnost & 0.688             & 0.635              & 0.589              & 0.637                                      & 0.050       \\
                                   & F1 ocena   & 0.578             & 0.584              & 0.589              & 0.586                                        & 0.005   \\
                                   \hline  
\textbf{AWS SageMaker}.   & Priklic  & 0.675              & 0.605              & 0.587              & 0.622                         & 0.046                   \\
                                   &  Natančnost & 0.520              & 0.492             & 0.526             & 0.513                                       & 0.018     \\
                                   & F1 ocena   & 0.587             & 0.543             & 0.555              & 0.562   					 & 0.023 \\
                                   \hline  
\textbf{Azure Cognitive Services}   & Priklic  & 0.532              & 0.559             & 0.500              & 0.530                    & 0.030                        \\
                       &  Natančnost & 0.674              & 0.648             & 0.689              & 0.670                                         	 & 0.021 \\
                        & F1 ocena   & 0.595              & 0.600              & 0.579              & \textbf{0.592}                                                  & 0.011    \\
                        \hline  
                        \hline                  
\end{tabular}}
\end{table}

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{KEY.png}
\end{center}
\caption{Prepoznavanje besednih zvez Ocena F1}
\label{pic2}
\end{figure}

\newpage
Pri izvajanju naloge zvlečka besedne zveze je bil uporabljen korpus  \hyperref[sec:semeval]{\underline {SemEval-2017}}.

Kot najboljša rešitev za izvleček besedne zveze pa se je izkazala storitev Azure Cognitive Services.


\textbf{Analiza napak} 

Najpogosteje opažene napake pri izvlečeku besedne zveze:  
\begin{enumerate}
 \item Napačne oznake: napake v oznaki besednih zvez, na primer napačno označitev besedne zveze kot pomembne, čeprav ni pomembna ali obratno. 
  \item Izpuščanje: napake, pri katerih se besedna zveza izpusti iz izvlečka, na primer zaradi napake pri prepoznavanju besednih zvez ali zaradi napake pri razdelitvi besedila na stavke. 
  \item   Ponavljanje: To so napake, pri katerih se besedna zveza ponovi v izvlečku, na primer zaradi napake pri razdelitvi besedila na stavke ali zaradi napake pri ohranitvi besedne zveze. 
 \end{enumerate}


  \newpage
%----------------------------------------------------------------
% Klasifikacija besedila 
%----------------------------------------------------------------

\section{Uvrščanje besedil}
\begin{table}[h!]
\centering
\caption{Uvrščanje besedil}
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}
\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje}          & \textbf{St. odklon}                   \\ \hline      \hline                                                                                                                                                                                                                                                                                                                                       
\textbf{Transformers}   & Priklic  & 0.933             & 0.948                  &  0.896             &  0.926                            & 0.027              \\
				    &  Natančnost  &  0.898               & 0.935                 & 0.958               &  0.930   		     & 0.030  \\
                                     & F1 ocena    &  0.915                  &  0.941                  &  0.926              &  \textbf{0.928} 		& 0.013     \\
                                     \hline  
\textbf{Google Vertex AI}         & Priklic  &  0.842              &  0.901              &  0.844             &  0.962                          & 0.034                   \\
                                   &  Natančnost &  0.989              &  0.924              &  0.959              &  0.957                        & 0.033                     \\
                                   & F1 ocena   &  0.910              &  0.912              &  0.989              &  0.907                           & 0.008                 \\
                                   \hline  
\textbf{AWS SageMaker}.   & Priklic  &  0.789              &  0.802             &  0.697              &  0.763              & 0.057                              \\
                                   &  Natančnost &  0.879              &  0.799              &  0.895              &  0.858                          & 0.051                   \\
                                   & F1 ocena   &  0.832              &  0.800              &  0.784              &  0.808   			& 0.024    \\
                                   \hline  
\textbf{Azure Cognitive Services}   & Priklic  &  0.935              &  0.925             &  0.900              &  0.920      & 0.018                                      \\
                       &  Natančnost &  0.827              &  0.888              &  0.925             &  0.880                                      & 0.049       \\
                        & F1 ocena   &  0.878              &  0.906              &  0.912              &  0.900                                        & 0.018   \\
                        \hline  
                        \hline                                  
\end{tabular}}
\end{table}

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{CLASSIFICATION.png}
\end{center}
\caption{Uvrščanje besedil  Ocena F1}
\label{pic2}
\end{figure}


Pri izvajanju naloge klasifikacije besedila je bil uporabljen korpus  \hyperref[sec:imdb]{\underline {IMDb Reviews}}.

Kot najboljša rešitev za naloge klasifikacije besedila pa se je izkazala storitev Transformers.

\vspace{\baselineskip}
  \newpage
\textbf{Analiza napak} 

Najpogosteje opažene napake pri klasifikaciji besedila:  

\begin{enumerate}
  \item Napačno uvrščanje razredov: zaradi pomanjkanja jasnih ločnic med razredi ali zaradi podobnosti med besedili različnih razredov. 
    \item Nezaznavanje: kadar se izpustijo pomembne informacije iz besedila, kar la povzroči, da je uvrščanje netočno ali nepopolno. 

Paragraph locked by Gregor Kocmut
 \end{enumerate}
%----------------------------------------------------------------
% Zaznava objektov 
%---------------------------------------------------------------

\section{Zaznava objektov}
\begin{table}[h!]
\centering
\caption{Zaznava objektov }
\label{my-label}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrrr}
\multicolumn{1}{r}{} &   & \textbf{Množica 1}             & \textbf{Množica 2}                & \textbf{Množica 3}               & \textbf{Povprečje }            & \textbf{St. odklon}                  \\ \hline    \hline                                                                                                                                                                                                                                                                                                                                       
\textbf{Transformers}   & Točnost  & 0.900             & 0.970                  & 0.940              & 0.940                            & 0.018             \\
\hline
\textbf{Google Vertex AI}         & Točnost  & 0.963              & 0.991              & 0.977             & 0.977                                 & 0.014             \\
\hline
\textbf{AWS SageMaker}.   & Točnost  & 0.995              & 0.963              & 0.982              & \textbf{0.980}                   & 0.016                         \\
\hline
\textbf{Azure Cognitive Services}   & Točnost  & 0.960             & 0.950              & 0.985             & 0.965              & 0.017 \\
\hline\hline                                                                   
\end{tabular}}
\end{table}


 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{OBJECT.png}
\end{center}
\caption{ Zaznava objektov Ocena F1}
\label{pic2}
\end{figure}


Pri zaznavi objektov je bil uporabljen  \hyperref[sec:coco]{\underline {COCO}} korpus.

Kot najboljša izbira za zaznavanje objektov pa se je izkazala storitev AWS SageMaker.



\textbf{Analiza napak} 


Do napak pri zazvanju objektov prihaja zaradi različnih razlogov, na primer zaradi napak v algoritmu za zaznavanje objektov, zaradi slabe kakovosti slik ali zaradi prisotnosti motenj v okolju. 

Najpogosteje opažene napake pri zaznavi objektov:
\begin{enumerate}
 \item  Nenamerna zaznava: zaznava objektov, ki v dejanskem okolju niso prisotni.
  \item Nezaznavanje: izpuščanje objektov, ki so dejansko pristotni v okolju.
   \item Napačna zaznava: AI modeli lahko nepravilno zaznajo objekte.
 \end{enumerate}

%----------------------------------------------------------------
% Poglavje (Chapter) 6
%----------------------------------------------------------------
\chapter{Zaključek}
\label{ch8}

Magistrska naloga je obravnavala širok spekter področij obdelave naravnega jezika z uporabo oblačnih ter odprtokodne rešitev Hugging Face Transformers. Cilj raziskave je bil razumeti, kako se različni ponudniki odzivajo na različne izzive in naloge ter določiti njihovo uspešnost na posameznih področjih. Analiza je zajemala prepoznavanje imenskih entitet, analizo sentimenta, povzemanje besedil, luščenje ključnih besed, klasifikacijo besedila ter zaznavo objektov.


Na podlagi raziskave smo ugotovili, da se je vsak ponudnik specializiral in izkazal za najboljšega na določenem področju. Pri prepoznavanju imenskih entitet je izstopal AWS SageMaker s svojo natančnostjo. Google Cloud Vertex AI je blestel pri analizi sentimenta, kar je ključno za razumevanje čustev in mnenj v besedilu. Pri povzemanju besedila se je Azure Cognitive Services izkazal kot najboljši, kar poudarja njegovo sposobnost za ustvarjanje povzetkov besedilnih vsebin. Pri luščenju ključnih besed je bila rešitev Azure Cognitive Services v ospredju, saj je omogočala najboljši izvleček bistvenih informacij iz besedil. Hugging Face je prevzel vodilno vlogo pri analizi sentimenta z natančnostjo določanja čustvenega tona besedil.  AWS SageMaker pa se je izkazal kot močan v zaznavanju objektov.

Vendar pa je pomembno poudariti, da ima vsak ponudnik v oblaku svoje prednosti in omejitve ter da izbira med njimi temelji na specifičnih potrebah in zahtevah uporabnika. Pri izbiri pravega ponudnika je potrebno upoštevati različne faktorje, kot so natančnost, hitrost, stroške, prilagodljivost in integracija z obstoječimi sistemi.

Pomembno je izpostaviti, da so rezultati analize odvisni od specifičnih nalog,modelov in korpusov , ki so bili uporabljeni v tej raziskavi. Prav tako se tehnologije in zmogljivosti ponudnikov v oblaku nenehno razvijajo, zato je pomembno, da podjetja in raziskovalci ostanejo pozorni na nove in izboljšane metode za obdelavo naravnega jezika.

V sklepni fazi je jasno, da noben ponudnik v oblaku ne izstopa kot absolutno najboljši na vseh področjih. Različni ponudniki imajo svoje prednosti in posebne zmogljivosti glede na določene naloge obdelave naravnega jezika. Izbiro ustrezne platforme je torej smiselno prilagoditi specifičnim potrebam in zahtevam. Hkrati pa je obetavno opazovati, kako odprtokodne rešitve, kot je Hugging Face Transformers, pridobivajo na veljavi in omogočajo raziskovalcem in razvijalcem, da izkoristijo najboljše iz več različnih tehnologij.

Zaključno lahko rečemo, da je obdelava naravnega jezika v oblaku zelo dinamično in obetavno področje, ki bo še naprej oblikovalo način, kako interaktiramo s tehnologijo in kako razumemo ter uporabljamo jezikovne vsebine v digitalnem svetu.


% ---------------------------------------------------------------
% Appendix
% ---------------------------------------------------------------
%00\appendix
%\addcontentsline{toc}{chapter}{Razširjeni povzetek}
%\chapter{Title of the appendix 1}

%Example of the appendix.

%----------------------------------------------------------------
% SLO: bibliografija
% ENG: bibliography
%----------------------------------------------------------------
\bibliographystyle{elsarticle-num}

%----------------------------------------------------------------
% SLO: odkomentiraj za uporabo zunanje datoteke .bib (ne pozabi je potem prevesti!)
% ENG: uncomment to use .bib file (don't forget to compile it!)
%----------------------------------------------------------------
%\bibliography{bibliography}

%----------------------------------------------------------------
% SLO: zakomentiraj spodnji del, če uporabljaš zunanjo .bib datoteko
% ENG: comment the part below if using the .bib file
%----------------------------------------------------------------

\begin{thebibliography}{99}
\bibitem{hugging} Hugging Face. Dostopno na: \url{https://huggingface.co/learn/nlp-course/chapter1/4}  [Dostopano 10. 06. 2023].
\bibitem{transformers} Transformers. Dostopno na: \url{https://huggingface.co/learn/nlp-course/chapter2/1?fw=pt}  [Dostopano 10. 06. 2023].
\bibitem{google} Google Cloud. Dostopno na: \url{https://cloud.google.com/natural-language#section-1}  [Dostopano 10. 06. 2023].
\bibitem{vertex} Vertex AI. Dostopno na: \url{https://cloud.google.com/vertex-ai}  [Dostopano 10. 06. 2023].
\bibitem{aws} Amazon Web Services (AWS).  Dostopno na: \url{https://aws.amazon.com/}  [Dostopano 10. 06. 2023].
\bibitem{sage} Amazon SageMaker.  Dostopno na: \url{https://aws.amazon.com/sagemaker/}  [Dostopano 10. 06. 2023].
\bibitem{azure} Azure. Dostopno na: \url{https://azure.microsoft.com/en-us}  [Dostopano 10. 06. 2023].
\bibitem{cognitive} Azure Cognitive Services. Dostopno na: \url{https://azure.microsoft.com/en-gb/products/cognitive-services}  [Dostopano 10. 06. 2023].
\bibitem{ner} Named Entity Recognition. Dostopno na: \url{https://www.shaip.com/blog/named-entity-recognition-and-its-types/}  [Dostopano 10. 06. 2023].
\bibitem{sentiment} Sentiment Analysis. Dostopno na: \url{https://aws.amazon.com/what-is/sentiment-analysis/}  [Dostopano 10. 06. 2023].
\bibitem{povzetek} Summarization. Dostopno na: \url{https://huggingface.co/tasks/summarization}  [Dostopano 10. 06. 2023].
\bibitem{luscenje} Keyphrase Extraction. Dostopno na: \url{https://www.geeksforgeeks.org/keyphrase-extraction-in-nlp/}  [Dostopano 10. 06. 2023].
\bibitem{klasifikacija} Text Classification. Dostopno na: \url{https://huggingface.co/tasks/text-classification}  [Dostopano 10. 06. 2023].
\bibitem{object} Object Detection. Dostopno na: \url{https://huggingface.co/tasks/object-detection}  [Dostopano 10. 06. 2023].
\bibitem{truevsfalse} True vs. False and Positive vs. Negative. Dostopno na: \url{https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative}  [Dostopano10. 06. 2023].
\bibitem{conll}Erik F. Tjong Kim Sang and Fien De Meulder  ``Introduction to the CoNLL-2003''. Dostopno na: \url{https://aclanthology.org/W03-0419.pdf}  [Dostopano
10. 06. 2023].
\bibitem{imdb} IMDB Dataset Reviews. Dostopno na: \url{https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews}  [Dostopano 10. 06. 2023].
\bibitem{coco} COCO 2017 Dataset. Dostopno na: \url{https://www.kaggle.com/datasets/awsaf49/coco-2017-dataset}  [Dostopano 10. 06. 2023].
\bibitem{cnn} CNN dailymail Dataset. Dostopno na: \url{https://huggingface.co/datasets/cnn_dailymail}  [Dostopano 10. 06. 2023].
\bibitem{semeval} SemEval-datasetst. Dostopno na: \url{https://www.kaggle.com/datasets/azzouza2018/semevaldatadets?resource=download}  [Dostopano 10. 06. 2023].
\bibitem{accuracy} Accuracy. Dostopno na: \url{https://developers.google.com/machine-learning/crash-course/classification/accuracy}  [Dostopano
10. 06. 2023].
\bibitem{percision} Precision and Recall. Dostopno na: \url{https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall}  [Dostopano
10. 06. 2023].
\bibitem{ner_clanek} Arya Roy: Recent Trends in Named Entity Recognition (NER).Dostopno na: \url{https://arxiv.org/pdf/2101.11420.pdf}  [Dostopano
10. 06. 2023].
\end{thebibliography}

\end{document}
