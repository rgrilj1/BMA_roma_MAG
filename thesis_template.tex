%================================================================
% SLO
%----------------------------------------------------------------
% datoteka: 	thesis_template.tex
%
% opis: 		predloga za pisanje diplomskega dela v formatu LaTeX na
% 				Univerza v Ljubljani, Fakulteti za računalništvo in informatiko
%
% pripravili: 	Matej Kristan, Zoran Bosnić, Andrej Čopar,
%			  	po začetni predlogi Gašperja Fijavža
%
% popravil: 	Domen Rački, Jaka Cikač, Matej Kristan
%
% verzija: 		30. september 2016 (dodan razširjeni povzetek)
%================================================================


%================================================================
% SLO: definiraj strukturo dokumenta
% ENG: define file structure
%================================================================
\documentclass[a4paper, 12pt]{book}
 

%================================================================
% SLO: Odkomentiraj "\SLOtrue " za izbiro slovenskega jezika
% ENG: Uncomment "\SLOfalse" to chose English languagge
%================================================================
\newif\ifSLO
\newif\ifTRACKEXIST
\newif\ifTRACKCS
\newif\ifPROGRAMMM

% ---------------------------------------------------------------------------------------
% IMPORTANT: Adjust the thesis language, your study program and course within this block
% ---------------------------------------------------------------------------------------
% switch language
%\SLOtrue % Enables Slovenian language
\SLOfalse  % Enables English language

% switch programs: Computer science and Multimedia. Set to false if the program is in Multimedia
\PROGRAMMMfalse
%\PROGRAMMMtrue

% switch on if your program is divided into tracks CS and DS, otherwise leave it false
% CAUTION: if you were first enrolled into your program before school year 2019/2020, your program is not divided into tracks. In any case, be absolutely sure you select the correct variant. IF IN DOUBT, always contact the student office to advise you.
%
 \TRACKEXISTfalse
%\TRACKEXISTtrue

% default course name is "Computer science" if your course name is "Data science", set the following switch to false
\TRACKCStrue % uncomment if the thesis is from course "Information science"
%\TRACKCSfalse % uncomment if the thesis is from course "Data Science"
% -------------------------------------------------------------------------------------------
% End of language, program and course adjustment
% -------------------------------------------------------------------------------------------


%================================================================
% SLO: vključi oblikovanje in pakete
% ENG: include design and packages
%================================================================
\input{style/thesis_style}

%----------------------------------------------------------------
% |||||||||||||||||||||| USTREZNO POPRAVI |||||||||||||||||||||||
% |||||||||||||||||||||| EDIT ACCORDINGLY |||||||||||||||||||||||
%----------------------------------------------------------------
\newcommand{\ttitle}{Primerjava uspešnosti odprtokodnih in komercialnih orodij za luščenje podatkov}
\newcommand{\ttitleEn}{Performance comparison of open source and commercial information extraction tools}
\newcommand{\tsubject}{\ttitle}
\newcommand{\tsubjectEn}{\ttitleEn}
\newcommand{\tauthor}{Romana Grilj}
\newcommand{\temail}{romana.grilj@gmai.com}
\newcommand{\myyear}{2023}
\newcommand{\tkeywords}{analiza podatkov, ekstrakcija podatkov, strukturni podatki, spletno rudarjenje}
\newcommand{\tkeywordsEn}{Data analysis, Information Retrieval, structural data, Web Mining}
\newcommand{\mysupervisor}{doc.~dr.\ Slavko Žitnik}
\newcommand{\mycosupervisor}{akad.~prof.~dr.\ Martin Krpan}
% include formatted front pages
\input{style/thesis_front_pages}

%================================================================
% ENG: main pages of the thesis
%================================================================

%----------------------------------------------------------------
% Poglavje (Chapter) 1
%----------------------------------------------------------------
\chapter{Uvod}
\label{ch:uvod}

Naravnojezikovno procesiranje (NLP) je eno izmed najhitreje razvijajočih se področij v umetni inteligenci, ki se ukvarja z obdelavo, razumevanjem in generiranjem naravnega jezika, kot ga uporabljajo ljudje za komunikacijo. Napredne NLP tehnike in modeli so v zadnjem desetletju privedli do prebojev v številnih aplikacijah, ki segajo od avtomatskega prevajanja in analize čustev do odgovarjanja na vprašanja in samodejnega povzemanja besedil.

Cilj te magistrske naloge je raziskati in analizirati različne pristope k NLP modelom, razpoložljive datasete, uporabljene metrike za evaluacijo modelov ter številna področja uporabe NLP tehnologij.

V nadaljevanju se bomo osredotočili na pomembnost kakovostnih datasetov za uspešno učenje NLP modelov. Pregledali bomo obstoječe in priljubljene datasete, ki se uporabljajo za različne naloge.
Metrike za evaluacijo modelov bomo proučili kot ključen element za oceno učinkovitosti modelov. Preučili bomo različne metrike, kot so natančnost, F1-score, ROUGE in druge. Razložili bomo, kako se uporabljajo za različne naloge in kako lahko ocenimo zmogljivost modelov.

Nato se bomo posvetili raznolikim področjem uporabe NLP tehnologij. Raziskali bomo, kako se tehnologije uporabljajo v avtomatskem prevajanju, analizi čustev, odgovarjanju na vprašanja, generiranju besedil, iskanju informacij, biomedicinski analizi in še več. Preučili bomo tudi izzive in omejitve, s katerimi se srečujejo NLP modeli pri uporabi na teh različnih področjih.

V Poglavju~\nameref{ch4}  bomo podrobneje spoznali izbrane funkcionalnosti, ki jih omogočajo AI/NLP modeli, ki temeljijo na umetni inteligenci in strojnem učenju ter so zasnovane za obdelavo, razumevanje in generiranje naravnega jezika. NLP modeli se uporabljajo za reševanje različnih nalog, povezanih z obdelavo jezika, kot so avtomatsko prevajanje, analiza čustev, razumevanje besedil, odgovarjanje na vprašanja, izluščevanje informacij iz besedil, klasifikacija besedil in še več.

V Poglavju~\nameref{ch5} bomo podrobneje spoznali uporabljene datasete, ki so ključnega pomena za uspešno razvoj, učenje in evalvacijo NLP modelov. Dataseti so zbirke besedilnih podatkov, ki so ročno označeni ali označeni s pomočjo algoritmov za različne naloge NLP.

V poglavju ~\nameref{ch6}  bomo temeljito raziskali različne metrike, ki omogočajo oceno učinkovitosti modelov glede na njihove specifične naloge. Raznolikost nalog v področju obdelave naravnega jezika (NLP) zahteva prilagodljivost pri izbiri primernih meril. V nadaljevanju so navedene ključne metrike, ki se redno uporabljajo pri evalvaciji NLP modelov.

V predzanjem poglavju ~\nameref{ch7}  so predstavljeni rezultati različnih storitev uporabljenih funkcionalnosti.

Sledijo še ~\nameref{ch8}.

Z predstavitvijo ključnih elementov v magistrski nalogi bomo pridobili celovit pregled nad uporabo modelov ter njihovo uporabo na različnih področij. Cilj je prispevati k razumevanju NLP  tehnologij ter predstaviti rezultate različnih storitev.
%----------------------------------------------------------------
% Poglavje (Chapter) 2
%----------------------------------------------------------------

%----------------------------------------------------------------
% Poglavje (Chapter) 3
%----------------------------------------------------------------

%----------------------------------------------------------------
% Poglavje (Chapter) 4
%----------------------------------------------------------------

%----------------------------------------------------------------
% Poglavje (Chapter) 5
%----------------------------------------------------------------
\chapter{Kaj pa literatura?}
\label{ch:literatura}
Kot smo omenili že v uvodu, je pravi način za citiranje literature uporaba \BibTeX{}a~\cite{ubi}.
Programski paket \LaTeX je prvotno predstavljen v priročniku~\cite{Lamport} in je v resnici nadgradnja sistema \TeX\ avtorja Donalda Knutha, znanega po denimo, če izpustim njegovo umetnost programiranja, Knuth-Bendixovem algoritmu~\cite{Knuth}.

Vsem raziskovalcem s področja računalništva pa svetujem v branje mnenje L.\ Fortnowa~\cite{Fortnow}.

%----------------------------------------------------------------
% Poglavje (Opis funkciionalnosti) 5
%----------------------------------------------------------------
\chapter{Izbrana področja uporabe}
\label{ch4}
\section{Prepoznavanje imenskih entitet}
\label{sec:ner}
Prepoznavanje imenskih entitet je tehnika na področju obdelave naravnega jezika, ki se uporablja za prepoznavanje in klasifikacijo besed v besedilu. Te posebne vrste so imenovane entitete, kot so imena oseb, organizacij, lokacij, datumov, številk, denarnih zneskov in drugih specifičnih poimenovanj.

Cilj je prepoznati in določiti začetek in konec posameznih entitet v besedilu ter jim pripisati ustrezno kategorijo. Na primer, v stavek "Janez Novak je rojen 10. avgusta 1985 v Ljubljani" bi sistem prepoznal "Janez Novak" kot ime osebe, "10. avgust 1985" kot datum in "Ljubljana" kot lokacijo.

Številne praktične uporabe:
\begin{enumerate}
 \item  Avtomatsko označevanje imenskih entitet v novicah, člankih in drugih besedilnih vsebinah.
 \item Razumevanje strukture in vsebine dokumentov za informacijsko iskanje in kategorizacijo.
 \item Pomoč pri analizi sentimenta, kjer se želimo razumeti, kako se osebe, organizacije ali druge entitete omenjene v besedilu nanašajo na določeno temo ali izdelek.
\end{enumerate}

\section{Analiza sentimenta}
Analiza sentimenta je proces določanja čustvenega odziva, nagnjenosti ali stališča zapisanega besedila. Cilj analize sentimenta je ugotoviti, ali je določeno besedilo pozitivno, negativno ali nevtralno. To je lahko koristno pri analizi mnenj strank, razumevanju čustvenega odziva na izdelke, blagovne znamke, dogodke in druge.
Na primer, če imamo naslednji stavek: "Ta film je fantastičen, vreden ogleda!", bi analiza sentimenta prepoznala, da je izraz pozitiven.
Ta analiza temelji na uporabi naravnojezikovnega procesiranja in strojnega učenja. Obstaja več pristopov k analizi sentimenta, vključno z naslednjimi:
\begin{enumerate}
 \item Pravilni pristopi: Uporabljajo se predvsem pravila in vzorci za identifikacijo pozitivnih in negativnih izrazov v besedilu. Na primer, besede, kot so "dobro", "fantastično", "radostno" itd., bi bile označene kot pozitivne, medtem ko bi bile besede, kot so "slabo", "žalostno", "neznosno" itd., označene kot negativne.
 \item Strojno učenje na podlagi besedila: Ta pristop vključuje uporabo algoritmov strojnega učenja, ki so naučeni prepoznati čustveni naboj besed v besedilu na podlagi velikega števila označenih podatkov (besedil s čustvenimi oznakami). 
 \item Analiza sentimenta s čustvenimi slovarji: Ta pristop vključuje uporabo slovarjev z besedami in izrazoslovjem, ki so povezani z določenimi čustvi. Besedilo se nato preveri in oceni glede na prisotnost pozitivnih ali negativnih besed iz čustvenih slovarjev.
 \item Algoritmi globokega učenja: V zadnjem času so se pojavili tudi pristopi, ki temeljijo na globokem učenju.
 \end{enumerate}
 
 \section{Povzemanje besedila}
Pri povzermanju besedila gre za postopek ustvarjanja krajšega in jedrnatega povzetka izdaljšega besedila, kot je članek ali dokument. Namen povzemanja je izluščiti ključne informacije in ideje iz izvornega besedila ter jih predstaviti na bolj pregleden in krajši način. To je zelo koristno v velikih količinah podatkov, ko želimo hitro pridobiti bistvo informacij, ne da bi brali celotno besedilo.

NLP tehnike za povzemanje uporabljajo različne algoritme in metode, ki vključujejo strojno učenje in obdelavo naravnega jezika, da bi učinkovito izluščile ključne besede, stavke ali odstavke, ki predstavljajo osrednje ideje v izvornem besedilu. Rezultat je običajno kratek povzetek, ki ohranja pomembne informacije iz izvirnega besedila. Ta tehnologija ima širok spekter uporab, kot so samodejno povzemanje novic, generiranje opisov izdelkov, izdelava povzetkov raziskovalnih člankov in še veliko več.
 
 \section{Izvleček besedne zveze}
Nanaša se na besede ali izraze, ki so najpomembnejši ali najbolj značilni za določeno besedilo ali dokument. Te besede so običajno tiste, ki nosijo ključne informacije ali so bistvene za razumevanje vsebine.

Identifikacija ključnih besed je pomembna naloga, saj nam omogoča, da hitro ugotovimo, o čem govori določen tekst. Te besede so lahko uporabne tudi za avtomatsko indeksiranje dokumentov, iskanje relevantnih informacij in razumevanje teme besedila brez potrebe po branju celotnega besedila.

 \section{Klasifikacija besedila}
 Klasifikacija besedil je tehnika, pri kateri avtomatizirano določimo kategorijo ali razred določenega besedila na podlagi vsebine besedila. To je lahko zelo uporabno, saj nam omogoča razvrščanje besedil v različne skupine glede na njihovo vsebino. Na primer, lahko klasificiramo e-poštna sporočila kot "spam" ali "ne-spam", novice glede na tematiko, uporabniške komentarje glede na ton (pozitiven, negativen, nevtralen), itd.

Postopek klasifikacije besedil se običajno začne s pripravo in čiščenjem besedil. To vključuje odstranjevanje nepotrebnih znakov, šumnikov, posebnih znakov, pretvorbo vseh črk v male črke, lahko pa tudi odstranjevanje pogostih besed, ki nimajo velikega pomena za klasifikacijo (npr. "in", "ali", "je", "na", "s", itd.).

Nato se besedila predstavijo v obliki, ki jo lahko uporabimo za učenje modela. Pogosto se uporablja metoda imenovana vreča besed ("Bag-of-Words"), kjer se besedilo pretvori v nabor besed, ki se pojavljajo v njem, in število pojavitev teh besed. Ta postopek lahko ponazorimo s pomočjo vektorja.
 
  \section{Zaznava objektov}
Je tehnika, ki se uporablja za avtomatsko zaznavanje in identifikacijo objektov na digitalnih slikah ali video posnetkih. Namen te tehnike je, da  prepozna in označi različne objekte v podobi ter jih loči od ozadja ali drugih objektov.

Postopek objektnega zaznavanja običajno vključuje naslednje korake:
\begin{enumerate}
 \item Zaznavanje: Model preučuje sliko ali video posnetek in identificira regije, kjer bi se lahko nahajali objekti.
 \item Lokalizacija: Po tem, ko so bile regije prepoznane, algoritem določi omejitveno okvirje (bounding boxes), ki natančno označujejo položaje in mejne točke objektov na sliki.
 \item Klasifikacija: Ko so objekti omejeni z omejitvenimi okviri, analizira vsebino znotraj teh okvirov in jih razvrsti v različne kategorije (npr. avto, pes, zgradba, itd.).
 \item  Sledenje: V video posnetkih je lahko zaželeno, da algoritem sledi objektom skozi različne kadre in tako beleži njihovo gibanje.
 \end{enumerate}
Objektno zaznavanje se uporablja v številnih aplikacijah, kot so samovozeča vozila za zaznavanje drugih vozil in pešcev, nadzorne kamere za varnostne namene, prepoznavanje obrazov, identifikacija prometnih znakov, analiza medicinskih slik in še veliko drugega. Gre za enega ključnih elementov umetne inteligence. %----------------------------------------------------------------
% Poglavje (Uporabljeni dataseti) 6
%----------------------------------------------------------------
\chapter{Dataseti}
\label{ch5}
\section{Kaj je dataset?}
Dataset je zbirka podatkov, ki so organizirani in shranjeni v strukturirani ali ne-strukturirani obliki ter označeni za namen analize, raziskav, učenja modelov ali drugih postopkov obdelave podatkov. Dataseti vsebujejo različne vrste podatkov, od številk, besedil, slik, zvokov, videoposnetkov do drugih tipov informacij.
V kontekstu računalniškega znanstvenega modeliranja in strojnega učenja so dataseti ključnega pomena, saj služijo kot osnova za razvoj, treniranje in evalvacijo modelov. Modeli se učijo na teh podatkih, tako da prepoznajo vzorce in povezave med vhodnimi podatki in ciljnimi izhodi.
Na primer, v naravnojezikovni obdelavi  dataset vsebuje besedilne podatke, ki so lahko članki, knjige, novičarski članki ali socialni mediji. 
UREDI PODATKE
Nekatere ključne točke o uporabi datasetov v NLP:

Učenje modelov: Dataseti se uporabljajo za učenje NLP modelov, pri čemer modeli na osnovi teh podatkov pridobivajo razumevanje jezika in njegove strukture. Čeprav obstajajo tudi nespremljani pristopi, večina uspešnih NLP modelov zahteva velike, kakovostne in označene datasete za doseganje najboljših rezultatov.

Razvoj in optimizacija: Razvijalci NLP modelov uporabljajo različne datasete za optimizacijo modelov in prilagajanje hiperparametrov. Z vzorci podatkov iz datasetov se preizkušajo različne arhitekture modelov in strategije učenja.

Evaluacija zmogljivosti: Dataseti se uporabljajo za evalvacijo zmogljivosti NLP modelov. Modeli se preizkušajo na ločenem testnem datasetu, ki modelom omogoča, da se oceni, kako dobro delujejo na novih, nevidenih podatkih.

Preverjanje generalizacije: Dober NLP model mora dobro delovati na različnih besedilih in jezikovnih vzorcih. S preverjanjem modela na raznolikih datasetih se preveri, ali model pravilno generalizira naučeno znanje na različne podatke.

Raziskovanje novih pristopov: Raziskovalci uporabljajo datasete za raziskovanje in razvoj novih pristopov k NLP nalogam. Ti pristopi lahko vključujejo kombinacijo različnih datasetov ali prilagoditev obstoječih modelov za nove naloge.

Nadzor kakovosti: Kvaliteta datasetov je ključnega pomena za uspešno delovanje NLP modelov. Zato je pomembno, da so dataseti natančno označeni in urejeni. Nadzor kakovosti pomaga prepoznati morebitne napake ali pristranskosti v datasetih.

Prilagajanje specifičnim aplikacijam: Včasih so potrebni specializirani NLP modeli za določene aplikacije ali domene. V takih primerih je morda potrebno ustvariti ali prilagoditi datasete, ki se bolje prilegajo ciljni uporabi.

Razvoj modelov za redke jezike: Razvoj NLP modelov za redke jezike zahteva ustrezne datasete v ciljnem jeziku, kar je lahko izziv, saj so ti dataseti pogosto omejeni ali pa jih sploh ni na voljo. V takih primerih se lahko uporabijo prevedeni ali preneseni dataseti.

V poslovnem okolju se dataseti uporabljajo za analizo strank, trženjske kampanje, obdelavo naravnega jezika v storitvah za stranke in še veliko drugih aplikacij.
Pomembno je, da so dataseti pravilno pripravljeni, imajo ustrezne metapodatke in so primerni za ciljno nalogo, da bi omogočili kakovostno analizo in doseganje uporabnih rezultatov.

\section{Uporabljeni dataseti}
\subsection{CoNLL 2003}
\label{sec:my_subsection}
 Je zbirka podatkov, ki se uporablja za razvoj in evalvacijo sistemov za obdelavo naravnega jezika , zlasti za nalogo imenovanja imenovalnih entitet.  Imenuje se po konferenci CoNLL (Conference on Computational Natural Language Learning) leta 2003, kjer je bil ta nabor podatkov predstavljen v okviru tekmovanja za prepoznavanje imenovanih entitet.
 Dataset CoNLL 2003 je priljubljen referenčni dataset za prepoznavanje poimenovanih entitet naravnega jezika v obdelavi naravnega jezika. Uporabljen je bil v skupni nalogi na konferenci o računalniškem učenju naravnega jezika (CoNLL) leta 2003.

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{conll.png}
\end{center}
\caption{CoNLL2003 dataset}
\label{pic2}
\end{figure}

Poimenovane entitete so razdeljene v štiri glavne kategorije:
\begin{enumerate}
 \item Oseba (PER): Posamezna imena ljudi.
 \item Organizacija (ORG): Imena podjetij, ustanov ali organizacij.
 \item Lokacija (LOC): Imena geografskih lokacij, kot so mesta, države ali regije.
 \item Razno (MISC): Druge poimenovane entitete, ki ne spadajo v zgoraj navedene kategorije, na primer datumi, odstotki ali denar.
 \end{enumerate}
 Podatki v datasetu so predstavljeni v obliki ene besede na vrstico, kjer vsaka vrstica predstavlja besedo in pripadajočo oznako v stavku. Besede in oznake so ločene z belim prostorom.
 Dataset CoNLL 2003 se pogosto uporablja za evalvacijo zmogljivosti modelov za prepoznavanje poimenovanih entitet in že več let je standardni benchmark za raziskovalce in strokovnjake v skupnosti obdelave naravnega jezika. Ostaja dragocen vir za razvoj in preizkušanje novih algoritmov in sistemov za NER.
Dataset je sestavljen/razdeljen na tri različne skupine in sicer:
CoNLL2003  podatkovna zbirka je običajno razdeljena na tri sklope:
\begin{enumerate}
 \item učni (train) z 14.000 vrsticami  primerov
 \item validacijski (validation) z 3.250 vrsticami primerov
 \item preizkusni (test) z 3.450 vrsticami primerov
 \end{enumerate}

\subsection{IMDb Reviews dataset}
\label{sec:imdb}
IMDB podatkovna zbirka, znana tudi kot IMDB Movie Reviews Dataset, je priljubljen benchmark podatkovni niz v področju obdelave naravnega jezika. Ta niz je sestavljen iz pregledov filmov, ki so jih prispevali uporabniki na spletni strani IMDb (Internet Movie Database).

Podatki vsebujejo ocene in besedilne komentarje, ki jih je ustvarila skupnost uporabnikov IMDb. Vsak pregled vsebuje besedilni komentar in oceno filma, ki se giblje med 1 (najslabša) in 10 (najboljša). Cilj te podatkovne zbirke v naravnem jeziku je razviti modele, ki lahko avtomatsko analizirajo besedilne komentarje in napovedo, ali je pregled pozitiven ali negativen glede na oceno in besedilo.
IMDB podatkovna zbirka je običajno razdeljena na dva sklopa: 
\begin{enumerate}
 \item učni (train) z 25.000 vrsticami  primerov
 \item preizkusni (test) z 25.000 vrsticami primerov
 \end{enumerate}
Vsak sklop vsebuje tisoče pregledov filmov. To je idealna podatkovna zbirka za naloge analize čustvenega tona besedil (sentiment analysis), kjer modeli ocenjujejo, ali je mnenje v besedilu pozitivno, negativno ali nevtralno.

\subsection{ COCO dataset}
\label{sec:coco}
COCO (Common Objects in Context) je široko uporabljen nabor podatkov v področju računalniškega vida in detekcije objektov. Namenjen je zagotavljanju celovite in raznolike zbirke slik za različne naloge, vključno z detekcijo objektov, segmentacijo in podnaslavljanjem. Nabor podatkov naj bi odražal scenarije iz resničnega sveta in vsebuje slike, ki so kompleksne ter vključujejo več objektov v različnih kontekstih.

Nabor podatkov COCO je obsežen in vsebuje deset tisoče slik z milijoni označenih posameznih objektov. Slike prihajajo iz različnih virov, zajemajo raznolike prizore, ozadja, svetlobne pogoje in velikosti objektov.


Tukaj je nekaj ključnih značilnosti nabora podatkov COCO:
\begin{enumerate}
 \item Kategorije slik: Nabor podatkov COCO vsebuje slike, ki zajemajo 80 različnih kategorij objektov, od splošnih objektov, kot so "oseba," "avto" in "pes," do bolj specifičnih objektov, kot so "mobilni telefon," "zobna ščetka" in "zmaj."

 \item Anotacije: Vsaka slika v naboru podatkov COCO je opremljena z oznakami na ravni objekta in koordinatami  okvirja. To pomeni, da je vsak posamezen objekt določene kategorije znotraj slike označen, okoli njega pa je narisano območje z okvirjem, ki označuje njegovo lokacijo. Informacije o anotacijah so ključnega pomena za usposabljanje modelov za detekcijo objektov in segmentacijo.

 \item Segmentacija objektov: Poleg anotacij območja z okviri nabor podatkov COCO prav tako zagotavlja maske segmentacije na ravni slikovnih pik za vsak posamezen objekt. To pomeni, da so objekti ne le lokalizirani z okviri, ampak so natančno določene tudi meje objektov na ravni slikovnih pik.

 \item Izzivi in tekmovanja: Nabor podatkov COCO je spodbudil številne izzive in tekmovanja v skupnosti računalniškega vida. COCO izziv je priljubljen dogodek, na katerem raziskovalci in inženirji predstavijo svoje modele za detekcijo objektov, segmentacijo in podnaslavljanje, s čimer premikajo meje tega, kar je mogoče v teh področjih.
 \end{enumerate}
 COCO podatkovna zbirka je običajno razdeljena na dva sklopa: 
\begin{enumerate}
 \item učni (train) z 117.000 primeri
 \item preizkusni (test) z 4.950 primeri
 \end{enumerate}
 
 \subsection{ CNN/Daily Mail Dataset}
 \label{sec:cnn}
 CNN/Daily Mail je zbirka novičarskih člankov skupaj s povzetki, ki se uporablja za usposabljanje in preizkušanje modelov za avstraktivno povzemanje besedil. Ta nabor podatkov vsebuje različne novičarske članke in njihove povzetke, zaradi česar je primeren za naloge avstraktivnega povzemanja, kjer se ustvarijo povzetki v lastnih besedah, ne le izbirajo stavke iz izvornega besedila.
 Nabor podatkov vsebuje na tisoče člankov s pripadajočimi povzetki, kar omogoča raziskovalcem obsežno usposabljanje in preizkušanje modelov.
 Tukaj je nekaj ključnih značilnosti nabora podatkov CNN/Daily Mail:
 \begin{enumerate}
  \item Novičarski Članki in Povzetki: Nabor podatkov vsebuje novičarske članke iz medijskih virov, kot sta CNN (Cable News Network) in Daily Mail, skupaj s pripadajočimi povzetki. Ti članki pokrivajo različne teme in dogodke ter so različnih dolžin.
 \item Avstraktivno Povzemanje: Za razliko od ekstraktivnega povzemanja, kjer se izvlečejo in združijo stavki iz izvornega besedila, avstraktivno povzemanje vključuje ustvarjanje povzetka v povsem novih besedah. Nabor podatkov CNN/Daily Mail je priljubljen za tovrstno naloge avstraktivnega povzemanja.
  \end{enumerate}
CNN/Daily Mail podatkovna zbirka je običajno razdeljena na tri sklope: 
\begin{enumerate}
 \item učni (train) z 287.000 vrsticami  primerov
 \item validacijski (validation) z 13.400 vrsticami primerov
 \item preizkusni (test) z 11.500 vrsticami primerov
 \end{enumerate}
 
 \subsection{ semeval-2017 dataset}
  \label{sec:semeval}
 SemEval podatkovne zbirke so zbirke besedilnih podatkov, ki so anotirane za različne naloge na področju obdelave naravnega jezika.
 
Tukaj je nekaj ključnih značilnosti SemEval podatkovnih zbirk:
\begin{enumerate}
 \item Anotacije: Podatki v SemEval podatkovnih zbirkah so običajno anotirani, kar pomeni, da so označeni z dodatnimi informacijami. Na primer, v podatkovni zbirki za naloge razreševanja sentimenta bi bili vzorci besedil označeni s pozitivnimi, negativnimi ali nevtralnimi sentimenti.

 \item Naloge: Vsaka SemEval podatkovna zbirka je oblikovana za reševanje specifične naloge naravnega jezika. To lahko vključuje naloge, kot so analiza sentimenta, prepoznavanje imenovanih entitet, razreševanje koreference, klasifikacija besedil itd.

 \item Raznolikost: SemEval podatkovne zbirke zajemajo širok spekter nalog, jezikov in domen. To omogoča raziskovalcem primerjavo modelov in pristopov na različnih področjih.

 \item Uporaba v tekmovanjih: SemEval podatkovne zbirke se pogosto uporabljajo v tekmovanjih, imenovanih SemEval naloge. Tekmovalci tekmujejo za razvoj najboljših algoritmov za določeno nalogo in se primerjajo z drugimi udeleženci.
 \end{enumerate}
Raziskovalna skupnost: SemEval podatkovne zbirke so postale pomemben del naravnega jezika raziskovalne skupnosti, saj omogočajo primerjavo najnovejših pristopov in tehnologij na enotnem naboru podatkov.
SemEval  podatkovna zbirka je običajno razdeljena na tri sklope: 
\begin{enumerate}
 \item učni (train) z 49.547 vrsticami  primerov
 \item validacijski (dev) z 12.285 vrsticami primerov
 \item preizkusni (test) z 12.285 vrsticami primerov
 \end{enumerate}
 
 %----------------------------------------------------------------
% Poglavje (Uporabljeni dataseti) 6
%----------------------------------------------------------------
\chapter{Metrike}
\label{ch6}

\section{Opis spremelnjivk za izračun metrik}
\textbf{Pravilno pozitivni (True Positive)}

Je izraz, ki se uporablja v statistiki in strojnem učenju za opis primerov, kjer je model pravilno napovedal pozitiven rezultat za določen razred. To pomeni, da je model prepoznal pozitiven pojav, ko je bil dejansko prisoten.

\emph{Primer:}

Predpostavimo, da razvijamo model za prepoznavanje spam sporočil v elektronski pošti. Model pravilno prepozna 25 sporočil kot nezaželena (spam), ki dejansko vsebujejo nezaželeno vsebino. To pomeni, da imamo 25 primerov "pravih pozitivnih". Te primere model pravilno prepozna kot spam, ker resnično vsebujejo neželeno vsebino.



\textbf{Napačno pozitivni (False Positive)}

Označuje situacijo, ko model napačno napove, da je nekaj pozitivno, medtem ko je v resnici negativno. Gre za vrsto napake, kjer model napačno identificira primer kot pripadajoč pozitivnemu razredu, čeprav dejansko pripada negativnemu razredu.


\emph{Primer:}

Predpostavimo, da imamo model za prepoznavanje spam sporočil v elektronski pošti. Če model označi sporočilo kot "spam", čeprav ni dejansko spam, imamo situacijo lažno pozitivnega primera. Drugače povedano, model je napačno napovedal pozitiven primer (spam), ko je dejansko negativen primer (ni spam).


\textbf{Napačno negativni (False Negatives)}

Označuje napako, ki se pojavi v kontekstu klasifikacije ali analize besedila, ko model napačno napove, da je nekaj negativno, čeprav je v resnici pozitivno. To je vrsta napake, kjer model spregleda ali ne prepozna pozitivnih primerov.

V primeru analize besedila v naravni jezikovni obdelavi (NLP), false negative se zgodi, ko model ne uspe zaznati pozitivnega elementa v besedilu, ki bi ga moral prepoznati. Na primer, če imamo model za prepoznavanje pozitivnih izjav v komentarjih in model spregleda pozitivno izjavo, to bi bil primer false negative.

\emph{Primer:}


Predpostavimo, da imamo napreden sistem za filtriranje neželenih sporočil (spam), ki ga uporabljamo za preverjanje prihajajočih e-poštnih sporočil. Sistem je zasnovan tako, da prepoznava in premika neželena sporočila v mapo za neželeno pošto.

Vendar pa se zgodi False Negative, ko sistem napačno presodi e-poštno sporočilo kot varno (ne-spam), čeprav vsebuje vse znake neželene vsebine. Na primer, če e-poštno sporočilo vsebuje povezave do nerealnih ponudb ali oglasev za sumljive izdelke, bi bila takšna sporočila številčno gledano ena od "False Negatives".

V tem primeru je sistem spregledal prepoznavo neželene vsebine, kar je povzročilo, da je sporočilo pristalo v glavnem predalu prejete pošte namesto v mapi za neželeno pošto. To lahko predstavlja težavo, saj se takšni neželeni vsebini lahko izognemo le, če sistem zanesljivo prepozna vse takšne primere.


\section{Precision}

Precision je pomembna metrika za ocenjevanje uspešnosti modelov v različnih nalogah, kot je klasifikacija, kjer se ukvarjamo z razdelitvijo podatkov v različne razrede. Poudarja natančnost pozitivnih napovedi, torej tistih primerov, ki jih model prepozna kot pozitivne. Visoka preciznost pomeni, da so pozitivne napovedi modela zanesljive in imajo malo lažno pozitivnih napak.

V kontekstu naravne jezikovne obdelave (NLP), precision igra ključno vlogo pri razumevanju besedila. Na primer, pri analizi sentimenta želimo natančno ugotoviti, ali je izraz pozitiven ali negativen. Visoka preciznost v tem primeru pomeni, da so napovedi modela o sentimentu točne in se malo zmotijo.

 
 Formula za izračun:
\begin{center}
  \Large{Precision = \(\frac{True Positive}{True Positive + False Negatives}\)}
\end{center}

 Povzeto po:https://www.analyticsvidhya.com/blog/2021/07/metrics-to-evaluate-your-classification-model-to-take-the-right-decisions/

\section{Recall}
Nanaša se na eno od metrik uspešnosti pri vrednotenju modelov za obdelavo naravnega jezika. Recall se meri kot razmerje med številom pravilno prepoznanih relevantnih primerov in celotnim številom dejansko obstoječih relevantnih primerov. Višji recall pomeni, da je model bolje usposobljen za iskanje in pridobivanje vseh relevantnih informacij, vendar to lahko vodi tudi v več lažno pozitivnih rezultatov. Zato je pomembno doseči uravnoteženost med recallom in natančnostjo (precision) pri oceni uspešnosti modelov. Primer uporabe recalla  je v iskalnih sistemih, kjer želimo zagotoviti, da se relevantni dokumenti ali informacije ne izpustijo pri iskanju. S pravilno optimizacijo modelov lahko dosežemo visoko kakovostno izluščevanje informacij iz besedil, kar je ključno za številne aplikacije, kot so avtomatizirano odzivanje na povratne informacije strank, analiza sentimenta in razumevanje besedil v različnih jezikih.

 Formula za izračun:
\begin{center}
 \Large{Recall = \(\frac{True Positive}{True Positive + False Positive}\)}
\end{center}

\section{F1}

F1-metrika je pomembna za ocenjevanje uspešnosti modelov v obdelavi besedil in naravnojezikovnem procesiranju. Združuje oceni natančnosti (precision) in prepoznavnosti (recall) v eno številko, ki odraža ravnotežje med temi dvema metrikama. Pri NLP nalogah, kot so klasifikacija besedil, izluščanje informacij ali identifikacija entitet, sta tako natančnost kot prepoznavnost ključni. Visoka natančnost pomeni pravilno identifikacijo relevantnih elementov, medtem ko visok recall zagotavlja prepoznavanje vseh resnično pozitivnih primerov. F1-metrika se izračuna kot povprečje med natančnostjo in prepoznavnostjo, dajeta pa ji enako težo. To omogoča, da ocenimo, kako dobro model obvladuje oba cilja hkrati. Visoka vrednost F1-metrike kaže, da je model uspešno uskladil identifikacijo pravih pozitivnih primerov z izogibanjem napačno pozitivnim rezultatom. Uporaba F1-metrike je zlasti smiselna, ko sta natančnost in prepoznavnost pomembni za končni rezultat in ko želimo doseči optimalno uravnoteženost med tema dvema vidikoma.


 Formula za izračun:
\begin{center}
 \Large{F1 = 2 x \(\frac{Precision \times Recal}{Precision + Recal}\)}
\end{center}

\section{Accuracy}
Natančnost je metrika, ki se pogosto uporablja za ocenjevanje uspešnosti modelov v strojnem učenju, vključno z modeli uporabljenimi v obdelavi naravnega jezika. Ta metrika meri, kako pravilno model napove razrede ali kategorije za vhodne podatke v primerjavi z dejanskimi vrednostmi.

V kontekstu NLP se natančnost uporablja, na primer, pri nalogah klasifikacije besedil. Predpostavimo, da imamo model, ki se uči razvrščati besedila v določene kategorije, kot so "pozitivno", "negativno" ali "neutra." Za vsako besedilo ima model svojo napoved, kateri kategoriji pripada.

 Formula za izračun:
\begin{center}
  \large{Accuracy = \(\frac{True Positive + True Negative}{True Positive + True Negative +False Positive + False Negative}\)}
\end{center}

\section{ROUGE}
ROUGE je metrika, ki se uporablja za ocenjevanje kakovosti generiranih besedil v primerjavi s referenčnimi besedili. Gre za kratico, ki označuje "Recall-Oriented Understudy for Gisting Evaluation" (ali v prevodu "ocena za podporo povzemanju z osrednjim poudarkom na priklicu"). Metrika ROUGE je pogosto uporabljena v področju obdelave naravnega jezika, še posebej v nalogah avtomatskega povzemanja besedil.

Metrika ROUGE primerja generirano besedilo s referenčnim besedilom (običajno človeško ustvarjenim besedilom) in oceni, kako dobro so se ujemale. Metrika upošteva različne vidike, kot so prekrivanje besed, besedni nizi in skupna dolžina besedil. Glavni cilj metrike ROUGE je merjenje stopnje, do katere je generirano besedilo sposobno pravilno povzeti pomembne informacije iz referenčnega besedila.

Obstajajo različne različice metrike ROUGE, kot so ROUGE-1, ROUGE-2, ROUGE-L itd. Vsaka različica meri različne vidike podobnosti med generiranim besedilom in referenčnim besedilom. Na primer, ROUGE-1 meri prekrivanje eno-besednih nizov med generiranim in referenčnim besedilom, medtem ko ROUGE-2 meri prekrivanje dvo-besednih nizov.

Metrika ROUGE je široko uporabljena v raziskavah in nalogah NLP, ki vključujejo avtomatsko povzemanje besedil, strojno prevajanje in druge naloge, kjer je pomembno oceniti kakovost generiranih besedil v primerjavi z referenčnimi besedili. Metrika ROUGE lahko pomaga raziskovalcem in razvijalcem oceniti učinkovitost svojih modelov in tehnik ter izboljšati rezultate pri generiranju besedil.


  %----------------------------------------------------------------
% Poglavje (Uporabljeni dataseti) 6
%----------------------------------------------------------------
\chapter{Analiza raziskave}
\label{ch7}
\section{Prepoznavanje imenskih entitet (Named Entity Recognition)}
\begin{table}[h!]
\caption{Prepoznavanje imenskih entitet}
\begin{center}
        \begin{tabular}{l|ccc}
             & {\tt Precision} & {\tt Recall}  & F1   \\ \hline
                        {\tt Transformers} & 0.949 & 0.953 & 0.951 \\
                        {\tt Vertex AI }   & 0.920 & 0.919  & 0.919  \\
                         {\tt AWS SageMaker}   & \textbf {0.954} & \textbf {0.961}& \textbf {0.958}  \\     
                        {\tt Azure Cognitive Services}   & 0.858 & 0.824  & 0.840
        \end{tabular}
        \end{center}
\label{tbl:1}
\end{table}

 \newpage
 
 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{NER.png}
\end{center}
\caption{Prepoznavanje imenskih entitet F1 rezultat}
\label{pic2}
\end{figure}

Pri analizi imenskih entitet je bil uporabljen \hyperref[sec:my_subsection]{\underline {CONLL-2003}} dataset.

Za prepoznavanje oseb (PER) in organizacij (ORG) se je najbolje izkazal Vertex AI storitev. Na splošno pa je bil v vseh področjih najboljši AWS SageMaker storitev.

  \newpage
\section{Analiza sentimenta (Sentiment Analaysis)}
\begin{table}[h!]
\caption{Analiza sentimenta}
\begin{center}
        \begin{tabular}{l|ccc}
             & {\tt Precision} & {\tt Recall}  & F1   \\ \hline
                        {\tt Transformers} & 0.800 & 0.799 & 0.799 \\
                        {\tt Vertex AI }   & \textbf {0.924} & \textbf {0.924 } & \textbf {0.924}  \\
                         {\tt AWS SageMaker}   & 0.862 & 0.891 & 0.876 \\     
                        {\tt Azure Cognitive Services}   & 0.862 & 0.891  & 0.877
        \end{tabular}
\end{center}        
\label{tbl:1}
\end{table}

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{KP.png}
\end{center}
\caption{Analiza sentimenta F1 rezultat}
\label{pic2}
\end{figure}
Pri analizi imenskih entitet je bil uporabljen  \hyperref[sec:imdb]{\underline {IMDb Reviews}} dataset.
Za analizo sentimenta  je bila najboljša Vertex AI storitev.

\pagebreak 

\section{Povzetek (Summarisation)}
\begin{table}[h!]
\caption{Povzetek }
\begin{center}
        \begin{tabular}{l|ccc}
             & {\tt ROUGE-1} & {\tt ROUGE-2}  & ROUGE-L   \\ \hline
                        {\tt Transformers} & 0.209 & 0.190 & 0.192 \\
                        {\tt Vertex AI }   & \textbf {0.429} & \textbf {0.208 } & \textbf {0.306}  \\
                         {\tt AWS SageMaker}   & 0.226 & 0.021 & 0.201 \\     
                        {\tt Azure Cognitive Services}   & 0.426 & 0.220  & 0.330
        \end{tabular}
 \end{center}
\label{tbl:1}
\end{table}

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{SUMM.png}
\end{center}
\caption{Povzetek F1 rezultat}
\label{pic2}
\end{figure}

Pri izdelavi povzetka je bil uporabljen dataset  \hyperref[sec:cnn]{\underline {CNN/Daily Mail}}.

Kot vrhunska izbira za ustvarjanje povzetkov pa se je izkazala storitev Vertex AI.

%----------------------------------------------------------------
%Izvleček besedne zveze 

%----------------------------------------------------------------
  \newpage
\section{Izvleček besedne zveze  (Key Phrases)}
\begin{table}[h!]
\caption{Izvleček besedne zveze  }
\begin{center}
        \begin{tabular}{l|ccc}
             & {\tt Precision} & {\tt Recall}  & F1   \\ \hline
                        {\tt Transformers} & 0.475 & 0.573 & 0.519\\
                        {\tt Vertex AI }   & 0.637 & 0.543  & 0.586  \\
                         {\tt AWS SageMaker}   & 0.513 & 0.622 & 0.562 \\     
                        {\tt Azure Cognitive Services}   &  \textbf {0.530} & \textbf {0.670}  & \textbf {0.592}
        \end{tabular}
\end{center}
\label{tbl:1}
\end{table}

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{KEY.png}
\end{center}
\caption{Izvleček besedne zveze F1 rezultat}
\label{pic2}
\end{figure}

Pri izvajanju naloge zvlečka besedne zveze je bil uporabljen podatkovni niz  \hyperref[sec:semeval]{\underline {semeval-2017}}.

Kot najboljša rešitev za naloge izvlečka besedne zveze pa se je izkazala storitev Azure Cognitive Services.

\pagebreak 
%----------------------------------------------------------------
% Klasifikacija besedila 
%----------------------------------------------------------------

\section{Klasifikacija besedila  (Text Classification)}
\begin{table}[h!]
\caption{ Klasifikacija besedila  }
\begin{center}
        \begin{tabular}{l|ccc}
             & {\tt Precision} & {\tt Recall}  & F1   \\ \hline
                        {\tt Transformers} & \textbf {0.930} & \textbf {0.926} & \textbf {0.928} \\
                        {\tt Vertex AI }   & 0.957 & 0.862  & 0.907  \\
                         {\tt AWS SageMaker}   & 0.858 & 0.763 & 0. 807\\     
                        {\tt Azure Cognitive Services}   & 0.880 & 0.920  & 0.900
        \end{tabular}
\end{center}
\label{tbl:1}
\end{table}

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{CLASSIFICATION.png}
\end{center}
\caption{ Klasifikacija besedila  F1 rezultat}
\label{pic2}
\end{figure}

Pri izvajanju naloge klasifikacije besedila je bil uporabljen podatkovni niz  \hyperref[sec:imdb]{\underline {IMDb Reviews}}.

Kot najboljša rešitev za naloge klasifikacije besedila pa se je izkazala storitev Transformers.

\pagebreak 
%----------------------------------------------------------------
% Zaznava objektov 
%---------------------------------------------------------------

\section{Zaznava objektov  (Object Detection)}
\begin{table}[h!]
\caption{ Klasifikacija besedila  }
\begin{center}
        \begin{tabular}{l|ccc}
             &  Accuracy   \\ \hline
                        {\tt Transformers} & 0.968\\
                        {\tt Vertex AI }   & 0.977   \\
                         {\tt AWS SageMaker}   & \textbf {0.980}  \\     
                        {\tt Azure Cognitive Services}   &  0.965
        \end{tabular}
\end{center}
\label{tbl:1}
\end{table}

 \begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{OBJECT.png}
\end{center}
\caption{ Zaznava objektov Accuracy rezultat}
\label{pic2}
\end{figure}


Pri zaznavi objektov je bil uporabljen  \hyperref[sec:coco]{\underline {COCO}} dataset.

Kot najboljša izbira za zaznavanje objektov pa se je izkazala storitev AWS SageMaker.


%----------------------------------------------------------------
% Poglavje (Chapter) 6
%----------------------------------------------------------------
\chapter{Sklepne ugotovitve}
\label{ch8}
Izbira \LaTeX\ ali ne \LaTeX\ je seveda prepuščena vam samim. Res je, da so prvi koraki v \LaTeX{}u težavni. Ta dokument naj vam služi kot začetna opora pri hoji.

% ---------------------------------------------------------------
% Appendix
% ---------------------------------------------------------------
\appendix
%\addcontentsline{toc}{chapter}{Razširjeni povzetek}
\chapter{Title of the appendix 1}

Example of the appendix.

%----------------------------------------------------------------
% SLO: bibliografija
% ENG: bibliography
%----------------------------------------------------------------
\bibliographystyle{elsarticle-num}

%----------------------------------------------------------------
% SLO: odkomentiraj za uporabo zunanje datoteke .bib (ne pozabi je potem prevesti!)
% ENG: uncomment to use .bib file (don't forget to compile it!)
%----------------------------------------------------------------
%\bibliography{bibliography}

%----------------------------------------------------------------
% SLO: zakomentiraj spodnji del, če uporabljaš zunanjo .bib datoteko
% ENG: comment the part below if using the .bib file
%----------------------------------------------------------------

\begin{thebibliography}{99}
\bibitem{Fortnow} L.\ Fortnow, ``Viewpoint: Time for computer science to grow up'',
{\it Communications of the ACM}, št.\ 52, zv.\ 8, str.\ 33--35, 2009.
\bibitem{Knuth} D.\ E.\ Knuth, P. Bendix. ``Simple word problems in universal algebras'', v zborniku: Computational Problems in Abstract Algebra (ur. J. Leech), 1970, str. 263--297.
\bibitem{Lamport} L.\ Lamport. {\it LaTEX: A Document Preparation System}. Addison-Wesley, 1986.
\bibitem{ubi} O.\ Patashnik (1998) \BibTeX{}ing.
Dostopno na: \url{http://ftp.univie.ac.at/packages/tex/biblio/bibtex/contrib/doc/btxdoc.pdf}
\bibitem{licence} licence-cc.pdf. Dostopno na: \url{https://ucilnica.fri.uni-lj.si/course/view.php?id=274}
\end{thebibliography}

\end{document}
